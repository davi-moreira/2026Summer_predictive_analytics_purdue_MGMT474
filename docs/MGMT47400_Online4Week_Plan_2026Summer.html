<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>mgmt47400_online4week_plan_2026summer – MGMT 47400: Predictive Analytics (Summer 2026 - 4-Week Intensive)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-e2886813ffd81db4f823f0bbbf45b6b3.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./images/mgmt_474_ai_logo_02-modified.png" alt="" class="sidebar-logo light-content py-0 d-lg-inline d-none">
      <img src="./images/mgmt_474_ai_logo_02-modified.png" alt="" class="sidebar-logo dark-content py-0 d-lg-inline d-none">
      </a>
      <div class="sidebar-tools-main">
    <a href="https://github.com/davi-moreira/2026Summer_predictive_analytics_purdue_MGMT474" title="GitHub" class="quarto-navigation-tool px-1" aria-label="GitHub"><i class="bi bi-github"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./syllabus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Syllabus</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./schedule.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Schedule and Material</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#mgmt-47400-predictive-analytics-3-credits" id="toc-mgmt-47400-predictive-analytics-3-credits" class="nav-link active" data-scroll-target="#mgmt-47400-predictive-analytics-3-credits">MGMT 47400 – Predictive Analytics (3 credits)</a>
  <ul class="collapse">
  <li><a href="#week-fully-online-course-plan-daniels-school-of-business" id="toc-week-fully-online-course-plan-daniels-school-of-business" class="nav-link" data-scroll-target="#week-fully-online-course-plan-daniels-school-of-business">4-Week Fully Online Course Plan (Daniels School of Business)</a></li>
  <li><a href="#delivery-constraints-operational" id="toc-delivery-constraints-operational" class="nav-link" data-scroll-target="#delivery-constraints-operational">Delivery constraints (operational)</a></li>
  <li><a href="#pedagogical-pattern-used-consistently" id="toc-pedagogical-pattern-used-consistently" class="nav-link" data-scroll-target="#pedagogical-pattern-used-consistently">Pedagogical pattern (used consistently)</a></li>
  <li><a href="#course-wide-core-references-used-repeatedly" id="toc-course-wide-core-references-used-repeatedly" class="nav-link" data-scroll-target="#course-wide-core-references-used-repeatedly">Course-wide core references (used repeatedly)</a></li>
  </ul></li>
  <li><a href="#weekly-structure-and-project-milestones" id="toc-weekly-structure-and-project-milestones" class="nav-link" data-scroll-target="#weekly-structure-and-project-milestones">Weekly structure and project milestones</a>
  <ul class="collapse">
  <li><a href="#project-single-end-to-end-applied-project-progresses-weekly" id="toc-project-single-end-to-end-applied-project-progresses-weekly" class="nav-link" data-scroll-target="#project-single-end-to-end-applied-project-progresses-weekly">Project (single end-to-end applied project; progresses weekly)</a></li>
  </ul></li>
  <li><a href="#week-1-days-15-foundations-eda-splits-linear-regression-regularization" id="toc-week-1-days-15-foundations-eda-splits-linear-regression-regularization" class="nav-link" data-scroll-target="#week-1-days-15-foundations-eda-splits-linear-regression-regularization">Week 1 (Days 1–5): Foundations, EDA, Splits, Linear Regression, Regularization</a>
  <ul class="collapse">
  <li><a href="#day-1-tue-may-18" id="toc-day-1-tue-may-18" class="nav-link" data-scroll-target="#day-1-tue-may-18">Day 1 — Tue May 18</a>
  <ul class="collapse">
  <li><a href="#launchpad-colab-workflow-gemini-vibe-coding-eda-and-splitting-correctly" id="toc-launchpad-colab-workflow-gemini-vibe-coding-eda-and-splitting-correctly" class="nav-link" data-scroll-target="#launchpad-colab-workflow-gemini-vibe-coding-eda-and-splitting-correctly">Launchpad: Colab workflow, Gemini vibe-coding, EDA, and splitting correctly</a></li>
  </ul></li>
  <li><a href="#day-2-wed-may-19" id="toc-day-2-wed-may-19" class="nav-link" data-scroll-target="#day-2-wed-may-19">Day 2 — Wed May 19</a>
  <ul class="collapse">
  <li><a href="#data-setup-and-preprocessing-pipelines-the-professional-way" id="toc-data-setup-and-preprocessing-pipelines-the-professional-way" class="nav-link" data-scroll-target="#data-setup-and-preprocessing-pipelines-the-professional-way">Data setup and preprocessing pipelines (the professional way)</a></li>
  </ul></li>
  <li><a href="#day-3-thu-may-20" id="toc-day-3-thu-may-20" class="nav-link" data-scroll-target="#day-3-thu-may-20">Day 3 — Thu May 20</a>
  <ul class="collapse">
  <li><a href="#trainvalidationtest-rigor-regression-metrics-baseline-modeling" id="toc-trainvalidationtest-rigor-regression-metrics-baseline-modeling" class="nav-link" data-scroll-target="#trainvalidationtest-rigor-regression-metrics-baseline-modeling">Train/validation/test rigor + regression metrics + baseline modeling</a></li>
  </ul></li>
  <li><a href="#day-4-fri-may-21" id="toc-day-4-fri-may-21" class="nav-link" data-scroll-target="#day-4-fri-may-21">Day 4 — Fri May 21</a>
  <ul class="collapse">
  <li><a href="#linear-regression-that-actually-works-features-interactions-diagnostics" id="toc-linear-regression-that-actually-works-features-interactions-diagnostics" class="nav-link" data-scroll-target="#linear-regression-that-actually-works-features-interactions-diagnostics">Linear regression that actually works: features, interactions, diagnostics</a></li>
  </ul></li>
  <li><a href="#day-5-mon-may-24" id="toc-day-5-mon-may-24" class="nav-link" data-scroll-target="#day-5-mon-may-24">Day 5 — Mon May 24</a>
  <ul class="collapse">
  <li><a href="#regularization-ridgelasso-project-proposal-sprint" id="toc-regularization-ridgelasso-project-proposal-sprint" class="nav-link" data-scroll-target="#regularization-ridgelasso-project-proposal-sprint">Regularization (Ridge/Lasso) + Project proposal sprint</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#week-2-days-610-classification-metrics-resampling-comparison-midterm" id="toc-week-2-days-610-classification-metrics-resampling-comparison-midterm" class="nav-link" data-scroll-target="#week-2-days-610-classification-metrics-resampling-comparison-midterm">Week 2 (Days 6–10): Classification, Metrics, Resampling, Comparison + Midterm</a>
  <ul class="collapse">
  <li><a href="#day-6-tue-may-25" id="toc-day-6-tue-may-25" class="nav-link" data-scroll-target="#day-6-tue-may-25">Day 6 — Tue May 25</a>
  <ul class="collapse">
  <li><a href="#logistic-regression-probabilities-decision-boundaries-and-pipelines" id="toc-logistic-regression-probabilities-decision-boundaries-and-pipelines" class="nav-link" data-scroll-target="#logistic-regression-probabilities-decision-boundaries-and-pipelines">Logistic regression: probabilities, decision boundaries, and pipelines</a></li>
  </ul></li>
  <li><a href="#day-7-wed-may-26" id="toc-day-7-wed-may-26" class="nav-link" data-scroll-target="#day-7-wed-may-26">Day 7 — Wed May 26</a>
  <ul class="collapse">
  <li><a href="#classification-metrics-confusion-matrix-rocpr-calibration-and-business-costs" id="toc-classification-metrics-confusion-matrix-rocpr-calibration-and-business-costs" class="nav-link" data-scroll-target="#classification-metrics-confusion-matrix-rocpr-calibration-and-business-costs">Classification metrics: confusion matrix, ROC/PR, calibration, and business costs</a></li>
  </ul></li>
  <li><a href="#day-8-thu-may-27" id="toc-day-8-thu-may-27" class="nav-link" data-scroll-target="#day-8-thu-may-27">Day 8 — Thu May 27</a>
  <ul class="collapse">
  <li><a href="#resampling-and-cv-how-to-compare-models-without-fooling-yourself" id="toc-resampling-and-cv-how-to-compare-models-without-fooling-yourself" class="nav-link" data-scroll-target="#resampling-and-cv-how-to-compare-models-without-fooling-yourself">Resampling and CV: how to compare models without fooling yourself</a></li>
  </ul></li>
  <li><a href="#day-9-fri-may-28" id="toc-day-9-fri-may-28" class="nav-link" data-scroll-target="#day-9-fri-may-28">Day 9 — Fri May 28</a>
  <ul class="collapse">
  <li><a href="#feature-engineering-model-selection-workflow-and-project-baseline-build" id="toc-feature-engineering-model-selection-workflow-and-project-baseline-build" class="nav-link" data-scroll-target="#feature-engineering-model-selection-workflow-and-project-baseline-build">Feature engineering + model selection workflow (and Project baseline build)</a></li>
  </ul></li>
  <li><a href="#day-10-mon-may-31" id="toc-day-10-mon-may-31" class="nav-link" data-scroll-target="#day-10-mon-may-31">Day 10 — Mon May 31</a>
  <ul class="collapse">
  <li><a href="#midterm-business-case-predictive-strategy-practicum-project-baseline-submission" id="toc-midterm-business-case-predictive-strategy-practicum-project-baseline-submission" class="nav-link" data-scroll-target="#midterm-business-case-predictive-strategy-practicum-project-baseline-submission">Midterm: Business-case predictive strategy practicum + Project baseline submission</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#week-3-days-1115-trees-ensembles-tuning-interpretation" id="toc-week-3-days-1115-trees-ensembles-tuning-interpretation" class="nav-link" data-scroll-target="#week-3-days-1115-trees-ensembles-tuning-interpretation">Week 3 (Days 11–15): Trees, Ensembles, Tuning, Interpretation</a>
  <ul class="collapse">
  <li><a href="#day-11-tue-june-1" id="toc-day-11-tue-june-1" class="nav-link" data-scroll-target="#day-11-tue-june-1">Day 11 — Tue June 1</a>
  <ul class="collapse">
  <li><a href="#decision-trees-interpretable-models-with-sharp-edges" id="toc-decision-trees-interpretable-models-with-sharp-edges" class="nav-link" data-scroll-target="#decision-trees-interpretable-models-with-sharp-edges">Decision trees: interpretable models with sharp edges</a></li>
  </ul></li>
  <li><a href="#day-12-wed-june-2" id="toc-day-12-wed-june-2" class="nav-link" data-scroll-target="#day-12-wed-june-2">Day 12 — Wed June 2</a>
  <ul class="collapse">
  <li><a href="#random-forests-bagging-oob-intuition-and-feature-importance" id="toc-random-forests-bagging-oob-intuition-and-feature-importance" class="nav-link" data-scroll-target="#random-forests-bagging-oob-intuition-and-feature-importance">Random forests: bagging, OOB intuition, and feature importance</a></li>
  </ul></li>
  <li><a href="#day-13-thu-june-3" id="toc-day-13-thu-june-3" class="nav-link" data-scroll-target="#day-13-thu-june-3">Day 13 — Thu June 3</a>
  <ul class="collapse">
  <li><a href="#gradient-boosting-performance-with-discipline-and-leakage-avoidance" id="toc-gradient-boosting-performance-with-discipline-and-leakage-avoidance" class="nav-link" data-scroll-target="#gradient-boosting-performance-with-discipline-and-leakage-avoidance">Gradient boosting: performance with discipline (and leakage avoidance)</a></li>
  </ul></li>
  <li><a href="#day-14-fri-june-4" id="toc-day-14-fri-june-4" class="nav-link" data-scroll-target="#day-14-fri-june-4">Day 14 — Fri June 4</a>
  <ul class="collapse">
  <li><a href="#model-selection-and-comparison-making-the-call-like-a-professional" id="toc-model-selection-and-comparison-making-the-call-like-a-professional" class="nav-link" data-scroll-target="#model-selection-and-comparison-making-the-call-like-a-professional">Model selection and comparison: making the call like a professional</a></li>
  </ul></li>
  <li><a href="#day-15-mon-june-7" id="toc-day-15-mon-june-7" class="nav-link" data-scroll-target="#day-15-mon-june-7">Day 15 — Mon June 7</a>
  <ul class="collapse">
  <li><a href="#interpretation-feature-importance-partial-dependence-project-improved-model-delivery" id="toc-interpretation-feature-importance-partial-dependence-project-improved-model-delivery" class="nav-link" data-scroll-target="#interpretation-feature-importance-partial-dependence-project-improved-model-delivery">Interpretation: feature importance + partial dependence + project improved model delivery</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#week-4-days-1620-error-analysis-fairnessethics-deployment-thinking-executive-narrative-final-project" id="toc-week-4-days-1620-error-analysis-fairnessethics-deployment-thinking-executive-narrative-final-project" class="nav-link" data-scroll-target="#week-4-days-1620-error-analysis-fairnessethics-deployment-thinking-executive-narrative-final-project">Week 4 (Days 16–20): Error Analysis, Fairness/Ethics, Deployment Thinking, Executive Narrative, Final Project</a>
  <ul class="collapse">
  <li><a href="#day-16-tue-june-8" id="toc-day-16-tue-june-8" class="nav-link" data-scroll-target="#day-16-tue-june-8">Day 16 — Tue June 8</a>
  <ul class="collapse">
  <li><a href="#error-analysis-to-decisions-thresholds-calibration-and-kpi-alignment" id="toc-error-analysis-to-decisions-thresholds-calibration-and-kpi-alignment" class="nav-link" data-scroll-target="#error-analysis-to-decisions-thresholds-calibration-and-kpi-alignment">Error analysis to decisions: thresholds, calibration, and KPI alignment</a></li>
  </ul></li>
  <li><a href="#day-17-wed-june-9" id="toc-day-17-wed-june-9" class="nav-link" data-scroll-target="#day-17-wed-june-9">Day 17 — Wed June 9</a>
  <ul class="collapse">
  <li><a href="#fairness-and-ethics-basics-responsible-predictive-analytics-minimum-viable-rigor" id="toc-fairness-and-ethics-basics-responsible-predictive-analytics-minimum-viable-rigor" class="nav-link" data-scroll-target="#fairness-and-ethics-basics-responsible-predictive-analytics-minimum-viable-rigor">Fairness and ethics basics: responsible predictive analytics (minimum viable rigor)</a></li>
  </ul></li>
  <li><a href="#day-18-thu-june-10" id="toc-day-18-thu-june-10" class="nav-link" data-scroll-target="#day-18-thu-june-10">Day 18 — Thu June 10</a>
  <ul class="collapse">
  <li><a href="#deployment-thinking-reproducibility-monitoring-drift-and-dont-ship-a-notebook" id="toc-deployment-thinking-reproducibility-monitoring-drift-and-dont-ship-a-notebook" class="nav-link" data-scroll-target="#deployment-thinking-reproducibility-monitoring-drift-and-dont-ship-a-notebook">Deployment thinking: reproducibility, monitoring, drift, and “don’t ship a notebook”</a></li>
  </ul></li>
  <li><a href="#day-19-fri-june-11" id="toc-day-19-fri-june-11" class="nav-link" data-scroll-target="#day-19-fri-june-11">Day 19 — Fri June 11</a>
  <ul class="collapse">
  <li><a href="#executive-narrative-slide-style-story-conference-video-plan-project-studio" id="toc-executive-narrative-slide-style-story-conference-video-plan-project-studio" class="nav-link" data-scroll-target="#executive-narrative-slide-style-story-conference-video-plan-project-studio">Executive narrative: slide-style story + conference video plan (project studio)</a></li>
  </ul></li>
  <li><a href="#day-20-mon-june-14" id="toc-day-20-mon-june-14" class="nav-link" data-scroll-target="#day-20-mon-june-14">Day 20 — Mon June 14</a>
  <ul class="collapse">
  <li><a href="#final-delivery-project-package-submission-peer-review-course-closeout" id="toc-final-delivery-project-package-submission-peer-review-course-closeout" class="nav-link" data-scroll-target="#final-delivery-project-package-submission-peer-review-course-closeout">Final delivery: project package submission + peer review + course closeout</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#project-bibliography-applies-across-all-milestones" id="toc-project-bibliography-applies-across-all-milestones" class="nav-link" data-scroll-target="#project-bibliography-applies-across-all-milestones">Project bibliography (applies across all milestones)</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="mgmt-47400-predictive-analytics-3-credits" class="level1">
<h1>MGMT 47400 – Predictive Analytics (3 credits)</h1>
<section id="week-fully-online-course-plan-daniels-school-of-business" class="level2">
<h2 class="anchored" data-anchor-id="week-fully-online-course-plan-daniels-school-of-business">4-Week Fully Online Course Plan (Daniels School of Business)</h2>
<p><strong>Run dates (business days):</strong> Tue <strong>May 18, 2027</strong> → Mon <strong>June 14, 2027</strong> (20 business days)<br>
<strong>Daily engagement target:</strong> <strong>112.5 minutes per business day</strong> (videos + Colab notebooks + exercises + quizzes + project work)<br>
<strong>Instruction format:</strong> short recorded <strong>micro-videos (≤ 12 minutes each)</strong> + <strong>hands-on Jupyter Notebooks</strong> opened in <strong>Google Colab</strong><br>
<strong>AI support:</strong> students use <strong>Gemini inside Colab</strong> for guided “vibe coding” (draft → verify → document)<br>
<strong>Course center of gravity:</strong> supervised predictive modeling in Python (ISLP-with-Python style)</p>
<hr>
</section>
<section id="delivery-constraints-operational" class="level2">
<h2 class="anchored" data-anchor-id="delivery-constraints-operational">Delivery constraints (operational)</h2>
<ul>
<li><strong>112.5 minutes per business day</strong> per student (Mon–Fri), inclusive of videos, notebook work, readings, exercises, quizzes, and project work.</li>
<li>All instructional video segments are <strong>≤ 12 minutes</strong>.</li>
<li>Every lecture/topic includes at least one <strong>Google Colab-ready notebook</strong>.</li>
<li>Every day includes at least one <strong>10-minute “pause-and-do” exercise</strong> inside the notebook.</li>
</ul>
<hr>
</section>
<section id="pedagogical-pattern-used-consistently" class="level2">
<h2 class="anchored" data-anchor-id="pedagogical-pattern-used-consistently">Pedagogical pattern (used consistently)</h2>
<p>For each topic/day, content follows a repeating loop: 1. <strong>Concept + demo in notebook</strong><br>
2. <strong>Guided practice</strong> with a <strong>10-minute student exercise (“pause-and-do”)</strong><br>
3. <strong>Next micro-video begins with solution + common mistakes + extensions</strong><br>
4. <strong>Next concept + demo</strong> … and repeat</p>
<hr>
</section>
<section id="course-wide-core-references-used-repeatedly" class="level2">
<h2 class="anchored" data-anchor-id="course-wide-core-references-used-repeatedly">Course-wide core references (used repeatedly)</h2>
<ul>
<li><strong>James, Witten, Hastie, Tibshirani.</strong> <em>An Introduction to Statistical Learning</em> (ISLP) + Python labs.</li>
<li><strong>Hastie, Tibshirani, Friedman.</strong> <em>The Elements of Statistical Learning</em> (ESL).</li>
<li><strong>Provost, Fawcett.</strong> <em>Data Science for Business</em>.</li>
<li><strong>Pedregosa et al.</strong> “Scikit-learn: Machine Learning in Python.” <em>JMLR</em>.</li>
<li><strong>scikit-learn User Guide</strong> (pipelines, preprocessing, model selection, metrics, inspection).</li>
<li><strong>Chip Huyen.</strong> <em>Designing Machine Learning Systems</em> (deployment thinking, monitoring).</li>
</ul>
<hr>
</section>
</section>
<section id="weekly-structure-and-project-milestones" class="level1">
<h1>Weekly structure and project milestones</h1>
<section id="project-single-end-to-end-applied-project-progresses-weekly" class="level2">
<h2 class="anchored" data-anchor-id="project-single-end-to-end-applied-project-progresses-weekly">Project (single end-to-end applied project; progresses weekly)</h2>
<ul>
<li><strong>Week 1 (due Day 5): Proposal + dataset selection</strong></li>
<li><strong>Week 2 (due Day 10): Baseline model + evaluation plan</strong></li>
<li><strong>Week 3 (due Day 15): Improved model + interpretation</strong></li>
<li><strong>Week 4 (due Day 20): Final model + executive-ready deliverable (slide-style narrative + conference video)</strong></li>
</ul>
<hr>
</section>
</section>
<section id="week-1-days-15-foundations-eda-splits-linear-regression-regularization" class="level1">
<h1>Week 1 (Days 1–5): Foundations, EDA, Splits, Linear Regression, Regularization</h1>
<p><strong>Project milestone:</strong> Week 1 proposal due <strong>Day 5</strong></p>
<hr>
<section id="day-1-tue-may-18" class="level2">
<h2 class="anchored" data-anchor-id="day-1-tue-may-18">Day 1 — Tue May 18</h2>
<section id="launchpad-colab-workflow-gemini-vibe-coding-eda-and-splitting-correctly" class="level3">
<h3 class="anchored" data-anchor-id="launchpad-colab-workflow-gemini-vibe-coding-eda-and-splitting-correctly">Launchpad: Colab workflow, Gemini vibe-coding, EDA, and splitting correctly</h3>
<p><strong>Learning objectives</strong> - Operate course workflow in Google Colab (run-all, save-copy, submit link). - Use Gemini in Colab to accelerate coding while preserving accountability (explain + verify). - Perform structured EDA (types, missingness, target distribution, leakage sniff test). - Create train/validation/test splits with reproducible seeds. - Identify obvious leakage patterns before modeling.</p>
<p><strong>Micro-videos (total 54 min)</strong> 1. Concept+demo: Colab setup + course notebook conventions (10)<br>
2. Guided practice: EDA checklist (what to compute/plot first) (8)<br>
3. Solution: EDA walkthrough + common plotting/data-type mistakes + extensions (9)<br>
4. Concept+demo: Train/validation/test and why leakage happens (10)<br>
5. Guided practice: Implement reproducible splits + sanity checks (8)<br>
6. Solution: Split validation + leakage red flags + extension: stratified splits (9)</p>
<p><strong>Notebook(s)</strong> - File: <code>01_launchpad_eda_splits.ipynb</code><br>
- Sections: - Setup (installs, imports, seeds, display settings) - Gemini workflow rules (“ask → verify → document”) - Load dataset (course-provided sample) - EDA checklist (tables + plots) - Splits (train/val/test) + leakage sniff test - Wrap-up: key takeaways + “next-day readiness” cells</p>
<p><strong>In-notebook exercises (10-minute scope)</strong> - Pause-and-do (10): Complete the EDA checklist on a provided dataset and summarize 3 findings.<br>
- Pause-and-do (10): Create train/val/test splits and write 3 leakage risks specific to the dataset.</p>
<p><strong>Assessments</strong> - Concept quiz (auto-graded, 5–7 items): EDA, splits, leakage basics<br>
- Colab readiness check: submit Colab link with all cells executed</p>
<p><strong>Time budget (112.5 min)</strong> - Videos 54 + Notebook work 46 + Quiz 7.5 + Reflection 5 = 112.5</p>
<p><strong>Bibliography</strong> - ISLP: introductory material + Python lab basics (as assigned)<br>
- scikit-learn User Guide: cross-validation overview; common pitfalls and recommended practices<br>
- Kaggle Learn (optional): data leakage + train/test split discipline</p>
<hr>
</section>
</section>
<section id="day-2-wed-may-19" class="level2">
<h2 class="anchored" data-anchor-id="day-2-wed-may-19">Day 2 — Wed May 19</h2>
<section id="data-setup-and-preprocessing-pipelines-the-professional-way" class="level3">
<h3 class="anchored" data-anchor-id="data-setup-and-preprocessing-pipelines-the-professional-way">Data setup and preprocessing pipelines (the professional way)</h3>
<p><strong>Learning objectives</strong> - Audit data types and fix common pandas pitfalls (strings, categories, dates). - Handle missing values without leaking information. - Build a preprocessing + model Pipeline with <code>ColumnTransformer</code>. - Separate “fit on train only” logic from evaluation logic. - Use Gemini to draft pipeline code and then harden it (tests + comments).</p>
<p><strong>Micro-videos (54 min)</strong> 1. Concept+demo: pandas audit: types, missingness, duplicates (10)<br>
2. Guided practice: Write a minimal cleaning function (8)<br>
3. Solution: Cleaning solution + mistakes + extension: unit checks (9)<br>
4. Concept+demo: Pipelines + ColumnTransformer (numeric/categorical) (10)<br>
5. Guided practice: Build preprocessing pipeline (impute/encode/scale) (8)<br>
6. Solution: Pipeline debugging + extension: <code>get_feature_names_out()</code> (9)</p>
<p><strong>Notebook(s)</strong> - File: <code>02_preprocessing_pipelines.ipynb</code><br>
- Sections: - Setup + dataset load - Data audit report function - Train/val/test imports from Day 1 pattern - Pipeline template (numeric + categorical) - Gemini prompt cards for pipeline generation - Wrap-up: checklist for “pipeline done right”</p>
<p><strong>In-notebook exercises (10-minute scope)</strong> - Pause-and-do (10): Implement <code>make_data_report(df)</code> (types, missingness %, unique counts).<br>
- Pause-and-do (10): Create a full sklearn Pipeline and run one validation score.</p>
<p><strong>Assessments</strong> - Concept quiz: pipelines, fit/transform, leakage via preprocessing<br>
- Notebook checkpoint submission (Colab link)</p>
<p><strong>Time budget (112.5 min)</strong> - Videos 54 + Notebook 46 + Quiz 7.5 + Reflection 5 = 112.5</p>
<p><strong>Bibliography</strong> - scikit-learn User Guide: pipelines and composite estimators; ColumnTransformer; preprocessing<br>
- Pedregosa et al.&nbsp;(scikit-learn paper): estimator API conventions<br>
- ISLP Python labs: preprocessing patterns aligned to regression/classification</p>
<hr>
</section>
</section>
<section id="day-3-thu-may-20" class="level2">
<h2 class="anchored" data-anchor-id="day-3-thu-may-20">Day 3 — Thu May 20</h2>
<section id="trainvalidationtest-rigor-regression-metrics-baseline-modeling" class="level3">
<h3 class="anchored" data-anchor-id="trainvalidationtest-rigor-regression-metrics-baseline-modeling">Train/validation/test rigor + regression metrics + baseline modeling</h3>
<p><strong>Learning objectives</strong> - Choose regression metrics aligned to business loss (MAE vs RMSE). - Establish a baseline model and interpret it correctly. - Run holdout evaluation without contaminating the test set. - Use quick diagnostic plots to spot obvious modeling issues. - Document evaluation decisions (metric, split, baseline, assumptions).</p>
<p><strong>Micro-videos (54 min)</strong> 1. Concept+demo: Regression metrics (MAE/RMSE/R²) and when to use each (10)<br>
2. Guided practice: Compute metrics + baseline model (8)<br>
3. Solution: Metric interpretation + mistakes + extension: error distribution (9)<br>
4. Concept+demo: Holdout evaluation workflow + test set “lockbox” (10)<br>
5. Guided practice: Build baseline + compare to simple linear model (8)<br>
6. Solution: Comparison table + pitfalls + extension: residual plots (9)</p>
<p><strong>Notebook(s)</strong> - File: <code>03_regression_metrics_baselines.ipynb</code><br>
- Sections: - Metrics utilities (<code>mae</code>, <code>rmse</code>) - Baseline predictors (mean/median) - Holdout evaluation template - Residual plots and error summary table - Gemini prompts: “write a clean evaluation function” - Wrap-up: “test lockbox” discipline</p>
<p><strong>In-notebook exercises (10-minute scope)</strong> - Pause-and-do (10): Write <code>evaluate_regression(y_true, y_pred)</code> returning MAE/RMSE/R².<br>
- Pause-and-do (10): Compare baseline vs linear regression and interpret the delta.</p>
<p><strong>Assessments</strong> - Concept quiz: metrics, baselines, test lockbox<br>
- 3-sentence evaluation note (submitted in LMS)</p>
<p><strong>Time budget (112.5 min)</strong> - Videos 54 + Notebook 46 + Quiz 7.5 + Reflection 5 = 112.5</p>
<p><strong>Bibliography</strong> - ISLP: Model Assessment and Selection (holdout/validation/test discipline)<br>
- ESL: test error, training error, bias–variance, evaluation framing<br>
- scikit-learn User Guide: regression metrics and evaluation patterns</p>
<hr>
</section>
</section>
<section id="day-4-fri-may-21" class="level2">
<h2 class="anchored" data-anchor-id="day-4-fri-may-21">Day 4 — Fri May 21</h2>
<section id="linear-regression-that-actually-works-features-interactions-diagnostics" class="level3">
<h3 class="anchored" data-anchor-id="linear-regression-that-actually-works-features-interactions-diagnostics">Linear regression that actually works: features, interactions, diagnostics</h3>
<p><strong>Learning objectives</strong> - Fit and interpret linear regression in a pipeline. - Create interaction/polynomial features responsibly. - Diagnose underfit/overfit using validation results. - Use residual analysis to spot nonlinearity and heteroskedasticity. - Translate coefficients into business meaning (with caveats).</p>
<p><strong>Micro-videos (54 min)</strong> 1. Concept+demo: Linear regression in sklearn + coefficient interpretation (10)<br>
2. Guided practice: Fit baseline linear model with preprocessing (8)<br>
3. Solution: Interpretation + mistakes (leakage, scaling, encoding) + extension (9)<br>
4. Concept+demo: Interactions/polynomials + when they help (10)<br>
5. Guided practice: Add feature transforms and re-evaluate (8)<br>
6. Solution: Diagnostics + extension: compare MAE vs RMSE impacts (9)</p>
<p><strong>Notebook(s)</strong> - File: <code>04_linear_features_diagnostics.ipynb</code><br>
- Sections: - Pipeline baseline recap - Linear regression + coefficient extraction - Feature engineering (<code>PolynomialFeatures</code>, interactions) - Residual diagnostics and “what to try next” - Gemini prompts for feature engineering blocks</p>
<p><strong>In-notebook exercises (10-minute scope)</strong> - Pause-and-do (10): Add an interaction or polynomial block and measure validation change.<br>
- Pause-and-do (10): Write a short diagnostic conclusion (what error patterns suggest).</p>
<p><strong>Assessments</strong> - Concept quiz: linear regression, features, diagnostics<br>
- Notebook checkpoint submission (Colab link)</p>
<p><strong>Time budget (112.5 min)</strong> - Videos 54 + Notebook 46 + Quiz 7.5 + Reflection 5 = 112.5</p>
<p><strong>Bibliography</strong> - ISLP: Linear Regression (interpretation, interactions, diagnostics)<br>
- ESL: linear model treatment (bias–variance, residual structure)<br>
- scikit-learn User Guide: LinearRegression, PolynomialFeatures, pipeline patterns</p>
<hr>
</section>
</section>
<section id="day-5-mon-may-24" class="level2">
<h2 class="anchored" data-anchor-id="day-5-mon-may-24">Day 5 — Mon May 24</h2>
<section id="regularization-ridgelasso-project-proposal-sprint" class="level3">
<h3 class="anchored" data-anchor-id="regularization-ridgelasso-project-proposal-sprint">Regularization (Ridge/Lasso) + Project proposal sprint</h3>
<p><strong>Learning objectives</strong> - Explain why regularization improves generalization. - Fit Ridge/Lasso with proper scaling and CV selection. - Interpret coefficient shrinkage and sparsity. - Draft a project proposal with a viable dataset + target + metric + split plan. - Use Gemini to scaffold code and then add guardrails (checks + comments).</p>
<p><strong>Micro-videos (48 min)</strong> 1. Concept+demo: Ridge vs Lasso vs Elastic Net (intuition) (8)<br>
2. Guided practice: Standardize + fit Ridge with CV (7)<br>
3. Solution: CV results + mistakes + extension: coefficient paths (8)<br>
4. Concept+demo: Lasso for feature selection (what it can/can’t do) (8)<br>
5. Guided practice: Fit LassoCV + compare to Ridge (7)<br>
6. Solution: Model comparison + pitfalls + extension: stability discussion (10)</p>
<p><strong>Notebook(s)</strong> - File: <code>05_regularization_project_proposal.ipynb</code><br>
- Sections: - Regularization pipeline templates - CV selection (<code>RidgeCV</code>, <code>LassoCV</code>) - Comparison table (baseline vs linear vs ridge vs lasso) - Project proposal builder (prompted cells) - Gemini prompts: “write Ridge/Lasso pipeline + report table”</p>
<p><strong>In-notebook exercises (10-minute scope)</strong> - Pause-and-do (10): Run RidgeCV and summarize alpha choice + validation performance.<br>
- Pause-and-do (10): Run LassoCV and identify top selected features (if any).</p>
<p><strong>Assessments</strong> - Concept quiz: regularization + CV<br>
- <strong>Project Milestone 1 (due): Proposal + dataset selection</strong> - 1-page proposal + dataset link + target + metric + split plan + leakage risks</p>
<p><strong>Time budget (112.5 min)</strong> - Videos 48 + Notebook 47 + Quiz 7.5 + Project work 10 = 112.5</p>
<p><strong>Bibliography</strong> - ISLP: Linear Model Selection and Regularization (ridge/lasso/elastic net)<br>
- ESL: shrinkage and regularization theory<br>
- scikit-learn User Guide: Ridge/Lasso/ElasticNet and CV variants</p>
<hr>
</section>
</section>
</section>
<section id="week-2-days-610-classification-metrics-resampling-comparison-midterm" class="level1">
<h1>Week 2 (Days 6–10): Classification, Metrics, Resampling, Comparison + Midterm</h1>
<p><strong>Project milestone:</strong> Week 2 baseline due <strong>Day 10</strong><br>
<strong>Midterm:</strong> Day 10 business-case strategy practicum</p>
<hr>
<section id="day-6-tue-may-25" class="level2">
<h2 class="anchored" data-anchor-id="day-6-tue-may-25">Day 6 — Tue May 25</h2>
<section id="logistic-regression-probabilities-decision-boundaries-and-pipelines" class="level3">
<h3 class="anchored" data-anchor-id="logistic-regression-probabilities-decision-boundaries-and-pipelines">Logistic regression: probabilities, decision boundaries, and pipelines</h3>
<p><strong>Learning objectives</strong> - Fit logistic regression with preprocessing in a pipeline. - Interpret probabilities vs classes (and why thresholds matter). - Use regularization in logistic regression for stability. - Choose an appropriate baseline for classification. - Document the classification objective and error costs.</p>
<p><strong>Micro-videos (54 min)</strong> 1. Concept+demo: Logistic regression: log-odds → probabilities (10)<br>
2. Guided practice: Fit logistic baseline pipeline (8)<br>
3. Solution: Interpreting output + mistakes + extension: odds ratios (9)<br>
4. Concept+demo: Regularized logistic regression + why scaling matters (10)<br>
5. Guided practice: Tune <code>C</code> quickly (validation set) (8)<br>
6. Solution: Comparison + pitfalls + extension: coefficient stability (9)</p>
<p><strong>Notebook(s)</strong> - File: <code>06_logistic_pipelines.ipynb</code><br>
- Sections: - Classification baselines - Logistic regression pipeline - Probability outputs + thresholding intro - Gemini prompts for clean pipeline + reporting</p>
<p><strong>In-notebook exercises (10-minute scope)</strong> - Pause-and-do (10): Build logistic pipeline and compute validation accuracy + log loss.<br>
- Pause-and-do (10): Change threshold from 0.5 and observe metric shifts.</p>
<p><strong>Assessments</strong> - Concept quiz: logistic regression, probabilities, thresholds<br>
- Notebook checkpoint submission (Colab link)</p>
<p><strong>Time budget (112.5 min)</strong> - Videos 54 + Notebook 46 + Quiz 7.5 + Reflection 5 = 112.5</p>
<p><strong>Bibliography</strong> - ISLP: Classification (logistic regression fundamentals)<br>
- ESL: logistic regression/classification foundations<br>
- scikit-learn User Guide: LogisticRegression, probability outputs, regularization, pipelines</p>
<hr>
</section>
</section>
<section id="day-7-wed-may-26" class="level2">
<h2 class="anchored" data-anchor-id="day-7-wed-may-26">Day 7 — Wed May 26</h2>
<section id="classification-metrics-confusion-matrix-rocpr-calibration-and-business-costs" class="level3">
<h3 class="anchored" data-anchor-id="classification-metrics-confusion-matrix-rocpr-calibration-and-business-costs">Classification metrics: confusion matrix, ROC/PR, calibration, and business costs</h3>
<p><strong>Learning objectives</strong> - Compute and interpret precision, recall, F1, ROC-AUC, PR-AUC. - Select thresholds based on business cost tradeoffs. - Understand calibration and when it matters. - Handle class imbalance at the evaluation level (metrics first). - Produce a metrics dashboard table for model comparison.</p>
<p><strong>Micro-videos (54 min)</strong> 1. Concept+demo: Confusion matrix + precision/recall tradeoffs (10)<br>
2. Guided practice: Compute full metric set from predicted probabilities (8)<br>
3. Solution: Common metric mistakes + extension: PR curves for imbalance (9)<br>
4. Concept+demo: Thresholding via cost (expected cost framework) (10)<br>
5. Guided practice: Choose an “optimal” threshold for a given cost matrix (8)<br>
6. Solution: Cost-based thresholding + pitfalls + extension: calibration curves (9)</p>
<p><strong>Notebook(s)</strong> - File: <code>07_classification_metrics_thresholding.ipynb</code><br>
- Sections: - Metric functions + ROC/PR plotting - Threshold sweep table - Cost-based threshold selection - Optional: calibration plot preview</p>
<p><strong>In-notebook exercises (10-minute scope)</strong> - Pause-and-do (10): Build a threshold sweep and pick a threshold by business cost.<br>
- Pause-and-do (10): Explain why accuracy fails under imbalance (with evidence).</p>
<p><strong>Assessments</strong> - Concept quiz: metrics, ROC/PR, calibration concepts<br>
- Short deliverable: threshold recommendation (1 paragraph)</p>
<p><strong>Time budget (112.5 min)</strong> - Videos 54 + Notebook 46 + Quiz 7.5 + Reflection 5 = 112.5</p>
<p><strong>Bibliography</strong> - Fawcett: “An introduction to ROC analysis”<br>
- Saito &amp; Rehmsmeier: PR curves under class imbalance<br>
- scikit-learn User Guide: classification metrics + ROC/PR tooling<br>
- Optional calibration: Niculescu-Mizil &amp; Caruana; Zadrozny &amp; Elkan</p>
<hr>
</section>
</section>
<section id="day-8-thu-may-27" class="level2">
<h2 class="anchored" data-anchor-id="day-8-thu-may-27">Day 8 — Thu May 27</h2>
<section id="resampling-and-cv-how-to-compare-models-without-fooling-yourself" class="level3">
<h3 class="anchored" data-anchor-id="resampling-and-cv-how-to-compare-models-without-fooling-yourself">Resampling and CV: how to compare models without fooling yourself</h3>
<p><strong>Learning objectives</strong> - Run k-fold cross-validation for classification and regression. - Use stratified CV for classification. - Understand variance of performance estimates (why one split is fragile). - Compare models using consistent CV and a single primary metric. - Build a reusable CV evaluation function (project-ready).</p>
<p><strong>Micro-videos (54 min)</strong> 1. Concept+demo: Why CV exists (variance, stability, fair comparison) (10)<br>
2. Guided practice: Implement StratifiedKFold + cross_validate (8)<br>
3. Solution: CV summary + pitfalls + extension: repeated CV (9)<br>
4. Concept+demo: Model comparison under CV (what is “fair”) (10)<br>
5. Guided practice: Compare two pipelines with identical CV (8)<br>
6. Solution: Comparison table + extension: repeated runs for stability (9)</p>
<p><strong>Notebook(s)</strong> - File: <code>08_cross_validation_model_comparison.ipynb</code><br>
- Sections: - CV utilities (<code>cross_validate</code>, scoring) - StratifiedKFold template - Comparison report function (mean, std, runtime) - Gemini prompts for reusable <code>compare_models()</code></p>
<p><strong>In-notebook exercises (10-minute scope)</strong> - Pause-and-do (10): Write <code>cv_report(model, X, y, cv, scoring)</code> returning mean/std.<br>
- Pause-and-do (10): Compare logistic vs regularized logistic under the same CV.</p>
<p><strong>Assessments</strong> - Concept quiz: CV logic, stratification, comparison discipline<br>
- Notebook checkpoint submission</p>
<p><strong>Time budget (112.5 min)</strong> - Videos 54 + Notebook 46 + Quiz 7.5 + Reflection 5 = 112.5</p>
<p><strong>Bibliography</strong> - ISLP: Model Assessment and Selection (k-fold CV, resampling concepts)<br>
- ESL: resampling theory and selection bias<br>
- scikit-learn User Guide: cross-validation utilities and scoring</p>
<hr>
</section>
</section>
<section id="day-9-fri-may-28" class="level2">
<h2 class="anchored" data-anchor-id="day-9-fri-may-28">Day 9 — Fri May 28</h2>
<section id="feature-engineering-model-selection-workflow-and-project-baseline-build" class="level3">
<h3 class="anchored" data-anchor-id="feature-engineering-model-selection-workflow-and-project-baseline-build">Feature engineering + model selection workflow (and Project baseline build)</h3>
<p><strong>Learning objectives</strong> - Engineer features with pipelines without leakage. - Use <code>GridSearchCV</code> / <code>RandomizedSearchCV</code> for systematic tuning. - Define a project-grade evaluation plan (metric + split/CV + baseline + reporting). - Produce a baseline model notebook that can be extended. - Use Gemini to draft search grids and then simplify them.</p>
<p><strong>Micro-videos (48 min)</strong> 1. Concept+demo: Feature engineering inside pipelines (safe patterns) (8)<br>
2. Guided practice: Add engineered features and re-run CV (7)<br>
3. Solution: Results + mistakes + extension: ablation mindset (8)<br>
4. Concept+demo: Intro to GridSearchCV (what it really does) (8)<br>
5. Guided practice: Run a small grid and collect best params (7)<br>
6. Solution: Tuning pitfalls + extension: runtime controls (10)</p>
<p><strong>Notebook(s)</strong> - File: <code>09_tuning_feature_engineering_project_baseline.ipynb</code><br>
- Sections: - Pipeline + feature blocks - Minimal GridSearch template - Reporting: baseline vs tuned model table - Project baseline notebook scaffold (copy into project repo)</p>
<p><strong>In-notebook exercises (10-minute scope)</strong> - Pause-and-do (10): Build a small grid (2–3 params) and report best CV score.<br>
- Pause-and-do (10): Create a baseline report table suitable for the project.</p>
<p><strong>Assessments</strong> - Concept quiz: pipelines + tuning fundamentals<br>
- Project checkpoint: draft baseline notebook link</p>
<p><strong>Time budget (112.5 min)</strong> - Videos 48 + Notebook 47 + Quiz 7.5 + Project work 10 = 112.5</p>
<p><strong>Bibliography</strong> - ISLP Python labs: feature engineering examples aligned to course datasets<br>
- scikit-learn User Guide: grid search; randomized search; pipeline parameter tuning<br>
- Provost &amp; Fawcett: evaluation and business framing of predictive tasks</p>
<hr>
</section>
</section>
<section id="day-10-mon-may-31" class="level2">
<h2 class="anchored" data-anchor-id="day-10-mon-may-31">Day 10 — Mon May 31</h2>
<section id="midterm-business-case-predictive-strategy-practicum-project-baseline-submission" class="level3">
<h3 class="anchored" data-anchor-id="midterm-business-case-predictive-strategy-practicum-project-baseline-submission">Midterm: Business-case predictive strategy practicum + Project baseline submission</h3>
<p><strong>Learning objectives</strong> - Translate business cases into predictive tasks (target, unit, horizon, KPI). - Select split strategy and metrics aligned to case and cost structure. - Identify leakage risks and data availability constraints. - Propose a modeling shortlist and an evaluation plan. - Deliver a baseline model + evaluation plan for the course project.</p>
<p><strong>Micro-videos (30 min; 6×5 min)</strong> 1. Case 1 briefing + what a “good plan” looks like (5)<br>
2. Guided practice: Case 1 plan build instructions (5)<br>
3. Debrief: Case 1 rubric + common mistakes + extensions (5)<br>
4. Case 2 briefing + framing templates (5)<br>
5. Guided practice: Case 2 (and optional Case 3) execution checklist (5)<br>
6. Debrief: scoring rubric + pitfalls + “how to earn full credit” (5)</p>
<p><strong>Notebook(s)</strong> - File: <code>10_midterm_casebook.ipynb</code><br>
- Sections: - Integrity + allowed resources + Gemini usage boundaries (explain/verify) - Case 1 prompt + structured response cells - Case 2 prompt + structured response cells - Optional mini-case 3 - Submission checklist (self-audit)</p>
<p><strong>In-notebook exercises (10-minute scope)</strong> - Pause-and-do (10): Case 1 plan (split + metric + leakage risks + model shortlist).<br>
- Pause-and-do (10): Case 2 evaluation plan + error-cost logic.<br>
- Pause-and-do (10): Mini-case strategy under constraints.</p>
<p><strong>Assessments</strong> - <strong>Midterm submission (graded):</strong> completed notebook (strategy + minimal prototype code where requested)<br>
- <strong>Project Milestone 2 (due): Baseline model + evaluation plan</strong> - baseline pipeline + metric + split/CV design + baseline report table</p>
<p><strong>Time budget (112.5 min)</strong> - Videos 30 + Midterm notebook work 60 + Project baseline finalization 15 + Concept check 7.5 = 112.5</p>
<p><strong>Bibliography</strong> - Provost &amp; Fawcett: end-to-end predictive modeling process and business framing<br>
- ISLP: assessment/selection + classification/regression chapters as reference<br>
- scikit-learn User Guide: common pitfalls (especially leakage and improper evaluation)</p>
<hr>
</section>
</section>
</section>
<section id="week-3-days-1115-trees-ensembles-tuning-interpretation" class="level1">
<h1>Week 3 (Days 11–15): Trees, Ensembles, Tuning, Interpretation</h1>
<p><strong>Project milestone:</strong> Week 3 improved model due <strong>Day 15</strong></p>
<hr>
<section id="day-11-tue-june-1" class="level2">
<h2 class="anchored" data-anchor-id="day-11-tue-june-1">Day 11 — Tue June 1</h2>
<section id="decision-trees-interpretable-models-with-sharp-edges" class="level3">
<h3 class="anchored" data-anchor-id="decision-trees-interpretable-models-with-sharp-edges">Decision trees: interpretable models with sharp edges</h3>
<p><strong>Learning objectives</strong> - Fit decision trees for regression/classification. - Control complexity (depth, min samples) to manage overfitting. - Interpret tree structure and failure modes. - Compare tree vs linear/logistic baselines under CV. - Document “when a tree is the right tool.”</p>
<p><strong>Micro-videos (54 min)</strong> 1. Concept+demo: Trees intuition + key hyperparameters (10)<br>
2. Guided practice: Fit a tree + visualize + baseline compare (8)<br>
3. Solution: Overfitting patterns + mistakes + extension: cost-complexity pruning (9)<br>
4. Concept+demo: Tree evaluation under CV + stability concerns (10)<br>
5. Guided practice: Small grid over depth/min_samples (8)<br>
6. Solution: Tuning result + extension: sensitivity analysis (9)</p>
<p><strong>Notebook(s)</strong> - File: <code>11_decision_trees.ipynb</code><br>
- Sections: - Tree fit + visualization - Hyperparameter effects (depth sweep) - CV comparison table - Gemini prompts: “generate a clean depth sweep block”</p>
<p><strong>In-notebook exercises (10-minute scope)</strong> - Pause-and-do (10): Run a depth sweep and choose depth based on CV.<br>
- Pause-and-do (10): Write 3 observed tree failure modes (with evidence).</p>
<p><strong>Assessments</strong> - Concept quiz: tree mechanics + overfitting<br>
- Notebook checkpoint submission</p>
<p><strong>Time budget (112.5 min)</strong> - Videos 54 + Notebook 46 + Quiz 7.5 + Reflection 5 = 112.5</p>
<p><strong>Bibliography</strong> - ISLP: Tree-Based Methods (trees, pruning)<br>
- ESL: CART foundations and complexity control<br>
- scikit-learn User Guide: DecisionTreeClassifier/Regressor parameters and inspection tools</p>
<hr>
</section>
</section>
<section id="day-12-wed-june-2" class="level2">
<h2 class="anchored" data-anchor-id="day-12-wed-june-2">Day 12 — Wed June 2</h2>
<section id="random-forests-bagging-oob-intuition-and-feature-importance" class="level3">
<h3 class="anchored" data-anchor-id="random-forests-bagging-oob-intuition-and-feature-importance">Random forests: bagging, OOB intuition, and feature importance</h3>
<p><strong>Learning objectives</strong> - Explain bagging and why forests reduce variance. - Train a random forest and tune the most impactful knobs. - Use permutation importance responsibly. - Compare forest vs tree vs linear/logistic baselines. - Produce project-ready model comparison tables.</p>
<p><strong>Micro-videos (54 min)</strong> 1. Concept+demo: Bagging → random forests (why it works) (10)<br>
2. Guided practice: Fit a forest + baseline compare (8)<br>
3. Solution: Mistakes + extension: OOB vs CV discussion (9)<br>
4. Concept+demo: Permutation importance (what it means / doesn’t) (10)<br>
5. Guided practice: Compute importance + sanity checks (8)<br>
6. Solution: Interpretation pitfalls + extension: grouped features (9)</p>
<p><strong>Notebook(s)</strong> - File: <code>12_random_forests_importance.ipynb</code><br>
- Sections: - Forest training + CV comparison - Permutation importance + plot - Reporting template (model table + narrative bullets) - Gemini prompts: “importance + report block”</p>
<p><strong>In-notebook exercises (10-minute scope)</strong> - Pause-and-do (10): Tune <code>n_estimators</code> and <code>max_features</code> minimally and report effects.<br>
- Pause-and-do (10): Compute permutation importance and write 3 interpretation bullets.</p>
<p><strong>Assessments</strong> - Concept quiz: bagging/forests + importance<br>
- Notebook checkpoint submission</p>
<p><strong>Time budget (112.5 min)</strong> - Videos 54 + Notebook 46 + Quiz 7.5 + Reflection 5 = 112.5</p>
<p><strong>Bibliography</strong> - Breiman: “Random Forests”<br>
- ISLP: Tree-Based Methods (bagging/forests)<br>
- scikit-learn User Guide: RandomForest estimators; permutation importance and caveats</p>
<hr>
</section>
</section>
<section id="day-13-thu-june-3" class="level2">
<h2 class="anchored" data-anchor-id="day-13-thu-june-3">Day 13 — Thu June 3</h2>
<section id="gradient-boosting-performance-with-discipline-and-leakage-avoidance" class="level3">
<h3 class="anchored" data-anchor-id="gradient-boosting-performance-with-discipline-and-leakage-avoidance">Gradient boosting: performance with discipline (and leakage avoidance)</h3>
<p><strong>Learning objectives</strong> - Explain boosting vs bagging at a high level. - Train a gradient boosting model with sensible defaults. - Tune learning rate / depth / estimators with runtime controls. - Compare boosted model vs forest under consistent CV. - Identify and control overfitting in boosting.</p>
<p><strong>Micro-videos (54 min)</strong> 1. Concept+demo: Boosting intuition + bias/variance lens (10)<br>
2. Guided practice: Fit a baseline boosting model (8)<br>
3. Solution: Common pitfalls + extension: learning rate tradeoff (9)<br>
4. Concept+demo: Tuning boosting (small, smart grids) (10)<br>
5. Guided practice: Run a constrained randomized search (8)<br>
6. Solution: Result interpretation + extension: stability notes (9)</p>
<p><strong>Notebook(s)</strong> - File: <code>13_gradient_boosting.ipynb</code><br>
- Sections: - Baseline GBM fit - Constrained tuning template - Comparison report (forest vs GBM) - Gemini prompts: constrained RandomizedSearchCV with guardrails</p>
<p><strong>In-notebook exercises (10-minute scope)</strong> - Pause-and-do (10): Train baseline GBM and compare against RF under CV.<br>
- Pause-and-do (10): Run constrained tuning and report best params + score.</p>
<p><strong>Assessments</strong> - Concept quiz: boosting, tuning tradeoffs<br>
- Notebook checkpoint submission</p>
<p><strong>Time budget (112.5 min)</strong> - Videos 54 + Notebook 46 + Quiz 7.5 + Reflection 5 = 112.5</p>
<p><strong>Bibliography</strong> - Friedman: “Greedy Function Approximation: A Gradient Boosting Machine”<br>
- ISLP: Tree-Based Methods (boosting overview)<br>
- scikit-learn User Guide: gradient boosting estimators and tuning guidance</p>
<hr>
</section>
</section>
<section id="day-14-fri-june-4" class="level2">
<h2 class="anchored" data-anchor-id="day-14-fri-june-4">Day 14 — Fri June 4</h2>
<section id="model-selection-and-comparison-making-the-call-like-a-professional" class="level3">
<h3 class="anchored" data-anchor-id="model-selection-and-comparison-making-the-call-like-a-professional">Model selection and comparison: making the call like a professional</h3>
<p><strong>Learning objectives</strong> - Build a standardized model comparison workflow (same CV, same metric). - Use multiple metrics without “metric shopping.” - Select a champion model and justify it (performance, stability, interpretability, cost). - Create a reproducible experiment log table. - Prepare project improved-model plan for submission.</p>
<p><strong>Micro-videos (54 min)</strong> 1. Concept+demo: Comparison protocol (what must be held constant) (10)<br>
2. Guided practice: Build a comparison harness (3 models, 1 function) (8)<br>
3. Solution: Harness review + mistakes + extension: runtime tracking (9)<br>
4. Concept+demo: Selecting a champion (beyond top score) (10)<br>
5. Guided practice: Write a decision memo from results (8)<br>
6. Solution: Decision memo example + extension: robustness checks (9)</p>
<p><strong>Notebook(s)</strong> - File: <code>14_model_selection_protocol.ipynb</code><br>
- Sections: - Comparison harness (pipelines list → CV scores table) - Multi-metric reporting (primary + supporting metrics) - Champion selection memo scaffold - Gemini prompts: “generate experiment log table”</p>
<p><strong>In-notebook exercises (10-minute scope)</strong> - Pause-and-do (10): Implement the comparison harness for 3 candidate models.<br>
- Pause-and-do (10): Write a champion selection memo (5 bullets + 1 risk).</p>
<p><strong>Assessments</strong> - Concept quiz: selection protocol + robustness<br>
- Notebook checkpoint submission</p>
<p><strong>Time budget (112.5 min)</strong> - Videos 54 + Notebook 46 + Quiz 7.5 + Reflection 5 = 112.5</p>
<p><strong>Bibliography</strong> - ISLP: Model Assessment and Selection (protocols for fair comparison)<br>
- ESL: selection bias and repeated peeking hazards<br>
- scikit-learn User Guide: model evaluation + parameter tuning best practices</p>
<hr>
</section>
</section>
<section id="day-15-mon-june-7" class="level2">
<h2 class="anchored" data-anchor-id="day-15-mon-june-7">Day 15 — Mon June 7</h2>
<section id="interpretation-feature-importance-partial-dependence-project-improved-model-delivery" class="level3">
<h3 class="anchored" data-anchor-id="interpretation-feature-importance-partial-dependence-project-improved-model-delivery">Interpretation: feature importance + partial dependence + project improved model delivery</h3>
<p><strong>Learning objectives</strong> - Generate model interpretation artifacts (permutation importance, PDP/ICE). - Conduct error analysis to find systematic failure segments. - Communicate model behavior honestly (limits, caveats, instability). - Deliver a project improved model with interpretation and error analysis. - Use Gemini to draft explanation text, then tighten it to evidence.</p>
<p><strong>Micro-videos (48 min)</strong> 1. Concept+demo: Interpretation toolkit overview (importance vs PDP) (8)<br>
2. Guided practice: Compute permutation importance for your champion (7)<br>
3. Solution: Interpretation pitfalls + extension: correlated features (8)<br>
4. Concept+demo: Partial dependence + what it can mislead (8)<br>
5. Guided practice: Create PDP/ICE + do segment error analysis (7)<br>
6. Solution: Error analysis patterns + extension: calibration check (10)</p>
<p><strong>Notebook(s)</strong> - File: <code>15_interpretation_error_analysis_project.ipynb</code><br>
- Sections: - Importance + PDP/ICE - Segment-level error table (by key categorical / quantile bins) - Interpretation narrative template (evidence-based) - Project Milestone 3 scaffold</p>
<p><strong>In-notebook exercises (10-minute scope)</strong> - Pause-and-do (10): Create permutation importance and write 3 evidence-based bullets.<br>
- Pause-and-do (10): Run segment error analysis and identify one failure segment.</p>
<p><strong>Assessments</strong> - Concept quiz: interpretation + PDP caveats<br>
- <strong>Project Milestone 3 (due): Improved model + interpretation</strong> - updated comparison, champion choice, importance + PDP/ICE, error segment findings</p>
<p><strong>Time budget (112.5 min)</strong> - Videos 48 + Notebook 47 + Quiz 7.5 + Project work 10 = 112.5</p>
<p><strong>Bibliography</strong> - scikit-learn User Guide: inspection tools (permutation importance, partial dependence)<br>
- Molnar (optional): <em>Interpretable Machine Learning</em> (global/local methods and caveats)<br>
- ISLP: interpretation discussions across linear and tree-based methods</p>
<hr>
</section>
</section>
</section>
<section id="week-4-days-1620-error-analysis-fairnessethics-deployment-thinking-executive-narrative-final-project" class="level1">
<h1>Week 4 (Days 16–20): Error Analysis, Fairness/Ethics, Deployment Thinking, Executive Narrative, Final Project</h1>
<p><strong>Project milestone:</strong> Week 4 final deliverable due <strong>Day 20</strong></p>
<hr>
<section id="day-16-tue-june-8" class="level2">
<h2 class="anchored" data-anchor-id="day-16-tue-june-8">Day 16 — Tue June 8</h2>
<section id="error-analysis-to-decisions-thresholds-calibration-and-kpi-alignment" class="level3">
<h3 class="anchored" data-anchor-id="error-analysis-to-decisions-thresholds-calibration-and-kpi-alignment">Error analysis to decisions: thresholds, calibration, and KPI alignment</h3>
<p><strong>Learning objectives</strong> - Translate model outputs into business decisions (thresholds, costs, constraints). - Evaluate calibration and when to calibrate probabilities. - Compare models by decision impact, not only by AUC/accuracy. - Produce a threshold/decision recommendation. - Document risks and assumptions explicitly.</p>
<p><strong>Micro-videos (54 min)</strong> 1. Concept+demo: From prediction to action (thresholds and costs) (10)<br>
2. Guided practice: Threshold sweep with expected cost (8)<br>
3. Solution: Choosing thresholds + mistakes + extension: sensitivity analysis (9)<br>
4. Concept+demo: Calibration intuition + reliability plots (10)<br>
5. Guided practice: Calibrate and compare decision impact (8)<br>
6. Solution: Calibration pitfalls + extension: decision policy reporting (9)</p>
<p><strong>Notebook(s)</strong> - File: <code>16_decision_thresholds_calibration.ipynb</code><br>
- Sections: - Cost matrix + expected cost computation - Threshold sweep dashboard - Calibration plot + optional calibration model - Decision policy summary block (ready for slides)</p>
<p><strong>In-notebook exercises (10-minute scope)</strong> - Pause-and-do (10): Select a threshold that minimizes expected cost and justify it.<br>
- Pause-and-do (10): Check calibration and decide whether calibration is needed.</p>
<p><strong>Assessments</strong> - Concept quiz: thresholds, calibration, decision impact<br>
- Short deliverable: decision policy paragraph (for project slides)</p>
<p><strong>Time budget (112.5 min)</strong> - Videos 54 + Notebook 46 + Quiz 7.5 + Reflection 5 = 112.5</p>
<p><strong>Bibliography</strong> - Provost &amp; Fawcett: decision-making with predictions and cost alignment<br>
- scikit-learn User Guide: thresholding and calibration tooling<br>
- Optional calibration: Niculescu-Mizil &amp; Caruana; Zadrozny &amp; Elkan</p>
<hr>
</section>
</section>
<section id="day-17-wed-june-9" class="level2">
<h2 class="anchored" data-anchor-id="day-17-wed-june-9">Day 17 — Wed June 9</h2>
<section id="fairness-and-ethics-basics-responsible-predictive-analytics-minimum-viable-rigor" class="level3">
<h3 class="anchored" data-anchor-id="fairness-and-ethics-basics-responsible-predictive-analytics-minimum-viable-rigor">Fairness and ethics basics: responsible predictive analytics (minimum viable rigor)</h3>
<p><strong>Learning objectives</strong> - Identify fairness risks and ethical failure modes in predictive systems. - Compute basic group fairness diagnostics (when sensitive attributes exist). - Use slicing to detect performance disparities across segments. - Write a model card-style limitations and responsible-use section. - Apply responsible AI framing to the course project deliverable.</p>
<p><strong>Micro-videos (54 min)</strong> 1. Concept+demo: Fairness vocabulary (disparity, harm, proxies, feedback loops) (10)<br>
2. Guided practice: Set up group slicing evaluation (8)<br>
3. Solution: Slicing report + mistakes + extension: intersectional slices (9)<br>
4. Concept+demo: Fairness metrics (selection rate, TPR/FPR gaps) + caution (10)<br>
5. Guided practice: Compute basic fairness diagnostics (8)<br>
6. Solution: Interpretation + what not to claim + extension: mitigation options (9)</p>
<p><strong>Notebook(s)</strong> - File: <code>17_fairness_slicing_model_cards.ipynb</code><br>
- Sections: - Slice-based performance table - Optional fairness metrics (dataset permitting) - Model card template: intended use, limitations, risks, monitoring - Gemini prompts for drafting text + evidence-tightening checklist</p>
<p><strong>In-notebook exercises (10-minute scope)</strong> - Pause-and-do (10): Create slice performance table and highlight one disparity (if any).<br>
- Pause-and-do (10): Draft a model card limitations section (6–8 lines).</p>
<p><strong>Assessments</strong> - Concept quiz: fairness basics, responsible communication<br>
- Upload model card draft text (project-ready)</p>
<p><strong>Time budget (112.5 min)</strong> - Videos 54 + Notebook 46 + Quiz 7.5 + Reflection 5 = 112.5</p>
<p><strong>Bibliography</strong> - Barocas, Hardt, Narayanan: <em>Fairness and Machine Learning</em><br>
- Hardt, Price, Srebro: Equality of Opportunity<br>
- Mitchell et al.: Model Cards for Model Reporting<br>
- Optional: Chouldechova (fair prediction with disparate impact)</p>
<hr>
</section>
</section>
<section id="day-18-thu-june-10" class="level2">
<h2 class="anchored" data-anchor-id="day-18-thu-june-10">Day 18 — Thu June 10</h2>
<section id="deployment-thinking-reproducibility-monitoring-drift-and-dont-ship-a-notebook" class="level3">
<h3 class="anchored" data-anchor-id="deployment-thinking-reproducibility-monitoring-drift-and-dont-ship-a-notebook">Deployment thinking: reproducibility, monitoring, drift, and “don’t ship a notebook”</h3>
<p><strong>Learning objectives</strong> - Package a model pipeline reproducibly (single function, fixed preprocessing). - Save/load model artifacts and ensure consistent inference. - Define monitoring signals (data drift, performance drift, calibration drift). - Create a minimal production checklist and risk log. - Prepare the project notebook for executive-facing reproducibility.</p>
<p><strong>Micro-videos (54 min)</strong> 1. Concept+demo: Reproducible pipelines (fit once, run anywhere) (10)<br>
2. Guided practice: Refactor notebook into functions + config block (8)<br>
3. Solution: Refactor review + extension: experiment config (9)<br>
4. Concept+demo: Monitoring + drift (what to watch and why) (10)<br>
5. Guided practice: Create monitoring checklist + drift proxies (8)<br>
6. Solution: Monitoring plan + mistakes + extension: governance (9)</p>
<p><strong>Notebook(s)</strong> - File: <code>18_reproducibility_monitoring.ipynb</code><br>
- Sections: - Refactor into <code>train()</code> / <code>predict()</code> / <code>evaluate()</code> - Save/load via joblib - Monitoring plan template (tables) - “Ready-to-share” notebook hygiene checklist</p>
<p><strong>In-notebook exercises (10-minute scope)</strong> - Pause-and-do (10): Implement <code>train_model(config)</code> returning pipeline + metrics.<br>
- Pause-and-do (10): Draft a monitoring plan with 5–8 signals and owners.</p>
<p><strong>Assessments</strong> - Concept quiz: reproducibility + drift<br>
- Notebook checkpoint submission</p>
<p><strong>Time budget (112.5 min)</strong> - Videos 54 + Notebook 46 + Quiz 7.5 + Reflection 5 = 112.5</p>
<p><strong>Bibliography</strong> - Chip Huyen: <em>Designing Machine Learning Systems</em><br>
- Optional: <em>Machine Learning Design Patterns</em> (Lakshmanan et al.)<br>
- Optional: <em>Dataset Shift in Machine Learning</em> (Quionero-Candela et al.)<br>
- Rabanser, Günnemann, Lipton: dataset shift detection (Failing Loudly)<br>
- scikit-learn User Guide: model persistence and reproducible pipelines</p>
<hr>
</section>
</section>
<section id="day-19-fri-june-11" class="level2">
<h2 class="anchored" data-anchor-id="day-19-fri-june-11">Day 19 — Fri June 11</h2>
<section id="executive-narrative-slide-style-story-conference-video-plan-project-studio" class="level3">
<h3 class="anchored" data-anchor-id="executive-narrative-slide-style-story-conference-video-plan-project-studio">Executive narrative: slide-style story + conference video plan (project studio)</h3>
<p><strong>Learning objectives</strong> - Convert technical work into an executive-ready slide narrative. - Build a clear “problem → approach → results → recommendation → risks” flow. - Create credible visuals (comparison table, key plots, decision policy). - Script a short conference video (tight, evidence-based, non-technical). - Finalize the project deliverable package.</p>
<p><strong>Micro-videos (42 min)</strong> 1. Concept+demo: Executive narrative structure (1-slide-per-idea) (7)<br>
2. Guided practice: Storyboard your deck (10-slide target) (6)<br>
3. Solution: Storyboard example + mistakes + extension: stakeholder tailoring (7)<br>
4. Concept+demo: What visuals to include (and what to avoid) (7)<br>
5. Guided practice: Draft speaker script + timing plan (6)<br>
6. Solution: Script tightening + extension: Q&amp;A slide and limitations (9)</p>
<p><strong>Notebook(s)</strong> - File: <code>19_project_narrative_video_studio.ipynb</code><br>
- Sections: - Slide outline template (markdown → slides) - Required visuals checklist - Script template (time-coded) - Gemini prompts: tighten script; convert findings to executive bullets</p>
<p><strong>In-notebook exercises (10-minute scope)</strong> - Pause-and-do (10): Create a 10-slide outline (titles + 2 bullets each).<br>
- Pause-and-do (10): Write a 2–3 minute script aligned to the outline.</p>
<p><strong>Assessments</strong> - Concept quiz: executive communication and evidence discipline<br>
- Project checkpoint: draft slide outline + script (links)</p>
<p><strong>Time budget (112.5 min)</strong> - Videos 42 + Notebook 45 + Quiz 7.5 + Project studio 18 = 112.5</p>
<p><strong>Bibliography</strong> - Cole Nussbaumer Knaflic: <em>Storytelling with Data</em><br>
- Barbara Minto: <em>The Pyramid Principle</em><br>
- Provost &amp; Fawcett: communicating results to stakeholders (framing and impact)</p>
<hr>
</section>
</section>
<section id="day-20-mon-june-14" class="level2">
<h2 class="anchored" data-anchor-id="day-20-mon-june-14">Day 20 — Mon June 14</h2>
<section id="final-delivery-project-package-submission-peer-review-course-closeout" class="level3">
<h3 class="anchored" data-anchor-id="final-delivery-project-package-submission-peer-review-course-closeout">Final delivery: project package submission + peer review + course closeout</h3>
<p><strong>Learning objectives</strong> - Deliver a complete end-to-end predictive analytics package. - Produce an executive-ready deck and a conference-style video. - Demonstrate reproducibility (run-all notebook, documented choices). - Evaluate peers’ work using a structured rubric and provide actionable feedback. - Write a concise postmortem: what worked, what didn’t, what you’d do next.</p>
<p><strong>Micro-videos (30 min; 6×5 min)</strong> 1. Final submission checklist (what graders check first) (5)<br>
2. Guided practice: Run-all reproducibility audit (5)<br>
3. Solution: Common submission failures + prevention (5)<br>
4. Peer review rubric (how to be useful, not nice) (5)<br>
5. Guided practice: High-signal feedback in 5 minutes (5)<br>
6. Solution: Example peer review + extension: next-iteration roadmap (5)</p>
<p><strong>Notebook(s)</strong> - File: <code>20_final_submission_peer_review.ipynb</code><br>
- Sections: - Final self-audit checklist (run-all, outputs, links) - Submission links + artifact manifest (notebook, deck, video) - Peer review form (rubric + comment prompts) - Postmortem prompts (8–10 lines)</p>
<p><strong>In-notebook exercises (10-minute scope)</strong> - Pause-and-do (10): Run-all audit and fix one reproducibility issue (real or simulated).<br>
- Pause-and-do (10): Complete one peer review with rubric scores + 3 actionable edits.</p>
<p><strong>Assessments</strong> - <strong>Project Milestone 4 (due): Final model + executive-ready deliverable</strong> - Final run-all notebook + model card/limitations + monitoring plan<br>
- Slide narrative (deck or slide markdown)<br>
- Conference-style video<br>
- Peer review submission (graded for quality)<br>
- Final concept quiz (course wrap)</p>
<p><strong>Time budget (112.5 min)</strong> - Videos 30 + Final submission notebook work 55 + Peer review 20 + Wrap quiz 7.5 = 112.5</p>
<p><strong>Bibliography</strong> - Mitchell et al.: Model Cards (responsible reporting alignment)<br>
- Chip Huyen: deployment checklists and monitoring as product handoff<br>
- Storytelling with Data / Pyramid Principle: narrative polish and reviewer-friendly structure</p>
<hr>
</section>
</section>
</section>
<section id="project-bibliography-applies-across-all-milestones" class="level1">
<h1>Project bibliography (applies across all milestones)</h1>
<ul>
<li>Provost &amp; Fawcett: <em>Data Science for Business</em> (problem framing, value, evaluation)</li>
<li>ISLP + Python labs (modeling, resampling, interpretation foundations)</li>
<li>scikit-learn User Guide (pipelines, tuning, metrics, inspection)</li>
<li>Mitchell et al.&nbsp;(Model Cards) + Barocas/Hardt/Narayanan (Fairness and ML) for limitations, risks, and responsible-use language</li>
<li>Chip Huyen: <em>Designing Machine Learning Systems</em> (monitoring and deployment thinking)</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>