<!DOCTYPE html>
<html lang="en"><head>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.25">

  <meta name="author" content="Professor: Davi Moreira">
  <title>MGMT 47400: Predictive Analytics (Summer 2026 - 4-Week Intensive) –  MGMT 47400: Predictive Analytics </title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-96a67a1340eb436771fd03060be7db16.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title"><span style="font-size: 100%;"> MGMT 47400: Predictive Analytics </span></h1>
  <p class="subtitle"><span style="font-size: 150%;"> Syllabus, Logistics, and Introduction</span></p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Professor: Davi Moreira 
</div>
</div>
</div>

</section>
<section>
<section id="welcome" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Welcome!</h1>

</section>
<section id="overview" class="slide level2 center">
<h2>Overview</h2>
<div class="columns">
<div class="column" style="text-align: center; justify-content: center; align-items: center;">
<ul>
<li>Introductions</li>
<li>Course Overview and Logistics</li>
<li>Motivation</li>
<li>Course Objectives</li>
</ul>
</div><div class="column" style="text-align: center; justify-content: center; align-items: center;">
<ul>
<li><p>Supervised Learning</p></li>
<li><p>Unsupervised Learning</p></li>
<li><p>Statistical Learning Overview</p>
<ul>
<li>What is Statistical Learning?</li>
<li>Parametric and Structured Models</li>
<li>Assessing Model Accuracy</li>
<li>Classification Problems</li>
</ul></li>
</ul>
</div></div>
<p><br></p>
<p><em>This lecture content is inspired by and replicates the material from <a href="https://www.statlearning.com/">An Introduction to Statistical Learning</a>.</em></p>
</section></section>
<section>
<section id="introductions" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Introductions</h1>

</section>
<section id="instructor" class="slide level2 center">
<h2>Instructor</h2>
<div class="columns">
<div class="column" style="text-align: center; justify-content: center; align-items: center;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/davi_moreira_photo.JPG" class="quarto-figure quarto-figure-center" style="width:60.0%"></p>
</figure>
</div>
</div>
</div>
<p><a href="dmoreira@purdue.edu">dmoreira@purdue.edu</a></p>
<p><a href="https://davi-moreira.github.io/" class="uri">https://davi-moreira.github.io/</a></p>
</div><div class="column" style="text-align: center; justify-content: center; align-items: center;">
<ul>
<li class="fragment">Clinical Assistant Professor in the Quantitative Methods Department at the Mitch. Daniels School of Business at Purdue University;</li>
</ul>
<p><br></p>
<ul>
<li class="fragment">My academic work addresses Political Communication, Data Science, Text as Data, Artificial Intelligence, and Comparative Politics.</li>
</ul>
<p><br></p>
<ul>
<li class="fragment"><a href="https://blogs.worldbank.org/opendata/improving-how-we-measure-progress-community-biodiversity-conservation-projects-mozambique">M&amp;E Specialist consultant - World Bank (Brazil, Mozambique, Angola, and DRC)</a></li>
</ul>
</div></div>
</section>
<section id="instructors-passions" class="slide level2 center">
<h2>Instructor’s Passions</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/palmeiras_logo.png" class="quarto-figure quarto-figure-center" style="width:17.0%"></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/palmeiras_stadium.jpg" class="quarto-figure quarto-figure-center" style="width:40.0%"></p>
</figure>
</div>
</div>
</div>
<center>
<div style="font-size: 80%;">
<p><a href="https://www.youtube.com/watch?v=FCebgeX_3hI&amp;t=89s">The Most Exciting Game in History - Video</a></p>
</div>
</center>
<p><br> <br></p>
</section>
<section id="instructors-passions-1" class="slide level2 center">
<h2>Instructor’s Passions</h2>

<img data-src="figs/carnaval_olinda.jpg" class="quarto-figure quarto-figure-center r-stretch" style="width:25.0%"><center>
<a href="https://www.nytimes.com/2024/02/13/world/americas/brazil-carnival-john-travolta.html">NYT - How John Travolta Became the Star of Carnival</a><a href="https://www.nytimes.com/video/world/americas/100000009311331/the-star-of-this-carnival-is-a-giant-john-travolta-puppet.html?auth=login-google1tap&amp;login=google1tap">-Video.</a>
</center>
<p><br></p>
</section>
<section id="students" class="slide level2 center">
<h2>Students</h2>
<p><br></p>
<center>
<strong>What do you expect to gain from this Predictive Analytics course?</strong>
</center>
<p><br></p>
<ul>
<li class="fragment"><p>It is your turn! - 10 minutes</p></li>
<li class="fragment"><p>Present yourself to your left/right colleague and ask:</p></li>
<li class="fragment"><p>Collect her/his answer and submit your first Participation Assignment!</p></li>
</ul>
</section></section>
<section>
<section id="course-overview-and-logistics" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Course Overview and Logistics</h1>

</section>
<section id="course-overview-and-logistics-1" class="slide level2 center">
<h2>Course Overview and Logistics</h2>
<div style="font-size: 80%;">
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li class="fragment"><strong>Course Info</strong>:
<ul>
<li class="fragment">Brightspace - Official.</li>
<li class="fragment"><a href="https://davi-moreira.github.io/2025F_predictive_analytics_purdue_MGMT474/" target="_blank">Course Webpage - Supplementary.</a></li>
</ul></li>
<li class="fragment"><a href="https://davi-moreira.github.io/2025F_predictive_analytics_purdue_MGMT474/" target="_blank"><strong>Syllabus</strong></a>
<ul>
<li class="fragment"><strong>Class Times &amp; Location:</strong> check the course syllabus.<br>
</li>
<li class="fragment"><strong>Office Hours:</strong> check the course syllabus for group and individual appointments.</li>
</ul></li>
<li class="fragment"><a href="https://davi-moreira.github.io/2025F_predictive_analytics_purdue_MGMT474/schedule.html" target="_blank"><strong>Schedule and Materials</strong></a>:
<ul>
<li class="fragment">Podcast (before class)<br>
</li>
<li class="fragment">Required Readings (before class)<br>
</li>
<li class="fragment">Lecture Slides (before class)<br>
</li>
<li class="fragment">Lecture Video (during class)<br>
</li>
<li class="fragment">Book labs (during/after class)<br>
</li>
<li class="fragment">Supplementary Material (after class)</li>
</ul></li>
</ul>
</div><div class="column" style="width:50%;">
<ul>
<li class="fragment"><strong>Course Tracks</strong>
<ul>
<li class="fragment">Standard Track<br>
</li>
<li class="fragment">External Case Competition (bonus)</li>
</ul></li>
<li class="fragment"><strong>Assessments</strong>
<ul>
<li class="fragment">Attendance<br>
</li>
<li class="fragment">Participation<br>
</li>
<li class="fragment">Quizzes<br>
</li>
<li class="fragment">Homework<br>
</li>
<li class="fragment">Course Case Competition<br>
</li>
<li class="fragment">Final Project</li>
</ul></li>
</ul>
</div></div>
</div>
</section></section>
<section>
<section id="motivation" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Motivation</h1>
<!---

## Statistical Learning Problems

- **Identify the risk factors for prostate cancer.**

- Classify a recorded phoneme based on a log-periodogram.

- Predict whether someone will have a heart attack on the basis of demographic, diet, and clinical measurements.

- Customize an email spam detection system.

- Identify the numbers in a handwritten zip code.

- Classify a tissue sample into one of several cancer classes, based on a gene expression profile.

- Establish the relationship between salary and demographic variables in population survey data.

- Classify the pixels in a LANDSAT image, by usage.

--->
</section>
<section id="spam-detection" class="slide level2 center">
<h2>Spam Detection</h2>
<div style="font-size: 80%;">
<ul>
<li>Data from 4601 emails sent to an individual (named George, at HP Labs, before 2000). Each is labeled as <em>spam</em> or <em>email</em>.</li>
<li>Goal: build a customized spam filter.</li>
<li>Input features: relative frequencies of 57 of the most commonly occurring words and punctuation marks in these email messages.</li>
</ul>
<table class="caption-top">
<thead>
<tr class="header">
<th>Word</th>
<th>Spam</th>
<th>Email</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>george</td>
<td>0.00</td>
<td>1.27</td>
</tr>
<tr class="even">
<td>you</td>
<td>2.26</td>
<td>1.27</td>
</tr>
<tr class="odd">
<td>hp</td>
<td>0.02</td>
<td>0.90</td>
</tr>
<tr class="even">
<td>free</td>
<td>0.52</td>
<td>0.07</td>
</tr>
<tr class="odd">
<td>!</td>
<td>0.51</td>
<td>0.11</td>
</tr>
<tr class="even">
<td>edu</td>
<td>0.01</td>
<td>0.29</td>
</tr>
<tr class="odd">
<td>remove</td>
<td>0.28</td>
<td>0.01</td>
</tr>
</tbody>
</table>
<p><em>Average percentage of words or characters in an email message equal to the indicated word or character. We have chosen the words and characters showing the largest difference between spam and email.</em></p>
</div>
</section>
<section id="zip-code" class="slide level2 center">
<h2>Zip Code</h2>
<div style="font-size: 80%;">
<p>Identify the numbers in a handwritten zip code.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/zip_code.png" class="quarto-figure quarto-figure-center" style="width:45.0%"></p>
</figure>
</div>
</div>
</div>
</div>
<p><br></p>
</section>
<section id="netflix-prize" class="slide level2 center">
<h2>Netflix Prize</h2>
<p><br></p>
<center>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/netflix_prize.png" class="quarto-figure quarto-figure-center" style="width:60.0%"></p>
</figure>
</div>
</div>
</div>
<p><a href="https://www.youtube.com/watch?v=ImpV70uLxyw" target="_blank">Video: Winning the Netflix Prize</a></p>
<p><a href="https://en.wikipedia.org/wiki/Netflix_Prize" target="_blank">Netflix Prize - Wiki</a></p>
<p><br></p>
</center>
</section></section>
<section id="statistical-learning-overview" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Statistical Learning Overview</h1>

</section>

<section>
<section id="what-is-statistical-learning" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>What is Statistical Learning?</h1>

</section>
<section id="what-is-statistical-learning-1" class="slide level2 center">
<h2>What is Statistical Learning?</h2>
<div style="font-size: 80%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/2_1-1.png" class="quarto-figure quarto-figure-center" style="width:60.0%"></p>
</figure>
</div>
</div>
</div>
<p>Shown are <strong>Sales</strong> vs <strong>TV</strong>, <strong>Radio</strong>, and <strong>Newspaper</strong>, with a blue linear-regression line fit separately to each.</p>
<p>Can we predict <strong>Sales</strong> using these three?</p>
<div class="fragment">
<p>Perhaps we can do better using a model:</p>
<p><span class="math display">\[
\text{Sales} \approx f(\text{TV}, \text{Radio}, \text{Newspaper})
\]</span></p>
</div>
</div>
<p><br></p>
</section>
<section id="notation" class="slide level2 center">
<h2>Notation</h2>
<div style="font-size: 80%;">
<ul>
<li><p><strong>Sales</strong> is a <em>response</em> or <em>target</em> that we wish to predict. We generically refer to the response as <span class="math inline">\(Y\)</span>.</p></li>
<li><p><strong>TV</strong> is a <em>feature</em>, or <em>input</em>, or <em>predictor</em>; we name it <span class="math inline">\(X_1\)</span>.<br>
Likewise, name <strong>Radio</strong> as <span class="math inline">\(X_2\)</span>, and so on.</p></li>
<li><p>The input vector collectively is referred to as:</p></li>
</ul>
<p><span class="math display">\[
X = \begin{pmatrix}
X_1 \\
X_2 \\
X_3
\end{pmatrix}
\]</span></p>
<p>We write our model as:</p>
<p><span class="math display">\[
Y = f(X) + \epsilon
\]</span></p>
<p>where <span class="math inline">\(\epsilon\)</span> captures measurement errors and other discrepancies.</p>
</div>
</section>
<section id="what-is-fx-good-for" class="slide level2 center">
<h2>What is <span class="math inline">\(f(X)\)</span> Good For?</h2>
<ul>
<li class="fragment"><p>With a good <span class="math inline">\(f\)</span>, we can make predictions of <span class="math inline">\(Y\)</span> at new points <span class="math inline">\(X = x\)</span>.</p></li>
<li class="fragment"><p>Understand which components of <span class="math inline">\(X = (X_1, X_2, \ldots, X_p)\)</span> are important in explaining <span class="math inline">\(Y\)</span>, and which are irrelevant.</p>
<ul>
<li class="fragment">Example: <em>Seniority</em> and <em>Years of Education</em> have a big impact on <em>Income</em>, but <em>Marital Status</em> typically does not.</li>
</ul></li>
<li class="fragment"><p>Depending on the complexity of <span class="math inline">\(f\)</span>, understand how each component <span class="math inline">\(X_j\)</span> affects <span class="math inline">\(Y\)</span>.</p></li>
</ul>
</section>
<section id="is-there-an-ideal-fx" class="slide level2 center">
<h2>Is There an Ideal <span class="math inline">\(f(X)\)</span>?</h2>
<div style="font-size: 80%;">
<p>In particular, what is a good value for <span class="math inline">\(f(X)\)</span> at a selected value of <span class="math inline">\(X\)</span>, say <span class="math inline">\(X = 4\)</span>?</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/2_1_2.png" class="quarto-figure quarto-figure-center" style="width:60.0%"></p>
</figure>
</div>
</div>
</div>
<div class="fragment">
<p>There can be many <span class="math inline">\(Y\)</span> values at <span class="math inline">\(X=4\)</span>. A good value is:</p>
<p><span class="math display">\[
f(4) = E(Y|X=4)
\]</span></p>
<p>where <span class="math inline">\(E(Y|X=4)\)</span> means the <em>expected value</em> (average) of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X=4\)</span>.</p>
<p>This ideal <span class="math inline">\(f(x) = E(Y|X=x)\)</span> is called the <strong>regression function</strong>.</p>
</div>
</div>
</section>
<section id="the-regression-function-fx" class="slide level2 center">
<h2>The Regression Function <span class="math inline">\(f(x)\)</span></h2>
<div style="font-size: 80%;">
<ul>
<li><strong>Is also defined for a vector</strong> <span class="math inline">\(\mathbf{X}\)</span>.</li>
</ul>
<p><span class="math display">\[
f(\mathbf{x}) = f(x_1, x_2, x_3) = \mathbb{E}[\,Y \mid X_1 = x_1,\, X_2 = x_2,\, X_3 = x_3\,].
\]</span></p>
<div class="fragment">
<ul>
<li><strong>Is the ideal or optimal predictor</strong> of <span class="math inline">\(Y\)</span> in terms of mean-squared prediction error:</li>
</ul>
<p><span class="math display">\[
  f(x) = \mathbb{E}[Y \mid X = x]
  \quad\text{is the function that minimizes}\quad
  \mathbb{E}[(Y - g(X))^2 \mid X = x]
  \text{ over all } g \text{ and for all points } X = x.
\]</span></p>
</div>
<div class="fragment">
<ul>
<li><p><span class="math inline">\(\varepsilon = Y - f(x)\)</span> is the <strong>irreducible error</strong>.</p>
<ul>
<li>Even if we knew <span class="math inline">\(f(x)\)</span>, we would still make prediction errors because at each <span class="math inline">\(X = x\)</span> there is a distribution of possible <span class="math inline">\(Y\)</span> values.</li>
</ul></li>
</ul>
</div>
<div class="fragment">
<ul>
<li>For any estimate <span class="math inline">\(\hat{f}(x)\)</span> of <span class="math inline">\(f(x)\)</span>,</li>
</ul>
<p><span class="math display">\[
    \mathbb{E}\bigl[(Y - \hat{f}(X))^2 \mid X = x\bigr]
    = \underbrace{[\,f(x) - \hat{f}(x)\,]^2}_{\text{Reducible}}
      \;+\; \underbrace{\mathrm{Var}(\varepsilon)}_{\text{Irreducible}}.
\]</span></p>
</div>
</div>
</section></section>
<section>
<section id="supervised-learning" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Supervised Learning</h1>

</section>
<section id="supervised-learning-1" class="slide level2 center">
<h2>Supervised Learning</h2>
<div class="columns">
<div class="column" style="font-size: 90%;">
<ul>
<li><p><strong>Definition:</strong><br>
Learning a mapping from inputs <span class="math inline">\(X\)</span> to an output <span class="math inline">\(Y\)</span> using labeled data.<br>
The algorithm is <em>supervised</em> because the correct answers are known during training.</p></li>
<li><p><strong>Goal:</strong></p>
<ul>
<li>Predict <span class="math inline">\(Y\)</span> for new unseen <span class="math inline">\(X\)</span>.<br>
</li>
<li>Minimize prediction error.</li>
</ul></li>
</ul>
</div><div class="column" style="font-size: 90%;">
<ul>
<li><strong>Examples of Methods:</strong>
<ul>
<li>Linear Regression, Logistic Regression<br>
</li>
<li>Decision Trees, Random Forests, SVMs<br>
</li>
<li>Neural Networks</li>
</ul></li>
<li><strong>Applications:</strong>
<ul>
<li>Predicting stock prices<br>
</li>
<li>Diagnosing diseases<br>
</li>
<li>Spam email detection</li>
</ul></li>
</ul>
</div></div>
</section></section>
<section>
<section id="unsupervised-learning" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Unsupervised Learning</h1>

</section>
<section id="unsupervised-learning-1" class="slide level2 center">
<h2>Unsupervised Learning</h2>
<div class="columns">
<div class="column" style="font-size: 90%;">
<ul>
<li><p><strong>Definition:</strong><br>
Learning the structure or patterns in data without labeled outputs.<br>
The algorithm is <em>unsupervised</em> because no outcome variable guides the learning.</p></li>
<li><p><strong>Goal:</strong></p>
<ul>
<li>Discover hidden structures in <span class="math inline">\(X\)</span>.<br>
</li>
<li>Group, reduce, or represent data meaningfully.</li>
</ul></li>
</ul>
</div><div class="column" style="font-size: 90%;">
<ul>
<li><strong>Examples of Methods:</strong>
<ul>
<li>Clustering: k-means, hierarchical clustering<br>
</li>
<li>Dimensionality Reduction: PCA, t-SNE</li>
</ul></li>
<li><strong>Applications:</strong>
<ul>
<li>Customer segmentation<br>
</li>
<li>Market basket analysis<br>
</li>
<li>Reducing dimensionality of large datasets</li>
</ul></li>
<li><strong>Characteristics</strong>:
<ul>
<li>Difficult to know how well we are doing.<br>
</li>
<li>Different from supervised learning, but can be useful as a pre-processing step for supervised learning.</li>
</ul></li>
</ul>
</div></div>
<!---

## Starting point

<br>

::: nonincremental
::: {style="font-size: 90%;"}


- Outcome measurement $Y$ (also called dependent variable, response, target).

- Vector of $p$ predictor measurements $X$ (also called inputs, regressors, covariates, features, independent variables).

- In the regression problem, $Y$ is quantitative (e.g., price, blood pressure).

- In the classification problem, $Y$ takes values in a finite, unordered set (e.g., survived/died, digit 0–9, cancer class of tissue sample).

- We have training data $(x_1, y_1), \ldots, (x_N, y_N)$. These are observations (examples, instances) of these measurements.

:::
:::

## Objectives

On the basis of the training data, we would like to:

- Accurately predict unseen *test* cases.

- Understand which inputs affect the outcome, and how.

- Assess the quality of our predictions and inferences.

## Philosophy

<br>

::: nonincremental

- It is important to understand the ideas behind the various techniques, in order to know how and when to use them.

- We will understand the simpler methods first to grasp the more sophisticated ones later.

- It is important to accurately assess the performance of a method, to know how well or how badly it is working.

:::

# Unsupervised Learning  {background-color="#cfb991"}

## Unsupervised Learning

::: nonincremental
::: {style="font-size: 80%;"}

- No outcome variable, just a set of predictors (features) measured on a set of samples.

- Objective is more fuzzy:

    - Find groups of samples that behave similarly.
    
    - Find features that behave similarly.
    
    - Find linear combinations of features with the most variation.

- Difficult to know how well we are doing.

- Different from supervised learning, but can be useful as a pre-processing step for supervised learning.

:::
:::

--->
<!---
## Statistical Learning versus Machine Learning

::: nonincremental
::: {style="font-size: 80%;"}

- Machine learning arose as a subfield of Artificial Intelligence.

- Statistical learning arose as a subfield of Statistics.

- **There is much overlap—both fields focus on supervised and unsupervised problems:**
    
    - Machine learning has a greater emphasis on *large scale applications* and *prediction accuracy*.
    
    - Statistical learning emphasizes *models* and their *interpretability*, and *precision* and *uncertainty*.

- The distinction has become more blurred, with significant cross-fertilization.

- Machine learning has the upper hand in *Marketing*!

:::
:::
--->
</section>
<section id="how-to-estimate-f" class="slide level2 center">
<h2>How to Estimate <span class="math inline">\(f\)</span></h2>
<ul>
<li><p>Often, we lack sufficient data points for exact computation of <span class="math inline">\(E(Y|X=x)\)</span>.</p></li>
<li><p>So, we relax the definition:</p></li>
</ul>
<p><span class="math display">\[
\hat{f}(x) = \text{Ave}(Y|X \in \mathcal{N}(x))
\]</span></p>
<p>where <span class="math inline">\(\mathcal{N}(x)\)</span> is a <em>neighborhood</em> of <span class="math inline">\(x\)</span>.</p>

<img data-src="figs/2_1_3.png" class="quarto-figure quarto-figure-center r-stretch" style="width:50.0%"><p><br></p>
</section>
<section id="nearest-neighbor-observations" class="slide level2 center">
<h2>Nearest Neighbor Observations</h2>
<ul>
<li class="fragment"><p><strong>Nearest neighbor averaging</strong> can be pretty good for small <span class="math inline">\(p\)</span> — i.e., <span class="math inline">\(p \le 4\)</span> — and large-ish <span class="math inline">\(N\)</span>.</p></li>
<li class="fragment"><p>We will discuss <strong>smoother versions</strong>, such as kernel and spline smoothing, later in the course.</p></li>
<li class="fragment"><p>Nearest neighbor methods can be <strong>lousy</strong> when <span class="math inline">\(p\)</span> is large.</p>
<ul>
<li class="fragment"><p>Reason: the <em>curse of dimensionality</em>. Nearest neighbors tend to be far away in high dimensions.</p></li>
<li class="fragment"><p>We need to get a <strong>reasonable fraction</strong> of the <span class="math inline">\(N\)</span> values of <span class="math inline">\(y_i\)</span> to average in order to bring the variance down (e.g., 10%).</p></li>
<li class="fragment"><p>A 10% neighborhood in high dimensions is <strong>no longer truly local</strong>, so we lose the spirit of estimating <span class="math inline">\(\mathbb{E}[Y \mid X = x]\)</span> via local averaging.</p></li>
</ul></li>
</ul>
</section>
<section id="the-curse-of-dimensionality" class="slide level2 center">
<h2>The curse of dimensionality</h2>
<div style="font-size: 65%;">
<div class="columns">
<div class="column" style="width:50%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/2_1_4_1.png" class="quarto-figure quarto-figure-center" style="width:40.0%"></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/2_1_4_2.png" class="quarto-figure quarto-figure-center" style="width:40.0%"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<p><strong>Top panel:</strong> <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are uniformly distributed with edges minus one to plus one.</p>
<ul>
<li><p><strong>1-Dimensional Neighborhood</strong></p>
<ul>
<li>Focuses only on <span class="math inline">\(X_1\)</span>, ignoring <span class="math inline">\(X_2\)</span>.</li>
<li>Neighborhood is defined by vertical red dotted lines.</li>
<li>Centered on the target point <span class="math inline">\((0, 0)\)</span>.</li>
<li>Extends symmetrically along <span class="math inline">\(X_1\)</span> until it captures 10% of the data points.</li>
</ul></li>
<li><p><strong>2-Dimensional Neighborhood</strong></p>
<ul>
<li>Now, Considers both <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>.</li>
<li>Neighborhood is a circular region centered on the same target point <span class="math inline">\((0, 0)\)</span>.</li>
<li>Radius of the circle expands until it encloses 10% of the total data points.</li>
<li>The radius in 2D is much larger than the 1D width due to the need to account for more dimensions.</li>
</ul></li>
</ul>
<div class="fragment">
<p><strong>Bottom panel</strong>: We see how far we have to go out in one, two, three, five, and ten dimensions in order to capture a certain fraction of the points.</p>
<p><br></p>
<p><strong>Key Takeaway</strong>: As dimensionality increases, neighborhoods must expand significantly to capture the same fraction of data points, illustrating the <strong>curse of dimensionality</strong>.</p>
</div>
</div></div>
</div>
<p><br></p>
</section></section>
<section>
<section id="parametric-and-structured-models" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Parametric and Structured Models</h1>

</section>
<section id="parametric-and-structured-models-1" class="slide level2 center">
<h2>Parametric and Structured Models</h2>
<p>The <strong>linear model</strong> is a key example of a parametric model to deal with the <em>curse of dimensionality</em>:</p>
<p><span class="math display">\[
f_L(X) = \beta_0 + \beta_1X_1 + \beta_2X_2 + \ldots + \beta_pX_p
\]</span></p>
<ul>
<li class="fragment"><p>A linear model is specified in terms of <span class="math inline">\(p+1\)</span> parameters (<span class="math inline">\(\beta_0, \beta_1, \ldots, \beta_p\)</span>).</p></li>
<li class="fragment"><p>We estimate the parameters by fitting the model to training data.</p></li>
<li class="fragment"><p>Although it is <em>almost never correct</em>, it serves as a good and interpretable approximation to the unknown true function <span class="math inline">\(f(X)\)</span>.</p></li>
</ul>
</section>
<section id="comparison-of-models" class="slide level2 center">
<h2>Comparison of Models</h2>
<div class="columns">
<div class="column" style="text-align: center; justify-content: center; align-items: center;">
<center>
<strong>Linear model</strong>
</center>
<p><span class="math display">\[
\hat{f}_L(X) = \hat{\beta}_0 + \hat{\beta}_1X
\]</span></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/2_1_5.png" class="quarto-figure quarto-figure-center" style="width:90.0%"></p>
</figure>
</div>
</div>
</div>
<p>The linear model gives a reasonable fit here.</p>
</div><div class="column" style="text-align: center; justify-content: center; align-items: center;">
<div class="fragment">
<center>
<strong>Quadratic model:</strong>
</center>
<p><span class="math display">\[
\hat{f}_Q(X) = \hat{\beta}_0 + \hat{\beta}_1X + \hat{\beta}_2X^2
\]</span></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/2_1_6.png" class="quarto-figure quarto-figure-center" style="width:90.0%"></p>
</figure>
</div>
</div>
</div>
<p>Quadratic models may fit slightly better than linear models in some cases.</p>
</div>
</div></div>
</section>
<section id="simulated-example" class="slide level2 center">
<h2>Simulated Example</h2>
<p>Red points are simulated values for <strong>income</strong> from the model:</p>

<img data-src="figs/2_3-1.png" class="quarto-figure quarto-figure-center r-stretch" style="width:70.0%"><p><span class="math display">\[
\text{income} = f(\text{education}, \text{seniority}) + \epsilon
\]</span></p>
<p><span class="math inline">\(f\)</span> is the blue surface.</p>
<p><br></p>
</section>
<section id="linear-regression-fit" class="slide level2 center">
<h2>Linear Regression Fit</h2>
<p>Linear regression model fit to the simulated data:</p>

<img data-src="figs/2_4-1.png" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"><p><span class="math display">\[
\hat{f}_L(\text{education}, \text{seniority}) = \hat{\beta}_0 + \hat{\beta}_1 \times \text{education} + \hat{\beta}_2 \times \text{seniority}
\]</span></p>
<p><br></p>
</section>
<section id="flexible-regression-model-fit" class="slide level2 center">
<h2>Flexible Regression Model Fit</h2>
<p>More flexible regression model <span class="math inline">\(\hat{f}_S(\text{education}, \text{seniority})\)</span> fit to the simulated data.</p>

<img data-src="figs/2_5-1.png" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"><p>Here we use a technique called a <em>thin-plate spline</em> to fit a flexible surface. We control the roughness of the fit.</p>
<p><br></p>
</section>
<section id="overfitting" class="slide level2 center">
<h2>Overfitting</h2>
<p>Even more flexible spline regression model <span class="math inline">\(\hat{f}_S(\text{education}, \text{seniority})\)</span> fit to the simulated data. We tuned the parameter all the way down to zero and this surface actually goes through every single data point.</p>

<img data-src="figs/2_6-1.png" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"><p>The fitted model makes no errors on the training data! This is known as <strong>overfitting</strong>.</p>
<p><br></p>
</section>
<section id="some-trade-offs" class="slide level2 center">
<h2>Some Trade-offs</h2>
<ul>
<li class="fragment"><p><strong>Prediction accuracy versus interpretability</strong>:</p>
<ul>
<li class="fragment">Linear models are easy to interpret; thin-plate splines are not.</li>
</ul></li>
<li class="fragment"><p><strong>Good fit versus over-fit or under-fit</strong>:</p>
<ul>
<li class="fragment">How do we know when the fit is just right?</li>
</ul></li>
<li class="fragment"><p><strong>Parsimony versus black-box</strong>:</p>
<ul>
<li class="fragment">Prefer simpler models involving fewer variables over black-box predictors.</li>
</ul></li>
</ul>
</section>
<section id="flexibility-vs.-interpretability" class="slide level2 center">
<h2>Flexibility vs.&nbsp;Interpretability</h2>
<div style="font-size: 80%;">
<p>Trade-offs between <strong>flexibility</strong> and <strong>interpretability</strong>:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/2_7-1.png" class="quarto-figure quarto-figure-center" style="width:50.0%"></p>
</figure>
</div>
</div>
</div>
<ul>
<li class="fragment"><strong>High interpretability</strong>: Subset selection, Lasso.<br>
</li>
<li class="fragment"><strong>Intermediate</strong>: Least squares, Generalized Additive Models, Trees.<br>
</li>
<li class="fragment"><strong>High flexibility</strong>: Support Vector Machines, Deep Learning.</li>
</ul>
<p><br></p>
</div>
</section></section>
<section>
<section id="assessing-model-accuracy" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Assessing Model Accuracy</h1>

</section>
<section id="assessing-model-accuracy-1" class="slide level2 center">
<h2>Assessing Model Accuracy</h2>
<div style="font-size: 80%;">
<p>Suppose we fit a model <span class="math inline">\(\hat{f}(x)\)</span> to some training data <span class="math inline">\(Tr = \{x_i, y_i\}_{i=1}^N\)</span>, and we wish to evaluate its performance:</p>
<ul>
<li>Compute the average squared prediction error over the training set <span class="math inline">\(Tr\)</span>, the Mean Squared Error (MSE):</li>
</ul>
<p><span class="math display">\[
\text{MSE}_{Tr} = \text{Ave}_{i \in Tr}[(y_i - \hat{f}(x_i))^2]
\]</span></p>
<p>However, this may be biased toward more overfit models.</p>
<div class="fragment">
<ul>
<li>Instead, use fresh <strong>test data</strong> <span class="math inline">\(Te = \{x_i, y_i\}_{i=1}^M\)</span>:</li>
</ul>
<p><span class="math display">\[
\text{MSE}_{Te} = \text{Ave}_{i \in Te}[(y_i - \hat{f}(x_i))^2]
\]</span></p>
</div>
</div>
</section>
<section id="bias-variance-trade-off" class="slide level2 center">
<h2>Bias-Variance Trade-off</h2>
<div style="font-size: 80%;">
<div class="columns">
<div class="column">
<h3 id="bias-tends-to-underfit">Bias <em>(tends to underfit)</em></h3>
<ul>
<li><strong>Definition:</strong> The error introduced by approximating a real-world problem with a simplified model. High bias implies underfitting.<br>
</li>
<li><strong>Implication:</strong> High bias ⇒ the model misses important patterns (systematic error).<br>
</li>
<li><strong>Typical causes:</strong> Too-simple model (e.g., overly rigid assumptions), insufficient features, heavy regularization.</li>
</ul>
</div><div class="column">
<h3 id="variance-tends-to-overfit">Variance <em>(tends to overfit)</em></h3>
<ul>
<li><strong>Definition:</strong> The amount by which the model’s prediction would change if trained on a different training dataset. High variance implies overfitting.<br>
</li>
<li><strong>Implication:</strong> High variance ⇒ the model is overly sensitive to noise (unstable across samples).<br>
</li>
<li><strong>Typical causes:</strong> Overly flexible model, too many features vs.&nbsp;observations, weak regularization.</li>
</ul>
</div></div>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>The trade-off we manage</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Increasing flexibility ↓ <strong>bias</strong> but ↑ <strong>variance</strong>.<br>
</li>
<li>Goal: choose complexity that <strong>minimizes expected test error</strong>.</li>
</ul>
</div>
</div>
</div>
<p><strong>Decomposition of expected test MSE</strong><br>
<span class="math display">\[
\mathbb{E}\big[(Y-\hat f(X))^2\big]
   \;=\; \underbrace{\big(\mathrm{Bias}[\hat f(X)]\big)^2}_{\text{misspecification}}
   \;+\; \underbrace{\mathrm{Var}[\hat f(X)]}_{\text{sensitivity}}
   \;+\; \underbrace{\sigma^2}_{\text{irreducible noise}}
\]</span></p>
</div>
</section>
<section id="bias-variance-trade-off-1" class="slide level2 center">
<h2>Bias-Variance Trade-off</h2>
<div style="font-size: 55%;">
<div class="columns">
<div class="column" style="width:45%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/2_9-1-1.png" class="quarto-figure quarto-figure-center" style="width:45.0%"></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/2_9-1-2.png" class="quarto-figure quarto-figure-center" style="width:45.0%"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:55%;">
<p><strong>Top Panel: Model Fits</strong></p>
<ul>
<li><p><strong>Black Curve</strong>: The true generating function, representing the underlying relationship we want to estimate.</p></li>
<li><p><strong>Data Points</strong>: Observations generated from the black curve, with added noise (error).</p></li>
<li><p><strong>Fitted Models</strong>:</p>
<ul>
<li><strong>Orange Line</strong>: A simple linear model (low flexibility).</li>
<li><strong>Blue Line</strong>: A moderately flexible model, likely a spline or thin plate spline.</li>
<li><strong>Green Line</strong>: A highly flexible model that closely fits the data points but may overfit.</li>
</ul></li>
</ul>
<p><strong>Key Insight</strong>:</p>
<p>The green model captures the data points well but risks overfitting, while the orange model is too rigid and misses the underlying structure. The blue model strikes a balance.</p>
<div class="fragment">
<p><strong>Bottom Panel: Mean Squared Error (MSE)</strong></p>
<ul>
<li><p><strong>Gray Curve</strong>: Training data MSE.</p>
<ul>
<li>Decreases consistently as flexibility increases.</li>
<li>Flexible models fit the training data well, but this does not generalize to test data.</li>
</ul></li>
<li><p><strong>Red Curve</strong>: Test data MSE across models of increasing flexibility.</p>
<ul>
<li>Starts high for rigid models (orange line).</li>
<li>Decreases to a minimum (optimal model complexity, blue line).</li>
<li>Increases again for overly flexible models (green line), due to overfitting.</li>
</ul></li>
</ul>
<p><strong>Key Takeaway</strong>:<br>
There is an optimal model complexity (the “magic point”) where test data MSE is minimized. Beyond this point, models become overly complex and generalization performance deteriorates.</p>
</div>
</div></div>
</div>
</section>
<section id="bias-variance-trade-off-other-examples" class="slide level2 center">
<h2>Bias-Variance Trade-off: Other Examples</h2>
<div style="font-size: 65%;">
<div class="columns">
<div class="column" style="width:50%;">
<p><br></p>
<p>Here, the truth is <strong>smoother</strong>, so smoother fits and linear models perform well.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/2_10-1.png" class="quarto-figure quarto-figure-center" style="width:95.0%"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="fragment">
<p><br></p>
<p>Here, the truth is <strong>wiggly</strong> and the noise is low. More flexible fits perform the best.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/2_11-1.png" class="quarto-figure quarto-figure-center" style="width:95.0%"></p>
</figure>
</div>
</div>
</div>
</div>
</div></div>
</div>
</section>
<section id="bias-variance-trade-off-2" class="slide level2 center">
<h2>Bias-Variance Trade-off</h2>
<div style="font-size: 80%;">
<p>Suppose we have fit a model <span class="math inline">\(\hat{f}(x)\)</span> to some training data <span class="math inline">\(\text{Tr}\)</span>, and let <span class="math inline">\((x_0, y_0)\)</span> be a test observation drawn from the population.</p>
<p>If the true model is</p>
<p><span class="math display">\[
    Y = f(X) + \varepsilon
    \quad \text{(with } f(x) = \mathbb{E}[Y \mid X = x]\text{)},
\]</span></p>
<p>then</p>
<p><span class="math display">\[
\mathbb{E}\Bigl[\bigl(y_0 - \hat{f}(x_0)\bigr)^2\Bigr]
    = \mathrm{Var}\bigl(\hat{f}(x_0)\bigr)
    + \bigl[\mathrm{Bias}\bigl(\hat{f}(x_0)\bigr)\bigr]^2
    + \mathrm{Var}(\varepsilon).
\]</span></p>
<p>The expectation averages over the variability of <span class="math inline">\(y_0\)</span> as well as the variability in <span class="math inline">\(\text{Tr}\)</span>. Note that</p>
<p><span class="math display">\[
    \mathrm{Bias}\bigl(\hat{f}(x_0)\bigr)
    = \mathbb{E}[\hat{f}(x_0)] - f(x_0).
\]</span></p>
<p>Typically, as the <strong>flexibility</strong> of <span class="math inline">\(\hat{f}\)</span> increases, its variance increases and its bias decreases. Hence, choosing the flexibility based on average test error amounts to a <strong>bias-variance trade-off</strong>.</p>
<p><br></p>
</div>
</section>
<section id="bias-variance-trade-off-of-the-examples" class="slide level2 center">
<h2>Bias-Variance Trade-off of the Examples</h2>
<div style="font-size: 70%;">
<p>Below is a schematic illustration of the mean squared error (MSE), bias, and variance curves as a function of the model’s flexibility.</p>
<div class="column-screen">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/2_12-1.png" class="quarto-figure quarto-figure-center" style="width:60.0%"></p>
</figure>
</div>
</div>
</div>
<ul>
<li><p><strong>MSE (red curve)</strong> goes down initially (as the model becomes more flexible) but eventually goes up (as overfitting sets in).</p></li>
<li><p><strong>Bias (blue/teal curve)</strong> decreases with increasing flexibility.</p></li>
<li><p><strong>Variance (orange curve)</strong> increases with increasing flexibility.</p></li>
</ul>
</div>
<p>The vertical dotted line in each panel suggests a model flexibility that balances both bias and variance in an “optimal” region for minimizing MSE.</p>
</div>
<p><br></p>
<!--- Optei por remover da primeira semana para abordar nas segunda e terceira semandas.

# Classification Problems {background-color="#cfb991"}

## Classification Problems

:::: nonincremental
::: {style="font-size: 80%;"}

Here the response variable $Y$ is **qualitative**. For example:

- Email could be classified as **spam** or **ham** (good email).
    
- Digit classification could be one of $\{0, 1, 2, \dots, 9\}$.

:::{.fragment}

Our goals are to:

1. Build a classifier $C(X)$ that assigns a class label from the set $C$ to a future unlabeled observation $X$.
    
2. Assess the uncertainty in each classification.
    
3. Understand the roles of the different predictors among $X = (X_1, X_2, \dots, X_p)$.

:::

::::
::: 

## Ideal Classifier and Bayes Decision Rule

:::: nonincremental
::: {style="font-size: 80%;"}


::: {.cell layout-align="center"}
::: {.cell-output-display}
![](figs/2_1_7.png){fig-align='center' width=50%}
:::
:::


Consider a classification problem with $K$ possible classes,  numbered $1, 2, \ldots, K$. Define

$$
  p_k(x) = \Pr(Y = k \mid X = x), 
  \quad k = 1, 2, \ldots, K.
$$

These are the **conditional class probabilities** at $x$; e.g. see little
barplot at $x=5$. 

The **Bayes optimal** classifier at $x$ is

$$
  C(x) \;=\; j \quad \text{if} \quad p_j(x) = 
      \max \{\,p_1(x),\, p_2(x),\, \dots,\, p_K(x)\}.
$$

::::
:::

<br>

## Nearest-Neighbor Averaging

:::: nonincremental
::: {style="font-size: 80%;"}


::: {.cell layout-align="center"}
::: {.cell-output-display}
![](figs/2_1_8.png){fig-align='center' width=60%}
:::
:::


Nearest-neighbor averaging can be used as before.  

Also breaks down as dimension grows. However, the impact on $\hat{C}(x)$is less than on $\hat{p}_k(x)$, for $k = 1,\ldots,K$.

::::
:::


## Classification: Some Details

:::: nonincremental
::: {style="font-size: 90%;"}

Typically we measure the performance of $\hat{C}(x)$ using the **misclassification error rate**:

$$
    \mathrm{Err}_{\mathrm{Te}} 
      = \mathrm{Ave}_{i\in \mathrm{Te}} 
        \bigl[I(y_i \neq \hat{C}(x_i))\bigr].
$$

- The **Bayes classifier** (using the true $p_k(x)$) has the smallest error in the population.

- **Support-vector machines** build structured models for $\hat{C}(x)$.

- We also build **structured models** for representing $p_k(x)$. For example, logistic regression or generalized additive models.

::::
:::


## Example: K-Nearest Neighbors in Two Dimensions

Below is an example data set in two dimensions $(X_1, X_2)$. Points shown in **blue** might represent one class, and points in **orange** the other. The dashed boundary suggests a decision boundary formed by a classifier.


::: {.cell layout-align="center"}
::: {.cell-output-display}
![](figs/2_1_9.png){fig-align='center' width=80%}
:::
:::


<br>

## KNN: K = 10

Here is the same data set classified by **k-nearest neighbors** with $k = 10$. 
The black boundary line encloses the region of the feature space predicted as orange vs. blue, showing how the decision boundary has become smoother.


::: {.cell layout-align="center"}
::: {.cell-output-display}
![](figs/2_15-1.png){fig-align='center' width=80%}
:::
:::


<br>

## KNN: K = 1 vs. K = 100


::: {.cell layout-align="center"}
::: {.cell-output-display}
![](figs/2_16-1.png){fig-align='center' width=80%}
:::
:::


Comparisons of a **very low** value of $k$ (left, $k=1$) versus a **very high** value (right, $k=100$). 

- **$k=1$**: Overly flexible boundary that can overfit.

- **$k=100$**: Very smooth boundary that can underfit.

<br>

## KNN Error Rates

:::: nonincremental
::: {style="font-size: 80%;"}

:::: {.columns}
::: {.column width="45%"}



::: {.cell layout-align="center"}
::: {.cell-output-display}
![](figs/2_17-1.png){fig-align='center' width=95%}
:::
:::


::: 

::: {.column width="45%"}

The figure illustrates how **training errors** (blue curve) and **test errors** (orange curve) change for a K-nearest neighbors (KNN) classifier as $\frac{1}{K}$ varies.  

- **For small $K$** (i.e., large $\frac{1}{K}$), the model can become very flexible, often driving down training error but increasing overfitting and thus test error.

- **For large $K$** (i.e., small $\frac{1}{K}$), the model becomes smoother, which can help avoid overfitting but sometimes leads to underfitting.

The dashed horizontal line is the bayes error, used as reference for comparison.


:::

::::

::::
:::

<br>

--->
</section></section>
<section>
<section id="summary" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Summary</h1>

</section>
<section id="summary-1" class="slide level2 center">
<h2>Summary</h2>
<div style="font-size: 70%;">
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Statistical Learning and Predictive Analytics</strong></p>
<ul>
<li><p><strong>Goal</strong>: Build models to predict outcomes and understand relationships between inputs (predictors) and responses.</p></li>
<li><p><strong>Supervised Learning</strong>: Focuses on predicting <span class="math inline">\(Y\)</span> (response) using <span class="math inline">\(X\)</span> (predictors) via models like regression and classification.</p></li>
<li><p><strong>Unsupervised Learning</strong>: Focuses on finding patterns in data without predefined responses (e.g., clustering).</p></li>
</ul>
<p><strong>Bias-Variance Trade-off</strong></p>
<ul>
<li><p><strong>Key Trade-off</strong>: Model flexibility affects bias and variance:</p>
<ul>
<li><strong>High flexibility</strong> → Low bias but high variance (overfitting).</li>
<li><strong>Low flexibility</strong> → High bias but low variance (underfitting).</li>
</ul></li>
<li><p>Goal: Find the optimal flexibility that minimizes test error.</p></li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Techniques and Applications</strong></p>
<ul>
<li><p><strong>Parametric Models</strong>:</p>
<ul>
<li>Simpler and interpretable (e.g., linear regression).</li>
<li>Often used as approximations.</li>
</ul></li>
<li><p><strong>Flexible Models</strong>:</p>
<ul>
<li>Handle complex patterns (e.g., splines, SVMs, deep learning).</li>
<li>Require careful tuning to avoid overfitting.</li>
</ul></li>
</ul>
<p><strong>Practical Considerations</strong></p>
<ul>
<li><p><strong>Assessing Model Accuracy</strong>:</p>
<ul>
<li>Use test data to calculate MSE.</li>
<li>Balance between training performance and generalizability.</li>
</ul></li>
</ul>
<p><strong>Key Challenges</strong></p>
<ul>
<li><p><strong>Curse of Dimensionality</strong>:</p>
<ul>
<li>High-dimensional data affects distance-based methods like KNN.</li>
<li>Larger neighborhoods needed, losing “locality.”</li>
</ul></li>
</ul>
</div></div>
</div>
</section></section>
<section id="thank-you" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Thank you!</h1>


</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p>Predictive Analytics</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":false},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1600,

        height: 900,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>