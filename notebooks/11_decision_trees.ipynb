{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees - Interpretable Models with Sharp Edges\n",
    "\n",
    "<hr>\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "<img src=\"https://raw.githubusercontent.com/davi-moreira/2026Summer_predictive_analytics_purdue_MGMT474/main/notebooks/figures/mgmt_474_ai_logo_02-modified.png\" width=\"200\"/>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "# <center><a class=\"tocSkip\"></center>\n",
    "# <center>MGMT47400 Predictive Analytics</center>\n",
    "# <center>Professor: Davi Moreira </center>\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/davi-moreira/2026Summer_predictive_analytics_purdue_MGMT474/blob/main/notebooks/11_decision_trees.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Fit decision trees for regression/classification\n",
    "2. Control complexity (depth, min samples) to manage overfitting\n",
    "3. Interpret tree structure and failure modes\n",
    "4. Compare tree vs linear/logistic baselines under CV\n",
    "5. Document \"when a tree is the right tool\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.datasets import load_breast_cancer, fetch_california_housing\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\nfrom sklearn.linear_model import LogisticRegression, Ridge\nfrom sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\nimport warnings\n\nwarnings.filterwarnings('ignore')\npd.set_option('display.precision', 4)\nRANDOM_SEED = 474\nnp.random.seed(RANDOM_SEED)\nprint(\"\u2713 Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Reading the output:**\n",
    "\n",
    "The setup cell imports the core libraries for this notebook. `DecisionTreeClassifier` and `DecisionTreeRegressor` from scikit-learn implement the CART algorithm, while `plot_tree` lets us render the learned tree structure as a graphic. `StratifiedKFold` ensures each cross-validation fold preserves the class balance of the breast cancer dataset (roughly 63 % benign, 37 % malignant).\n",
    "\n",
    "The message `Setup complete!` with the random seed **RANDOM_SEED = 474** confirms that all libraries loaded without error and that every stochastic operation in this notebook will be reproducible.\n",
    "\n",
    "**Key takeaway:** A successful setup cell is the foundation of reproducibility. If any import fails here, none of the downstream code will run in Colab.\n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Decision Tree Intuition\n",
    "\n",
    "### How Trees Make Decisions\n",
    "\n",
    "**Algorithm (CART - Classification and Regression Trees):**\n",
    "1. Start with all data at root\n",
    "2. Find best feature + threshold to split\n",
    "   - \"Best\" = maximize information gain (classification) or minimize MSE (regression)\n",
    "3. Create two child nodes\n",
    "4. Repeat recursively until stopping criteria\n",
    "\n",
    "**Example Decision Path:**\n",
    "```\n",
    "Is income > $50k?\n",
    "  \u251c\u2500 No: Is age > 30?\n",
    "  \u2502   \u251c\u2500 No: Predict class 0 (high risk)\n",
    "  \u2502   \u2514\u2500 Yes: Predict class 1 (low risk)\n",
    "  \u2514\u2500 Yes: Predict class 1 (low risk)\n",
    "```\n",
    "\n",
    "### Key Hyperparameters\n",
    "\n",
    "**Complexity control:**\n",
    "- `max_depth`: Maximum tree depth (prevents overfitting)\n",
    "- `min_samples_split`: Minimum samples to split a node\n",
    "- `min_samples_leaf`: Minimum samples in leaf node\n",
    "- `max_features`: Number of features to consider per split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification Tree Example\n",
    "\n",
    "We will use the **Wisconsin Breast Cancer** dataset (569 samples, 30 numeric features) to build our first decision tree. Each sample is labeled as malignant or benign, making this a binary classification task. The tree will learn axis-aligned splits on features such as mean radius, mean texture, and worst concave points.\n",
    "\n",
    "We cap `max_depth=3` so the tree remains small enough to visualize and interpret. Even a shallow tree can achieve surprisingly high accuracy on well-separated classes, and the visualization makes it clear exactly which features and thresholds drive each prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "print(f\"Train: {len(X_train)} | Test: {len(X_test)}\")\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "\n",
    "# Fit a simple tree\n",
    "tree_clf = DecisionTreeClassifier(max_depth=3, random_state=RANDOM_SEED)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "train_score = tree_clf.score(X_train, y_train)\n",
    "test_score = tree_clf.score(X_test, y_test)\n",
    "\n",
    "print(f\"\\n=== DECISION TREE (max_depth=3) ===\")\n",
    "print(f\"Train accuracy: {train_score:.4f}\")\n",
    "print(f\"Test accuracy: {test_score:.4f}\")\n",
    "print(f\"Overfit gap: {train_score - test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Reading the output:**\n",
    "\n",
    "The dataset splits into **398 training** and **171 test** samples across **30 features**, all numeric measurements from digitized images of breast tissue. With `max_depth=3` the tree is constrained to at most 8 leaf nodes.\n",
    "\n",
    "Look at the two accuracy numbers. Training accuracy around **0.97-0.98** tells us the shallow tree captures most of the signal. Test accuracy close behind (gap typically < 0.02) confirms the model is not overfitting at this depth. The **overfit gap** printed at the bottom should be small and positive; a negative gap would indicate unusual luck on the test split.\n",
    "\n",
    "**Why this matters:** A depth-3 tree is already competitive with much more complex models on this dataset, demonstrating that a simple, interpretable model can be a strong baseline.\n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(\n",
    "    tree_clf,\n",
    "    feature_names=X.columns,\n",
    "    class_names=data.target_names,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=10\n",
    ")\n",
    "plt.title(\"Decision Tree Visualization (max_depth=3)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\ud83d\udca1 Follow a path from root to leaf to see decision logic\")\n",
    "print(\"\ud83d\udca1 Darker colors = more samples, purity of class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Reading the output:**\n",
    "\n",
    "The graphic shows every internal decision node and leaf node of the depth-3 tree. Each box contains four pieces of information: the **split rule** (e.g., `worst radius <= 16.8`), the **Gini impurity** (0 = perfectly pure), the **number of samples** reaching that node, and the **class distribution** (malignant vs. benign counts).\n",
    "\n",
    "Color intensity encodes purity: darker blue means almost all samples are benign, darker orange means almost all are malignant. Follow any path from root to leaf and you read a plain-English decision rule: \"If worst radius > 16.8 and worst concave points > 0.14, predict malignant.\"\n",
    "\n",
    "Notice that the root split uses a feature from the \"worst\" category (the largest cell nuclei in the image). This makes clinical sense because malignant tumors tend to have larger, more irregularly shaped nuclei.\n",
    "\n",
    "**Key takeaway:** This visualization is the primary advantage of decision trees over black-box models. You can hand this diagram to a domain expert and they can audit every prediction path.\n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Overfitting Problem\n",
    "\n",
    "### Trees Without Constraints = Memorization\n",
    "\n",
    "An unrestricted decision tree will keep splitting until every leaf contains a single sample, achieving **100 % training accuracy** by memorizing the data. On new data the performance collapses because those hyper-specific rules do not generalize. The depth sweep below makes this tradeoff visible: training accuracy climbs monotonically with depth, while test accuracy peaks at a moderate depth and then declines.\n",
    "\n",
    "Monitoring the **overfit gap** (train accuracy minus test accuracy) is the fastest way to diagnose the problem. A gap near zero means the model generalizes well; a large gap means the tree has memorized noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different depths\n",
    "depths = [1, 2, 3, 5, 10, 20, None]  # None = unlimited\n",
    "results = []\n",
    "\n",
    "for depth in depths:\n",
    "    tree = DecisionTreeClassifier(max_depth=depth, random_state=RANDOM_SEED)\n",
    "    tree.fit(X_train, y_train)\n",
    "    \n",
    "    train_acc = tree.score(X_train, y_train)\n",
    "    test_acc = tree.score(X_test, y_test)\n",
    "    \n",
    "    results.append({\n",
    "        'max_depth': str(depth),\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'gap': train_acc - test_acc,\n",
    "        'n_leaves': tree.get_n_leaves()\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"=== DEPTH SWEEP ===\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy vs depth\n",
    "axes[0].plot(range(len(depths)), results_df['train_acc'], marker='o', label='Train', linewidth=2)\n",
    "axes[0].plot(range(len(depths)), results_df['test_acc'], marker='s', label='Test', linewidth=2)\n",
    "axes[0].set_xticks(range(len(depths)))\n",
    "axes[0].set_xticklabels(results_df['max_depth'])\n",
    "axes[0].set_xlabel('Max Depth')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Accuracy vs Tree Depth')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Overfit gap\n",
    "axes[1].bar(range(len(depths)), results_df['gap'], alpha=0.7, edgecolor='black')\n",
    "axes[1].set_xticks(range(len(depths)))\n",
    "axes[1].set_xticklabels(results_df['max_depth'])\n",
    "axes[1].set_xlabel('Max Depth')\n",
    "axes[1].set_ylabel('Train - Test Gap')\n",
    "axes[1].set_title('Overfitting vs Tree Depth')\n",
    "axes[1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Unrestricted trees achieve 100% training accuracy (pure overfitting!)\")\n",
    "print(\"\ud83d\udca1 Best test performance is at moderate depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Reading the output:**\n",
    "\n",
    "The results table and two-panel plot reveal the classic bias-variance tradeoff. In the left panel, training accuracy (blue) climbs steadily and reaches **1.0** for `max_depth=None` (unlimited), while test accuracy (orange) peaks around depth 3-5 then flattens or declines. The right panel shows the overfit gap growing from near zero at depth 1 to a substantial value at unlimited depth.\n",
    "\n",
    "Key numbers to compare: at `max_depth=3` the gap is typically around **0.01-0.02**, meaning the model generalizes well. At `max_depth=None` the gap can exceed **0.05-0.10**, with the tree growing to dozens or hundreds of leaves that memorize training noise.\n",
    "\n",
    "The `n_leaves` column reinforces this: a depth-3 tree has at most 8 leaves, while an unrestricted tree may have 20+ leaves on 398 training samples, averaging fewer than 20 samples per leaf. Leaves with very few samples produce unreliable predictions.\n",
    "\n",
    "**Why this matters:** This depth sweep is the single most important diagnostic for decision trees. Always run it before selecting a final depth, and pick the depth that maximizes test (or CV) performance, not training performance.\n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcdd PAUSE-AND-DO Exercise 1 (5 minutes)\n",
    "\n",
    "**Task:** Run a depth sweep and choose depth based on CV.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE: Depth sweep with cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "depths_to_test = [2, 3, 4, 5, 6, 7, 8, 10, 15]\n",
    "\n",
    "cv_results = []\n",
    "for depth in depths_to_test:\n",
    "    tree = DecisionTreeClassifier(max_depth=depth, random_state=RANDOM_SEED)\n",
    "    scores = cross_val_score(tree, X_train, y_train, cv=cv, scoring='roc_auc')\n",
    "    \n",
    "    cv_results.append({\n",
    "        'max_depth': depth,\n",
    "        'cv_mean': scores.mean(),\n",
    "        'cv_std': scores.std()\n",
    "    })\n",
    "\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "print(\"=== CV DEPTH SWEEP ===\")\n",
    "print(cv_df.to_string(index=False))\n",
    "\n",
    "best_depth = cv_df.loc[cv_df['cv_mean'].idxmax(), 'max_depth']\n",
    "best_score = cv_df.loc[cv_df['cv_mean'].idxmax(), 'cv_mean']\n",
    "\n",
    "print(f\"\\n\u2713 Best depth by CV: {best_depth} (CV ROC-AUC = {best_score:.4f})\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(cv_df['max_depth'], cv_df['cv_mean'], yerr=cv_df['cv_std'], \n",
    "             marker='o', capsize=5, linewidth=2)\n",
    "plt.axvline(x=best_depth, color='r', linestyle='--', label=f'Best depth = {best_depth}')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('CV ROC-AUC')\n",
    "plt.title('Cross-Validation: Depth Selection')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Reading the output:**\n",
    "\n",
    "The cross-validation table reports ROC-AUC (not just accuracy) for each candidate depth, along with the standard deviation across five folds. The best depth is highlighted at the bottom. On the breast cancer dataset, the optimal depth is typically around **3-5**, yielding a CV ROC-AUC near **0.98-0.99**.\n",
    "\n",
    "The error-bar plot makes the choice visual: performance rises steeply from depth 2 to 3, plateaus through depth 5-7, and then may dip slightly at higher depths as overfitting erodes generalization. The error bars (one standard deviation) show that deeper trees also have *higher variance* across folds, another sign of instability.\n",
    "\n",
    "The vertical red dashed line marks the selected best depth. Note that choosing depth 3 vs. 4 vs. 5 may produce nearly identical mean ROC-AUC; in such cases, prefer the simpler (shallower) tree for better interpretability and robustness.\n",
    "\n",
    "**Key takeaway:** Cross-validation gives a more reliable depth selection than a single train/test split because it averages over multiple data partitions, reducing the risk of picking a depth that only works well by chance.\n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tree vs Linear Model Comparison\n",
    "\n",
    "Decision trees and logistic regression make fundamentally different assumptions about the data. Logistic regression fits a single linear decision boundary in feature space, which works well when classes are roughly linearly separable. Trees, on the other hand, carve the space into axis-aligned rectangles and can capture non-linear interactions without manual feature engineering.\n",
    "\n",
    "The comparison below uses the same `StratifiedKFold` cross-validation object for both models so the evaluation is fair. We report ROC-AUC on validation folds and on the held-out test set. On the breast cancer dataset, the two approaches often perform similarly because the classes are well separated; the real differences emerge on more complex datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare tree vs logistic regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "models = {\n",
    "    'Decision Tree (best)': DecisionTreeClassifier(max_depth=int(best_depth), random_state=RANDOM_SEED),\n",
    "    'Logistic Regression': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', LogisticRegression(random_state=RANDOM_SEED, max_iter=1000))\n",
    "    ])\n",
    "}\n",
    "\n",
    "comparison = []\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='roc_auc')\n",
    "    \n",
    "    # Fit on full train for test evaluation\n",
    "    model.fit(X_train, y_train)\n",
    "    test_score = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    comparison.append({\n",
    "        'Model': name,\n",
    "        'CV_Mean': scores.mean(),\n",
    "        'CV_Std': scores.std(),\n",
    "        'Test_Score': test_score\n",
    "    })\n",
    "\n",
    "comp_df = pd.DataFrame(comparison)\n",
    "print(\"=== TREE VS LINEAR COMPARISON ===\")\n",
    "print(comp_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Which performs better depends on data structure\")\n",
    "print(\"\ud83d\udca1 Trees handle non-linear relationships naturally\")\n",
    "print(\"\ud83d\udca1 Linear models need manual feature engineering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Reading the output:**\n",
    "\n",
    "The comparison table shows CV ROC-AUC (mean and standard deviation) plus the test-set ROC-AUC for both the tuned decision tree and logistic regression. On the breast cancer dataset, both models typically achieve ROC-AUC above **0.97**, because the 30 features provide strong linear separability.\n",
    "\n",
    "If the tree's CV standard deviation is noticeably larger than logistic regression's, that illustrates the **high-variance** nature of trees: small changes in the training fold can shift the tree structure significantly, while logistic regression produces a stable linear boundary every time.\n",
    "\n",
    "The test scores should be consistent with the CV means. If either model's test score falls outside the range mean +/- 2*std, that is a red flag worth investigating (possible data leakage or an unusual test split).\n",
    "\n",
    "**Why this matters:** This head-to-head comparison establishes whether a tree's ability to model non-linear boundaries actually helps on your specific dataset. On linearly separable data, the simpler logistic regression may be the better production choice due to its stability and interpretability.\n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcdd PAUSE-AND-DO Exercise 2 (5 minutes)\n",
    "\n",
    "**Task:** Write 3 observed tree failure modes (with evidence).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANALYSIS: Tree Failure Modes\n",
    "\n",
    "**Failure Mode 1: Overfitting**  \n",
    "[Evidence from depth sweep - what happened with unlimited depth?]\n",
    "\n",
    "**Failure Mode 2: Instability**  \n",
    "[Evidence from CV std - how much do scores vary across folds?]\n",
    "\n",
    "**Failure Mode 3: Extrapolation**  \n",
    "[Trees can only predict values seen in training - what's the implication?]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Regression Trees\n",
    "\n",
    "Everything we learned about classification trees applies to regression: the algorithm still makes recursive binary splits, but instead of Gini impurity it minimizes **mean squared error (MSE)** within each region. Leaf predictions are the average target value of the training samples that fall into that leaf.\n",
    "\n",
    "We demonstrate with the **California Housing** dataset (20,640 samples, 8 features), predicting median house value in units of $100k. The depth sweep below shows the same overfitting pattern we saw in classification: an unrestricted regression tree achieves near-perfect training R-squared but generalizes poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load regression dataset\n",
    "california = fetch_california_housing(as_frame=True)\n",
    "X_reg = california.data\n",
    "y_reg = california.target\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.3, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Depth sweep for regression\n",
    "depths_reg = [2, 3, 5, 7, 10, 15, None]\n",
    "reg_results = []\n",
    "\n",
    "for depth in depths_reg:\n",
    "    tree_reg = DecisionTreeRegressor(max_depth=depth, random_state=RANDOM_SEED)\n",
    "    tree_reg.fit(X_train_reg, y_train_reg)\n",
    "    \n",
    "    train_r2 = tree_reg.score(X_train_reg, y_train_reg)\n",
    "    test_r2 = tree_reg.score(X_test_reg, y_test_reg)\n",
    "    \n",
    "    reg_results.append({\n",
    "        'max_depth': str(depth),\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'gap': train_r2 - test_r2\n",
    "    })\n",
    "\n",
    "reg_df = pd.DataFrame(reg_results)\n",
    "print(\"=== REGRESSION TREE DEPTH SWEEP ===\")\n",
    "print(reg_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Same overfitting pattern as classification\")\n",
    "print(\"\ud83d\udca1 Unrestricted tree memorizes training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Reading the output:**\n",
    "\n",
    "The regression depth sweep mirrors the classification pattern. At `max_depth=2` the tree underfits with a low R-squared on both train and test. As depth increases, training R-squared approaches **1.0** (the tree memorizes the 14,448 training samples), while test R-squared peaks around depth **7-10** and then declines.\n",
    "\n",
    "Typical values: the best test R-squared is around **0.60-0.70**, meaning a single regression tree explains roughly 60-70 % of variance in California median house values. The overfit gap at `max_depth=None` is dramatic, often exceeding **0.30**, confirming that an unrestricted regression tree is a poor production model.\n",
    "\n",
    "Compare these numbers to what you would get from a simple Ridge regression (R-squared around 0.60). A moderately deep tree matches or slightly beats the linear baseline, but an unrestricted tree dramatically overfits. This motivates ensembles (Random Forests, Gradient Boosting) that combine many trees to achieve higher R-squared without memorization.\n",
    "\n",
    "**Key takeaway:** Regression trees have the same overfitting vulnerability as classification trees. Always limit depth and validate on held-out data. The next notebook shows how Random Forests solve this problem by averaging hundreds of trees.\n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. When to Use Decision Trees\n",
    "\n",
    "### Strengths\n",
    "- \u2713 Interpretable (can visualize and explain)\n",
    "- \u2713 Handle non-linear relationships naturally\n",
    "- \u2713 No feature scaling needed\n",
    "- \u2713 Handle mixed data types (numeric + categorical)\n",
    "- \u2713 Capture interactions automatically\n",
    "- \u2713 Fast to train and predict\n",
    "\n",
    "### Weaknesses\n",
    "- \u2717 High variance (unstable - small data changes \u2192 different tree)\n",
    "- \u2717 Easy to overfit\n",
    "- \u2717 Poor extrapolation (can't predict outside training range)\n",
    "- \u2717 Biased toward features with many values\n",
    "- \u2717 Step-function boundaries (not smooth)\n",
    "\n",
    "### Use Decision Trees When:\n",
    "1. Interpretability is critical\n",
    "2. You need quick baseline\n",
    "3. Relationships are highly non-linear\n",
    "4. You'll use ensemble methods (Random Forests, Boosting)\n",
    "\n",
    "### Avoid Decision Trees When:\n",
    "1. High-dimensional sparse data\n",
    "2. Need smooth decision boundaries\n",
    "3. Small datasets (unstable)\n",
    "4. Extrapolation required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Wrap-Up: Key Takeaways\n\n### What We Learned Today:\n\n1. **Tree Mechanics**: Recursive partitioning with greedy splits\n2. **Overfitting Risk**: Unrestricted trees memorize perfectly\n3. **Complexity Control**: depth, min_samples_split, min_samples_leaf\n4. **Interpretability**: Can visualize exact decision logic\n5. **Limitations**: High variance, poor extrapolation\n\n### Critical Rules:\n\n> **\"Never use unrestricted trees in production\"**\n\n> **\"Always tune depth with cross-validation\"**\n\n> **\"Trees are building blocks for ensembles\"**\n\n### Next Steps:\n\n- Next notebook: Random Forests (ensemble of trees)\n- We'll fix tree instability with bagging\n- Learn feature importance from forests\n\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participation Assignment Submission Instructions\n",
    "\n",
    "### To Submit This Notebook:\n",
    "\n",
    "1. **Complete all exercises**: Fill in both PAUSE-AND-DO exercise cells with your findings\n",
    "2. **Run All Cells**: Execute `Runtime \u2192 Run all` to ensure everything works\n",
    "3. **Save a Copy**: `File \u2192 Save a copy in Drive or Download the .ipynb extension`\n",
    "4. **Submit**: Upload your `.ipynb` file in the participation assignment you find in the course Brightspace page.\n",
    "\n",
    "### Before Submitting, Check:\n",
    "\n",
    "- [ ] All cells execute without errors\n",
    "- [ ] All outputs are visible\n",
    "- [ ] Both exercise responses are complete\n",
    "- [ ] Notebook is shared with correct permissions\n",
    "- [ ] You can explain every line of code you wrote\n",
    "\n",
    "### Next Step:\n",
    "\n",
    "Complete the **Quiz** in Brightspace (auto-graded)\n",
    "\n",
    "---\n",
    "\n",
    "## Bibliography\n\n- James, G., Witten, D., Hastie, T., & Tibshirani, R. (2021). *An Introduction to Statistical Learning with Python* - Tree-Based Methods (trees, pruning)\n- Hastie, T., Tibshirani, R., & Friedman, J. (2009). *The Elements of Statistical Learning* - CART foundations and complexity control\n- Breiman, L., Friedman, J., Stone, C. J., & Olshen, R. A. (1984). *Classification and Regression Trees*\n- scikit-learn User Guide: [Decision Trees](https://scikit-learn.org/stable/modules/tree.html)\n\n---\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "Thank you!\n",
    "\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}