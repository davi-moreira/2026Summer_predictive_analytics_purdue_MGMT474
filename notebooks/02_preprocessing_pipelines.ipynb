{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup and Preprocessing Pipelines (The Professional Way)\n",
    "\n",
    "<hr>\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "<img src=\"https://raw.githubusercontent.com/davi-moreira/2026Summer_predictive_analytics_purdue_MGMT474/main/notebooks/figures/mgmt_474_ai_logo_02-modified.png\" width=\"200\"/>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "# <center><a class=\"tocSkip\"></center>\n",
    "# <center>MGMT47400 Predictive Analytics</center>\n",
    "# <center>Professor: Davi Moreira </center>\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/davi-moreira/2026Summer_predictive_analytics_purdue_MGMT474/blob/main/notebooks/02_preprocessing_pipelines.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Audit data types and fix common pandas pitfalls (strings, categories, dates)\n",
    "2. Handle missing values without leaking information\n",
    "3. Build a preprocessing + model Pipeline with `ColumnTransformer`\n",
    "4. Separate \"fit on train only\" logic from evaluation logic\n",
    "5. Use Gemini to draft pipeline code and then harden it (tests + comments)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "> **ðŸ“‹ Participation Reminder:** This notebook contains **2 PAUSE-AND-DO exercises**. You are expected to complete all exercises before submitting your notebook.\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## ðŸ’¼ Why This Matters: The Messy Reality of Real-World Data\n\nYou just joined **HomeValue Analytics**, a real estate tech startup that helps buyers and sellers make informed pricing decisions in California. Your CEO hands you a dataset of 20,000+ neighborhood-level housing records and says: *\"Build me a model that predicts median house values.\"*\n\nYou open the data and discover: features on wildly different scales, potential missing values, and mixed numeric types. Before any prediction can happen, this data needs to be cleaned and transformed â€” reliably, repeatably, and without leaking information.\n\n> **Today's focus:** Building reusable preprocessing pipelines that transform raw housing data into model-ready features.\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup: Imports and Configuration\n",
    "\n",
    "Before building any model, we load the libraries that power our workflow. Each import serves a specific role:\n",
    "\n",
    "- **pandas / numpy** â€” data manipulation and numeric computation\n",
    "- **matplotlib / seaborn** â€” visualization\n",
    "- **sklearn.pipeline.Pipeline** â€” chains preprocessing and modeling into a single reproducible object\n",
    "- **sklearn.compose.ColumnTransformer** â€” applies different transformations to different column groups\n",
    "- **sklearn.preprocessing** â€” scaling (`StandardScaler`) and encoding (`OneHotEncoder`)\n",
    "- **sklearn.impute.SimpleImputer** â€” fills missing values so downstream models receive clean inputs\n",
    "- **sklearn.linear_model.LinearRegression** â€” our baseline regression model\n",
    "\n",
    "We also lock `RANDOM_SEED = 474` so that every split and every model produces the same result each time you run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Setup complete!\n",
      "Random seed: 474\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install pandas numpy matplotlib seaborn scikit-learn --quiet\n",
    "\n",
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "\n",
    "# Display settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 3)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 474\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"âœ“ Setup complete!\")\n",
    "print(f\"Random seed: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the output:**\n",
    "\n",
    "The `âœ“ Setup complete!` confirmation tells you every import succeeded and the environment is ready. The most important line is `Random seed: 474` â€” this guarantees that all random operations (data splits, model initialization) are **deterministic**: you will get the exact same numbers every time you run the notebook.\n",
    "\n",
    "**Key takeaway:** Always run the setup cell first. If any import fails (e.g., `ModuleNotFoundError`), uncomment the `!pip install` line at the top and rerun.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Load Dataset and Create Splits\n\nWe continue with the **California Housing** dataset introduced in the previous notebook. It contains **20,640 census block-groups** described by 8 numeric features (median income, house age, average rooms, etc.) with the target being **median house value** (in \\$100k units). Because the data is pre-cleaned by scikit-learn, we can focus entirely on the preprocessing and pipeline mechanics.\n\nAs in every notebook in this course, we use a **60 / 20 / 20** train / validation / test split created in a single two-step call to `train_test_split`. Splitting *before* any transformation is the first line of defense against data leakage."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "> ðŸ’¡ **Gemini Prompt:** \"Using scikit-learn, load the California Housing dataset as a pandas DataFrame (use `fetch_california_housing(as_frame=True)`). Print the dataset shape, list all column names, and display the first 5 rows.\"\n>\n> **After running, verify:**\n> - Shape is `(20640, 9)` (20,640 rows, 8 features + 1 target)\n> - Features include `MedInc`, `HouseAge`, `AveRooms`, `AveBedrms`, `Population`, `AveOccup`, `Latitude`, `Longitude`\n> - Target column is `MedHouseVal` (median house value in \\$100k units)\n"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (20640, 9)\n",
      "\n",
      "Features: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude', 'MedHouseVal']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.325</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984</td>\n",
       "      <td>1.024</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.301</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238</td>\n",
       "      <td>0.972</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.110</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.257</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288</td>\n",
       "      <td>1.073</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.643</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817</td>\n",
       "      <td>1.073</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.548</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.846</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.282</td>\n",
       "      <td>1.081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0   8.325      41.0     6.984      1.024       322.0     2.556     37.88   \n",
       "1   8.301      21.0     6.238      0.972      2401.0     2.110     37.86   \n",
       "2   7.257      52.0     8.288      1.073       496.0     2.802     37.85   \n",
       "3   5.643      52.0     5.817      1.073       558.0     2.548     37.85   \n",
       "4   3.846      52.0     6.282      1.081       565.0     2.181     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load California Housing dataset\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "california = fetch_california_housing(as_frame=True)\n",
    "df = california.frame\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFeatures: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Reading the output:**\n\nThe dataset has **20,640 rows** (one per census block-group) and **9 columns** â€” 8 features plus the target `MedHouseVal`. The `.head()` preview shows the first five rows with all columns visible. Key things to notice:\n\n- **MedInc** (median income, in \\$10k units) varies noticeably even in these five rows, hinting at its strong predictive power.\n- **Latitude / Longitude** are geographic coordinates â€” they encode *location*, which heavily influences California house prices.\n- **MedHouseVal** (target) is measured in \\$100k units, so a value of 4.526 means a median price of \\~\\$452,600.\n- All values are numeric floats â€” there are no string or categorical columns to worry about in this dataset.\n\n**Why this matters:** Understanding the shape and units of your data before writing any pipeline code prevents surprises later (e.g., accidentally treating Latitude as a feature that needs one-hot encoding).\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "> ðŸ’¡ **Gemini Prompt:** \"Split the California Housing data into features (`X`) and target (`y`, column `MedHouseVal`). Then create a 60/20/20 train/validation/test split using `train_test_split` with `random_state=474`. Print the number of samples and percentage for each split.\"\n>\n> **After running, verify:**\n> - Train set is \\~12,384 samples (\\~60%)\n> - Validation set is \\~4,128 samples (\\~20%)\n> - Test set is \\~4,128 samples (\\~20%)\n> - Percentages sum to 100%"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SPLIT SIZES ===\n",
      "Train: 12384 samples (60.0%)\n",
      "Validation: 4128 samples (20.0%)\n",
      "Test: 4128 samples (20.0%)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df.drop(columns=['MedHouseVal'])\n",
    "y = df['MedHouseVal']\n",
    "\n",
    "# Split: 60% train, 20% validation, 20% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(\"=== SPLIT SIZES ===\")\n",
    "print(f\"Train: {len(X_train)} samples ({len(X_train)/len(df)*100:.1f}%)\")\n",
    "print(f\"Validation: {len(X_val)} samples ({len(X_val)/len(df)*100:.1f}%)\")\n",
    "print(f\"Test: {len(X_test)} samples ({len(X_test)/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Reading the output:**\n\nThe split produces three non-overlapping subsets:\n\n- **Train:** \\~12,384 samples (60.0 %) â€” used to fit model parameters.\n- **Validation:** \\~4,128 samples (20.0 %) â€” used to tune hyperparameters and compare models.\n- **Test:** \\~4,128 samples (20.0 %) â€” held out until the very end to estimate real-world performance.\n\nThe two-step `train_test_split` strategy (first carve off 20 % for test, then split the remaining 80 % into 75/25 to get 60/20) is the course standard. Using `random_state=RANDOM_SEED` (474) ensures these exact same rows land in each subset every time the notebook is run.\n\n**Key takeaway:** All preprocessing decisions (imputer statistics, scaler means/stds) will be computed on the training set only. The validation and test sets exist solely for *evaluation* â€” never for fitting.\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Audit Report Function\n",
    "\n",
    "Before applying any transformation, a professional data scientist audits the training data for **data types**, **missing values**, and **cardinality** (unique-value counts). The function below wraps those checks into a single reusable report. Running it on every split lets you confirm that the train, validation, and test sets share the same schema â€” a simple but critical sanity check that catches silent errors early."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ðŸ’¡ **Gemini Prompt:** \"Write a Python function `make_data_report(df, name)` that prints a formatted data audit report showing: the DataFrame shape, a table with each column's dtype, missing count, missing percentage, unique count, and unique percentage, plus a summary of total missing values and column type counts. Return the report as a DataFrame. Then run it on `X_train`.\"\n",
    ">\n",
    "> **After running, verify:**\n",
    "> - Report shows all 8 feature columns (no target column)\n",
    "> - All columns have dtype `float64`\n",
    "> - Missing count is 0 for all columns (California Housing has no missing data)\n",
    "> - Non-numeric columns count is 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA AUDIT REPORT: Training Set\n",
      "============================================================\n",
      "\n",
      "Shape: 12,384 rows Ã— 8 columns\n",
      "\n",
      "=== COLUMN AUDIT ===\n",
      "              dtype  missing_count  missing_pct  unique_count  unique_pct\n",
      "MedInc      float64              0          0.0          8707       70.31\n",
      "HouseAge    float64              0          0.0            52        0.42\n",
      "AveRooms    float64              0          0.0         11853       95.71\n",
      "AveBedrms   float64              0          0.0          9475       76.51\n",
      "Population  float64              0          0.0          3320       26.81\n",
      "AveOccup    float64              0          0.0         11609       93.74\n",
      "Latitude    float64              0          0.0           806        6.51\n",
      "Longitude   float64              0          0.0           799        6.45\n",
      "\n",
      "=== SUMMARY ===\n",
      "Total missing values: 0\n",
      "Columns with missing data: 0\n",
      "Numeric columns: 8\n",
      "Non-numeric columns: 0\n"
     ]
    }
   ],
   "source": [
    "def make_data_report(df, name=\"Dataset\"):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive data audit report.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The dataframe to audit\n",
    "    name : str\n",
    "        Name of the dataset for reporting\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Report with types, missingness, and unique counts\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"DATA AUDIT REPORT: {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"\\nShape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
    "    \n",
    "    # Build report dataframe\n",
    "    report = pd.DataFrame({\n",
    "        'dtype': df.dtypes,\n",
    "        'missing_count': df.isnull().sum(),\n",
    "        'missing_pct': (df.isnull().sum() / len(df) * 100).round(2),\n",
    "        'unique_count': df.nunique(),\n",
    "        'unique_pct': (df.nunique() / len(df) * 100).round(2)\n",
    "    })\n",
    "    \n",
    "    print(\"\\n=== COLUMN AUDIT ===\")\n",
    "    print(report)\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\n=== SUMMARY ===\")\n",
    "    print(f\"Total missing values: {df.isnull().sum().sum():,}\")\n",
    "    print(f\"Columns with missing data: {(df.isnull().sum() > 0).sum()}\")\n",
    "    print(f\"Numeric columns: {df.select_dtypes(include=[np.number]).shape[1]}\")\n",
    "    print(f\"Non-numeric columns: {df.select_dtypes(exclude=[np.number]).shape[1]}\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Run audit on training data\n",
    "train_report = make_data_report(X_train, \"Training Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Reading the output:**\n\nThe audit report for the **Training Set** shows:\n\n- **Shape:** \\~12,384 rows Ã— 8 columns (60 % of 20,640 â€” exactly the training portion from our 60/20/20 split).\n- **Data types:** All 8 features are `float64` â€” no type conversions needed.\n- **Missing values:** Zero across every column. In real-world projects, this row would rarely be all zeros, so having the check in place is important for the day you encounter incomplete data.\n- **Unique counts:** Features like Latitude and Longitude have thousands of unique values (continuous), while HouseAge has only \\~52 (discrete, capped at 52 years by the census).\n\n**Why this matters:** Running this report *on the training set only* establishes the baseline data profile. When you compare it to the validation and test reports (next cell), any schema mismatch â€” different types, unexpected missingness, or wildly different unique counts â€” would signal a problem in how the splits were created.\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ PAUSE-AND-DO Exercise 1 (5 minutes)\n",
    "\n",
    "**Task:** Implement `make_data_report(df)` that returns types, missingness %, and unique counts.\n",
    "\n",
    "**Instructions:**\n",
    "1. The function is already implemented above\n",
    "2. Run it on `X_train`, `X_val`, and `X_test`\n",
    "3. Document any differences you observe between splits\n",
    "4. Write your observations in the cell below\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "> ðŸ’¡ **Gemini Prompt:** \"Run the `make_data_report` function on the validation set (`X_val`) and test set (`X_test`) to audit both splits.\"\n>\n> **After running, verify:**\n> - Both reports show the same 8 feature columns as the training report\n> - Missing values are 0 across all columns in both splits\n> - Row counts match the expected validation (\\~4,128) and test (\\~4,128) sizes"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA AUDIT REPORT: Validation Set\n",
      "============================================================\n",
      "\n",
      "Shape: 4,128 rows Ã— 8 columns\n",
      "\n",
      "=== COLUMN AUDIT ===\n",
      "              dtype  missing_count  missing_pct  unique_count  unique_pct\n",
      "MedInc      float64              0          0.0          3417       82.78\n",
      "HouseAge    float64              0          0.0            51        1.24\n",
      "AveRooms    float64              0          0.0          4054       98.21\n",
      "AveBedrms   float64              0          0.0          3642       88.23\n",
      "Population  float64              0          0.0          2158       52.28\n",
      "AveOccup    float64              0          0.0          4028       97.58\n",
      "Latitude    float64              0          0.0           652       15.79\n",
      "Longitude   float64              0          0.0           659       15.96\n",
      "\n",
      "=== SUMMARY ===\n",
      "Total missing values: 0\n",
      "Columns with missing data: 0\n",
      "Numeric columns: 8\n",
      "Non-numeric columns: 0\n",
      "\n",
      "============================================================\n",
      "DATA AUDIT REPORT: Test Set\n",
      "============================================================\n",
      "\n",
      "Shape: 4,128 rows Ã— 8 columns\n",
      "\n",
      "=== COLUMN AUDIT ===\n",
      "              dtype  missing_count  missing_pct  unique_count  unique_pct\n",
      "MedInc      float64              0          0.0          3479       84.28\n",
      "HouseAge    float64              0          0.0            52        1.26\n",
      "AveRooms    float64              0          0.0          4055       98.23\n",
      "AveBedrms   float64              0          0.0          3653       88.49\n",
      "Population  float64              0          0.0          2141       51.87\n",
      "AveOccup    float64              0          0.0          4034       97.72\n",
      "Latitude    float64              0          0.0           653       15.82\n",
      "Longitude   float64              0          0.0           648       15.70\n",
      "\n",
      "=== SUMMARY ===\n",
      "Total missing values: 0\n",
      "Columns with missing data: 0\n",
      "Numeric columns: 8\n",
      "Non-numeric columns: 0\n"
     ]
    }
   ],
   "source": [
    "# Run audit on all splits\n",
    "val_report = make_data_report(X_val, \"Validation Set\")\n",
    "test_report = make_data_report(X_test, \"Test Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR OBSERVATIONS HERE:\n",
    "\n",
    "**Observation 1:**  \n",
    "[Document any differences in data types across splits]\n",
    "\n",
    "**Observation 2:**  \n",
    "[Document any missingness patterns]\n",
    "\n",
    "**Observation 3:**  \n",
    "[Document any unique value differences]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing Pipeline Template\n",
    "\n",
    "### 4.1 Identify Column Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ðŸ’¡ **Gemini Prompt:** \"Using `select_dtypes`, identify which columns in `X_train` are numeric and which are categorical. Store them in lists called `numeric_features` and `categorical_features`. Print both lists with counts.\"\n",
    ">\n",
    "> **After running, verify:**\n",
    "> - All 8 features are classified as numeric (`MedInc`, `HouseAge`, `AveRooms`, `AveBedrms`, `Population`, `AveOccup`, `Latitude`, `Longitude`)\n",
    "> - Categorical features list is empty (California Housing is all-numeric)\n",
    "> - Total count is 8 numeric + 0 categorical = 8 features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FEATURE TYPES ===\n",
      "\n",
      "Numeric features (8):\n",
      "  - MedInc\n",
      "  - HouseAge\n",
      "  - AveRooms\n",
      "  - AveBedrms\n",
      "  - Population\n",
      "  - AveOccup\n",
      "  - Latitude\n",
      "  - Longitude\n",
      "\n",
      "Categorical features (0):\n",
      "  (none)\n"
     ]
    }
   ],
   "source": [
    "# Identify numeric and categorical columns\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"=== FEATURE TYPES ===\")\n",
    "print(f\"\\nNumeric features ({len(numeric_features)}):\")\n",
    "for feat in numeric_features:\n",
    "    print(f\"  - {feat}\")\n",
    "\n",
    "print(f\"\\nCategorical features ({len(categorical_features)}):\")\n",
    "if categorical_features:\n",
    "    for feat in categorical_features:\n",
    "        print(f\"  - {feat}\")\n",
    "else:\n",
    "    print(\"  (none)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the output:**\n",
    "\n",
    "The audit shows **8 numeric features** (MedInc, HouseAge, AveRooms, AveBedrms, Population, AveOccup, Latitude, Longitude) and **0 categorical features**. This means every column in `X_train` is already numeric (`float64`).\n",
    "\n",
    "We use `select_dtypes(include=[np.number])` rather than hard-coding column names because it is **portable**: if a future dataset contains `object`-type columns (e.g., neighborhood names, zip codes), the same two lines will automatically route them into the categorical list without any code changes.\n",
    "\n",
    "**Why this matters:** Knowing the column types determines which preprocessing steps each group needs â€” numeric features get imputation and scaling, categorical features get imputation and one-hot encoding. This column-type split is the foundation of the `ColumnTransformer` we build next.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 4.2 Build Preprocessing Pipeline\n\n**Pipeline Design Principles:**\n1. Fit transformers ONLY on training data\n2. Apply the same transformation to validation and test\n3. Handle numeric and categorical features separately\n4. Chain all steps together to prevent leakage\n\n### Understanding Each Transformer Step\n\nBefore we write the code, let's understand **why** each component exists and what problem it solves.\n\n**Numeric Transformer** (`SimpleImputer` â†’ `StandardScaler`):\n\n| Step | What it does | Why we need it |\n|------|-------------|----------------|\n| `SimpleImputer(strategy='median')` | Fills every `NaN` in a numeric column with that column's **median**, computed from the training set only | Scikit-learn models **crash on `NaN`** â€” even a single missing value causes an error.<br><br>We choose **median** over mean because median is robust to outliers: a few mansions with 50 rooms won't distort the fill value the way they would distort the mean. |\n| `StandardScaler()` | Rescales each feature to **mean â‰ˆ 0, std â‰ˆ 1** | Features live on wildly different scales (MedInc: 0â€“15 vs. Population: 0â€“35,000).<br><br>Without scaling: (1) regularized models like Ridge and Lasso unfairly penalize large-scale features, (2) gradient-based optimizers converge slowly, and (3) distance-based models like KNN are dominated by the largest-scale feature. |\n\n**Categorical Transformer** (`SimpleImputer` â†’ `OneHotEncoder`):\n\n| Step | What it does | Why we need it |\n|------|-------------|----------------|\n| `SimpleImputer(strategy='constant', fill_value='missing')` | Fills every `NaN` in a text/categorical column with the literal string `\"missing\"` | We can't compute a median for text â€” there is no \"middle\" word.<br><br>Instead, we create an explicit `\"missing\"` category so the encoder has a valid string to work with.<br>Alternative: `strategy='most_frequent'` fills with the most common category. |\n| `OneHotEncoder(handle_unknown='ignore', sparse_output=False)` | Converts each category into a **separate binary (0/1) column** | Models need numbers, not strings.<br><br>E.g., a `Color` column with values [Red, Blue, Green] becomes three columns: `Color_Red`, `Color_Blue`, `Color_Green`, each containing 0 or 1.<br><br>The flag `handle_unknown='ignore'` means if the validation/test set contains a category never seen during training, it gets all-zero columns instead of crashing. |\n\n> **ðŸ’¡ \"But this dataset has no missing values and no categorical columns â€” why bother?\"**  \n> Because a production-grade pipeline must handle messy data gracefully. The imputer is a **no-op** today (nothing to fill), and the categorical transformer is **idle** (no text columns to encode). But when you later work with a real-world dataset that has gaps and string features, this same pipeline structure works without any code changes. Design for the general case; benefit today from the clean case."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ðŸ’¡ **Gemini Prompt:** \"Build a scikit-learn preprocessing pipeline using `ColumnTransformer`. For numeric features, create a sub-pipeline that applies `SimpleImputer(strategy='median')` then `StandardScaler()`. For categorical features, create a sub-pipeline with `SimpleImputer(strategy='constant', fill_value='missing')` then `OneHotEncoder(handle_unknown='ignore', sparse_output=False)`. Print a confirmation with the feature counts.\"\n",
    ">\n",
    "> **After running, verify:**\n",
    "> - Preprocessor is a `ColumnTransformer` with two transformers: `num` and `cat`\n",
    "> - Numeric features count is 8\n",
    "> - Categorical features count is 0\n",
    "> - No errors about missing column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Preprocessor pipeline created!\n",
      "\n",
      "Numeric features: 8\n",
      "Categorical features: 0\n"
     ]
    }
   ],
   "source": [
    "# Numeric preprocessing: impute + scale\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical preprocessing: impute + encode\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Combine transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not specified\n",
    ")\n",
    "\n",
    "print(\"âœ“ Preprocessor pipeline created!\")\n",
    "print(f\"\\nNumeric features: {len(numeric_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the output:**\n",
    "\n",
    "The confirmation message tells us the `ColumnTransformer` is ready with **8 numeric features** and **0 categorical features**. Under the hood, three data-flow paths are defined:\n",
    "\n",
    "1. **`num` path** (numeric columns) â†’ `SimpleImputer(strategy='median')` â†’ `StandardScaler()`. Median imputation is robust to outliers (recall AveRooms and AveOccup have extreme values). Standard scaling centers each feature to mean 0 and std 1, which benefits regularized models introduced in upcoming notebooks.\n",
    "2. **`cat` path** (categorical columns) â†’ `SimpleImputer(strategy='constant')` â†’ `OneHotEncoder()`. This path is currently idle because all features are numeric, but including it makes the pipeline **portable**: if you swap in a dataset with categorical columns, the same code works without changes.\n",
    "3. **`remainder='drop'`** â€” any column not explicitly listed is discarded. This is a safety net that prevents accidental target leakage.\n",
    "\n",
    "**Key takeaway:** Defining the transformer *before* seeing results forces you to think about each column group's needs up front â€” a habit that prevents ad-hoc, error-prone transformations later.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### 4.2.1 Beyond This Dataset: Handling Strings and Dates\n\nThe California Housing dataset is all-numeric, but real-world datasets often contain **text strings** and **date/time columns**. Here is how each type fits into the `ColumnTransformer` pattern we just built.\n\n**String / Text Columns:**\n\n| Scenario | Recommended Tool | Example Columns |\n|----------|-----------------|-----------------|\n| Few unique values (< \\~20) | `OneHotEncoder` (already in our `cat` pipeline) | Product color, U.S. state, payment method |\n| Ordered categories with a natural ranking | `OrdinalEncoder(categories=[['Low','Medium','High']])` | Education level, satisfaction rating, T-shirt size |\n| Free-form text (sentences, paragraphs) | `CountVectorizer` or `TfidfVectorizer` | Customer reviews, email subject lines |\n| Very high cardinality (1,000+ unique values) | `TargetEncoder` or frequency-based encoding | City name, product SKU, zip code |\n\n> **ðŸ’¡ Key distinction:** `OneHotEncoder` creates one column per category â€” great when categories are few, but it explodes the feature count when there are thousands of unique values. For high-cardinality columns, `TargetEncoder` (available in scikit-learn â‰¥ 1.3) replaces each category with the mean of the target for that category, producing just **one** numeric column.\n\n**Date / Datetime Columns:**\n\nDates are not directly usable by models â€” \"2027-06-01\" is a string, not a number. The standard approach is to **extract numeric features** from them before the data enters the pipeline:\n\n```python\n# Parse the date column (do this BEFORE building the pipeline)\ndf['date'] = pd.to_datetime(df['date'])\n\n# Extract useful numeric features\ndf['year']        = df['date'].dt.year\ndf['month']       = df['date'].dt.month\ndf['day_of_week'] = df['date'].dt.dayofweek   # 0=Monday, 6=Sunday\ndf['is_weekend']  = (df['date'].dt.dayofweek >= 5).astype(int)\ndf['quarter']     = df['date'].dt.quarter\n\n# Drop the original date column â€” the pipeline can't process it\ndf = df.drop(columns=['date'])\n```\n\nOnce extracted, these columns are **plain numbers** and flow through the numeric transformer (imputer + scaler) like any other feature.\n\n> **ðŸ’¡ Rule of thumb:** Convert dates to numbers *before* building the pipeline, then drop the original date column. The extracted features (month, day_of_week, is_weekend, etc.) carry the temporal signal that the model can learn from; the raw datetime string does not.\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Full Pipeline: Preprocessing + Model\n",
    "\n",
    "Scikit-learn's `Pipeline` chains the `ColumnTransformer` (preprocessing) with a `LinearRegression` (model) into **one callable object**. This design has three major benefits:\n",
    "\n",
    "1. **No leakage** â€” `pipeline.fit(X_train, y_train)` fits the scaler statistics *only* on training data; `pipeline.score(X_val, y_val)` transforms the validation set with those same statistics before predicting.\n",
    "2. **Deployment-ready** â€” you can serialize the pipeline with `joblib` and run `pipeline.predict(new_data)` in production without rewriting any preprocessing code.\n",
    "3. **Reproducibility** â€” the exact sequence of steps is recorded in the pipeline object itself, eliminating copy-paste errors between notebooks or scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ðŸ’¡ **Gemini Prompt:** \"Create a full scikit-learn `Pipeline` that chains the `preprocessor` (from the previous step) with a `LinearRegression` model. Print the pipeline structure, fit it on `X_train`/`y_train`, then compute and print the R-squared scores on both training and validation sets, along with their difference.\"\n",
    ">\n",
    "> **After running, verify:**\n",
    "> - Pipeline has two steps: `preprocessor` and `regressor`\n",
    "> - Train R-squared is approximately 0.61\n",
    "> - Validation R-squared is approximately 0.59â€“0.61\n",
    "> - The difference (train minus validation) is small (< 0.03), indicating no severe overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FULL PIPELINE ===\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='median')),\n",
      "                                                                  ('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  ['MedInc', 'HouseAge',\n",
      "                                                   'AveRooms', 'AveBedrms',\n",
      "                                                   'Population', 'AveOccup',\n",
      "                                                   'Latitude', 'Longitude']),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(fill_value='missing',\n",
      "                                                                                 strategy='constant')),\n",
      "                                                                  ('encoder',\n",
      "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
      "                                                                                 sparse_output=False))]),\n",
      "                                                  [])])),\n",
      "                ('regressor', LinearRegression())])\n",
      "\n",
      "Fitting pipeline on training data...\n",
      "âœ“ Pipeline fitted!\n",
      "\n",
      "=== SCORES ===\n",
      "Train RÂ²: 0.6035\n",
      "Validation RÂ²: 0.6169\n",
      "Difference: -0.0133\n"
     ]
    }
   ],
   "source": [
    "# Create full pipeline: preprocessing + model\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "print(\"=== FULL PIPELINE ===\")\n",
    "print(full_pipeline)\n",
    "\n",
    "# Fit on training data ONLY\n",
    "print(\"\\nFitting pipeline on training data...\")\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "print(\"âœ“ Pipeline fitted!\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "train_score = full_pipeline.score(X_train, y_train)\n",
    "val_score = full_pipeline.score(X_val, y_val)\n",
    "\n",
    "print(f\"\\n=== SCORES ===\")\n",
    "print(f\"Train RÂ²: {train_score:.4f}\")\n",
    "print(f\"Validation RÂ²: {val_score:.4f}\")\n",
    "print(f\"Difference: {train_score - val_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Reading the output:**\n\nThe printed `Pipeline` object shows the two-step chain: first the `ColumnTransformer` (preprocessing), then `LinearRegression` (model). After fitting on the training set only, we obtain:\n\n- **Train RÂ² â‰ˆ 0.6035** â€” the model explains about 60 % of the variance in median house values on the data it was trained on.\n- **Validation RÂ² â‰ˆ 0.6169** â€” performance on unseen validation data is essentially the same (even slightly higher due to random-split variation).\n- **Difference â‰ˆ âˆ’0.01** â€” the tiny gap (and the fact that validation is not *lower*) tells us there is **no overfitting**. The model is equally mediocre on both sets, which is the hallmark of a high-bias, low-variance linear model.\n\n**Why this matters:** An RÂ² of \\~0.60 is a reasonable *baseline*. It means that a simple linear combination of the 8 features already captures the dominant income-drives-house-value relationship. In the next notebooks, we will try feature engineering and more flexible models (trees, ensembles) to push this number higher â€” but this pipeline ensures we always have a disciplined, leak-free starting point.\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Inspecting the Pipeline\n",
    "\n",
    "Understanding what features are created:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ðŸ’¡ **Gemini Prompt:** \"Extract the transformed feature names from the fitted pipeline using `get_feature_names_out()` on the preprocessor step. Print the total number of transformed features and list the first 10 names.\"\n",
    ">\n",
    "> **After running, verify:**\n",
    "> - Total transformed features equals 8 (all numeric, no one-hot expansion needed)\n",
    "> - Feature names are prefixed with `num__` (e.g., `num__MedInc`, `num__HouseAge`)\n",
    "> - All 8 original numeric feature names appear in the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRANSFORMED FEATURES ===\n",
      "Total features after preprocessing: 8\n",
      "\n",
      "First 10 features:\n",
      "  1. num__MedInc\n",
      "  2. num__HouseAge\n",
      "  3. num__AveRooms\n",
      "  4. num__AveBedrms\n",
      "  5. num__Population\n",
      "  6. num__AveOccup\n",
      "  7. num__Latitude\n",
      "  8. num__Longitude\n"
     ]
    }
   ],
   "source": [
    "# Get feature names after transformation\n",
    "try:\n",
    "    feature_names = full_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "    print(f\"=== TRANSFORMED FEATURES ===\")\n",
    "    print(f\"Total features after preprocessing: {len(feature_names)}\")\n",
    "    print(f\"\\nFirst 10 features:\")\n",
    "    for i, name in enumerate(feature_names[:10], 1):\n",
    "        print(f\"  {i}. {name}\")\n",
    "    \n",
    "    if len(feature_names) > 10:\n",
    "        print(f\"  ... and {len(feature_names) - 10} more\")\n",
    "except:\n",
    "    print(\"Feature names not available (older sklearn version)\")\n",
    "    print(f\"Estimated features: {len(numeric_features)} numeric features (scaled)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the output:**\n",
    "\n",
    "The `get_feature_names_out()` method lists every column that exits the `ColumnTransformer`. Each name carries a **prefix** that traces it back to the transformer that created it:\n",
    "\n",
    "- `num__MedInc`, `num__HouseAge`, â€¦ â€” the 8 original numeric features, now standardized (mean â‰ˆ 0, std â‰ˆ 1) by the `num` pipeline.\n",
    "\n",
    "Since the dataset has **zero categorical columns**, only the `num` transformer fires; the `cat` transformer produces no output columns, and `remainder='drop'` discards nothing because every column is already routed. The result is **8 features in â†’ 8 features out**, just rescaled.\n",
    "\n",
    "**Why this matters:** Being able to map transformed columns back to their original names is essential for model interpretation. When you inspect linear-regression coefficients or feature-importance scores in upcoming notebooks, these prefixed names will tell you exactly which feature each value belongs to.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ PAUSE-AND-DO Exercise 2 (5 minutes)\n",
    "\n",
    "**Task:** Create a full sklearn Pipeline and run one validation score.\n",
    "\n",
    "**Instructions:**\n",
    "1. The pipeline is already created above\n",
    "2. Modify the pipeline to try different imputation strategies:\n",
    "   - Change median to mean for numeric features\n",
    "   - Try different imputation for categorical features\n",
    "3. Compare the validation scores\n",
    "4. Document your findings below\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ðŸ’¡ **Gemini Prompt:** \"Create an alternative preprocessing pipeline that uses `SimpleImputer(strategy='mean')` instead of median for numeric features, keeping everything else the same. Fit it with `LinearRegression`, evaluate on train and validation sets, and print a comparison table showing both pipelines' R-squared scores side by side.\"\n",
    ">\n",
    "> **After running, verify:**\n",
    "> - Both pipelines produce similar R-squared values (California Housing has no missing data, so imputation strategy has minimal impact)\n",
    "> - The difference in validation scores between mean and median imputation is very small (< 0.001)\n",
    "> - Train scores are slightly higher than validation scores for both pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARISON ===\n",
      "\n",
      "Original (median imputation):\n",
      "  Train RÂ²: 0.6035\n",
      "  Val RÂ²: 0.6169\n",
      "\n",
      "Alternative (mean imputation):\n",
      "  Train RÂ²: 0.6035\n",
      "  Val RÂ²: 0.6169\n",
      "\n",
      "Difference in validation score: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE: Experiment with different preprocessing strategies\n",
    "\n",
    "# Example: Try mean imputation instead of median\n",
    "numeric_transformer_v2 = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Changed from median\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor_v2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer_v2, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "full_pipeline_v2 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_v2),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit and evaluate\n",
    "full_pipeline_v2.fit(X_train, y_train)\n",
    "train_score_v2 = full_pipeline_v2.score(X_train, y_train)\n",
    "val_score_v2 = full_pipeline_v2.score(X_val, y_val)\n",
    "\n",
    "print(\"=== COMPARISON ===\")\n",
    "print(f\"\\nOriginal (median imputation):\")\n",
    "print(f\"  Train RÂ²: {train_score:.4f}\")\n",
    "print(f\"  Val RÂ²: {val_score:.4f}\")\n",
    "\n",
    "print(f\"\\nAlternative (mean imputation):\")\n",
    "print(f\"  Train RÂ²: {train_score_v2:.4f}\")\n",
    "print(f\"  Val RÂ²: {val_score_v2:.4f}\")\n",
    "\n",
    "print(f\"\\nDifference in validation score: {val_score_v2 - val_score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the output:**\n",
    "\n",
    "The comparison table shows that the **median-imputation** and **mean-imputation** pipelines produce virtually identical RÂ² scores on both the training and validation sets. The difference in validation RÂ² is on the order of **10â»â¶** â€” essentially zero.\n",
    "\n",
    "This is expected: the California Housing dataset has **zero missing values**, so `SimpleImputer` is a no-op regardless of strategy. Neither median nor mean imputation actually changes any value.\n",
    "\n",
    "**Key takeaway:** The imputer is included in the pipeline not because this dataset needs it, but because a *production-grade* pipeline must handle missing data gracefully when new, unseen records arrive. Designing the pipeline once â€” even if the imputer does nothing today â€” saves you from rewriting code the moment real-world messiness appears.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR FINDINGS HERE:\n",
    "\n",
    "**Finding 1:**  \n",
    "[Compare the two imputation strategies]\n",
    "\n",
    "**Finding 2:**  \n",
    "[Discuss which performs better and why]\n",
    "\n",
    "**Finding 3:**  \n",
    "[Any other observations about the pipeline]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gemini Prompt Cards for Pipeline Generation\n",
    "\n",
    "### Example Prompts:\n",
    "\n",
    "**Prompt 1: Generate Pipeline**\n",
    "```\n",
    "Create a scikit-learn pipeline that:\n",
    "1. Imputes missing values (median for numeric, most_frequent for categorical)\n",
    "2. Scales numeric features using StandardScaler\n",
    "3. Encodes categorical features using OneHotEncoder\n",
    "4. Fits a LinearRegression model\n",
    "\n",
    "Use ColumnTransformer to handle different feature types separately.\n",
    "```\n",
    "\n",
    "**Prompt 2: Debug Pipeline**\n",
    "```\n",
    "I'm getting an error when fitting my pipeline: [error message]\n",
    "My pipeline code is: [code]\n",
    "Help me debug this issue and explain what's wrong.\n",
    "```\n",
    "\n",
    "**Prompt 3: Extend Pipeline**\n",
    "```\n",
    "I have a working pipeline with imputation and scaling.\n",
    "How can I add polynomial features (degree=2) only to numeric features\n",
    "while keeping the categorical encoding unchanged?\n",
    "```\n",
    "\n",
    "**Remember:** After using Gemini, always:\n",
    "1. Verify the code runs without errors\n",
    "2. Check the output makes sense\n",
    "3. Add your own comments explaining each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pipeline Done Right Checklist\n",
    "\n",
    "Before moving on, verify your pipeline meets these standards:\n",
    "\n",
    "### âœ“ Pre-fitting Checks:\n",
    "- [ ] Split data BEFORE building pipeline\n",
    "- [ ] Identified all numeric and categorical features\n",
    "- [ ] Handled missing values with appropriate strategy\n",
    "- [ ] Separate transformers for different feature types\n",
    "\n",
    "### âœ“ Fitting Checks:\n",
    "- [ ] Pipeline fitted ONLY on training data\n",
    "- [ ] No data leakage from validation or test sets\n",
    "- [ ] All preprocessing steps are inside the pipeline\n",
    "- [ ] Model is the last step in the pipeline\n",
    "\n",
    "### âœ“ Evaluation Checks:\n",
    "- [ ] Evaluated on validation set (not test set)\n",
    "- [ ] Training and validation scores are reasonable\n",
    "- [ ] No major signs of overfitting (huge train/val gap)\n",
    "- [ ] Pipeline can transform new data without refitting\n",
    "\n",
    "### âœ“ Code Quality:\n",
    "- [ ] All parameters are explicit (no hidden defaults)\n",
    "- [ ] Steps are named clearly\n",
    "- [ ] Comments explain \"why\" not just \"what\"\n",
    "- [ ] Can explain every step if asked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Wrap-Up: Key Takeaways\n",
    "\n",
    "### What We Learned Today:\n",
    "\n",
    "1. **Data Auditing**: Systematic checks for types, missingness, and unique values\n",
    "2. **Preprocessing Patterns**: Separate handling for numeric vs categorical features\n",
    "3. **Pipeline Architecture**: ColumnTransformer + Pipeline prevents leakage\n",
    "4. **Fit/Transform Discipline**: Fit on train, transform on train/val/test\n",
    "5. **Gemini Integration**: Use AI to draft, then verify and document\n",
    "\n",
    "### Critical Rules:\n",
    "\n",
    "> **\"Fit ONLY on training data\"**  \n",
    "> Any statistics (mean, median, categories) must be computed from training data only.\n",
    "\n",
    "> **\"Pipeline wraps everything\"**  \n",
    "> If you do it manually, you risk leakage. Put it in the pipeline.\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- The next notebook will cover regression metrics and baseline models\n",
    "- We'll use today's pipeline structure for all future models\n",
    "- Start thinking about your project dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participation Assignment Submission Instructions\n",
    "\n",
    "### To Submit This Notebook:\n",
    "\n",
    "1. **Complete all exercises**: Fill in both PAUSE-AND-DO exercise cells with your findings\n",
    "2. **Run All Cells**: Execute `Runtime â†’ Run all` to ensure everything works\n",
    "3. **Save a Copy**: `File â†’ Save a copy in Drive or Download the .ipynb extension`\n",
    "4. **Submit**: Upload your `.ipynb` file in the participation assignment you find in the course Brightspace page.\n",
    "\n",
    "### Before Submitting, Check:\n",
    "\n",
    "- [ ] All cells execute without errors\n",
    "- [ ] All outputs are visible\n",
    "- [ ] Both exercise responses are complete\n",
    "- [ ] Notebook is shared with correct permissions\n",
    "- [ ] You can explain every line of code you wrote\n",
    "\n",
    "### Next Step:\n",
    "\n",
    "Complete the **Quiz** in Brightspace (auto-graded)\n",
    "\n",
    "---\n",
    "\n",
    "## Bibliography\n",
    "\n",
    "- scikit-learn User Guide: [Pipelines and composite estimators](https://scikit-learn.org/stable/modules/compose.html)\n",
    "- scikit-learn User Guide: [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html)\n",
    "- scikit-learn User Guide: [Preprocessing data](https://scikit-learn.org/stable/modules/preprocessing.html)\n",
    "- Pedregosa et al. (2011). \"Scikit-learn: Machine Learning in Python.\" *Journal of Machine Learning Research*, 12, 2825-2830.\n",
    "- James, G., Witten, D., Hastie, T., & Tibshirani, R. (2021). *An Introduction to Statistical Learning with Python* (ISLP). Springer.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "Thank you!\n",
    "\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}