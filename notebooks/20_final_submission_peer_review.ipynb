{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Delivery - Project Package Submission + Peer Review\n",
    "\n",
    "<hr>\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "<img src=\"https://raw.githubusercontent.com/davi-moreira/2026Summer_predictive_analytics_purdue_MGMT474/main/notebooks/figures/mgmt_474_ai_logo_02-modified.png\" width=\"200\"/>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "# <center><a class=\"tocSkip\"></center>\n",
    "# <center>MGMT47400 Predictive Analytics</center>\n",
    "# <center>Professor: Davi Moreira </center>\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/davi-moreira/2026Summer_predictive_analytics_purdue_MGMT474/blob/main/notebooks/20_final_submission_peer_review.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Deliver a complete end-to-end predictive analytics package\n",
    "2. Produce an executive-ready deck and a conference-style video\n",
    "3. Demonstrate reproducibility (run-all notebook, documented choices)\n",
    "4. Evaluate peers' work using a structured rubric and provide actionable feedback\n",
    "5. Write a concise postmortem: what worked, what didn't, what you'd do next\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup: Imports and Display Settings\n",
    "\n",
    "First, let's set up our environment for final review and submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install pandas numpy matplotlib seaborn --quiet\n",
    "\n",
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "# Display settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 3)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"\u2713 Setup complete!\")\n",
    "print(f\"Final submission date: {datetime.now().strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the output:**\n",
    "\n",
    "The `Setup complete!` line confirms that pandas, numpy, matplotlib, seaborn,\n",
    "and `json` are all loaded. The **final submission date** is printed so the\n",
    "notebook timestamp matches the date you run your last audit. No modelling\n",
    "libraries are needed here because this notebook focuses on review,\n",
    "submission logistics, and peer evaluation.\n",
    "\n",
    "**Why this matters:** Even an audit-focused notebook should run cleanly\n",
    "from top to bottom, proving that you practise what you preach about\n",
    "reproducibility.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. Final Self-Audit Checklist\n",
    "\n",
    "### Why Self-Audit?\n",
    "\n",
    "> **\"Graders check the basics first. If those fail, they may not see your best work.\"**  \n",
    "> A thorough self-audit prevents avoidable mistakes.\n",
    "\n",
    "### 2.1 Technical Reproducibility Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technical reproducibility checklist\n",
    "technical_audit = pd.DataFrame([\n",
    "    {\n",
    "        'Category': 'Notebook Execution',\n",
    "        'Item': 'Restart kernel completed',\n",
    "        'How to Check': 'Runtime \u2192 Restart runtime',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'CRITICAL'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Notebook Execution',\n",
    "        'Item': 'Run All completed without errors',\n",
    "        'How to Check': 'Runtime \u2192 Run all (watch for red error messages)',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'CRITICAL'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Notebook Execution',\n",
    "        'Item': 'All outputs visible',\n",
    "        'How to Check': 'Scroll through entire notebook',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'CRITICAL'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Notebook Execution',\n",
    "        'Item': 'No deprecated warnings (or documented)',\n",
    "        'How to Check': 'Check for yellow warning messages',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'HIGH'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Data & Splits',\n",
    "        'Item': 'Data source documented',\n",
    "        'How to Check': 'URL or citation present',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'HIGH'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Data & Splits',\n",
    "        'Item': 'Train/val/test splits clearly labeled',\n",
    "        'How to Check': 'Variable names and sizes printed',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'HIGH'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Data & Splits',\n",
    "        'Item': 'No test set leakage',\n",
    "        'How to Check': 'Test set only used in final evaluation',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'CRITICAL'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Data & Splits',\n",
    "        'Item': 'Random seeds documented',\n",
    "        'How to Check': 'RANDOM_SEED variable defined and used consistently',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'HIGH'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Modeling',\n",
    "        'Item': 'Baseline model included',\n",
    "        'How to Check': 'Simple baseline (majority class, mean, etc.) reported',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'HIGH'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Modeling',\n",
    "        'Item': 'Multiple models compared',\n",
    "        'How to Check': 'At least 2-3 different approaches tried',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'HIGH'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Modeling',\n",
    "        'Item': 'Model selection justified',\n",
    "        'How to Check': 'Clear explanation of why final model was chosen',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'HIGH'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Modeling',\n",
    "        'Item': 'Hyperparameter tuning documented',\n",
    "        'How to Check': 'Process and results shown',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'MEDIUM'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Evaluation',\n",
    "        'Item': 'Appropriate metrics chosen',\n",
    "        'How to Check': 'Metrics match problem type and business goals',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'HIGH'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Evaluation',\n",
    "        'Item': 'Validation strategy documented',\n",
    "        'How to Check': 'Cross-validation or hold-out clearly explained',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'HIGH'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Evaluation',\n",
    "        'Item': 'Final test set results reported',\n",
    "        'How to Check': 'Test metrics clearly stated',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'CRITICAL'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Artifacts',\n",
    "        'Item': 'Model saved (joblib or pickle)',\n",
    "        'How to Check': 'Save/load code present and tested',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'HIGH'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Artifacts',\n",
    "        'Item': 'Configuration saved separately',\n",
    "        'How to Check': 'CONFIG dict or JSON file',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'MEDIUM'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Code Quality',\n",
    "        'Item': 'No debug code or TODOs',\n",
    "        'How to Check': 'Search for \"TODO\", \"FIXME\", \"print\"',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'MEDIUM'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Code Quality',\n",
    "        'Item': 'Imports organized at top',\n",
    "        'How to Check': 'All imports in setup cell',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'MEDIUM'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Code Quality',\n",
    "        'Item': 'Functions have docstrings',\n",
    "        'How to Check': 'Key functions documented',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'MEDIUM'\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"=== TECHNICAL REPRODUCIBILITY AUDIT ===\")\n",
    "print(technical_audit.to_string(index=False))\n",
    "\n",
    "# Summary by priority\n",
    "print(\"\\n=== PRIORITY SUMMARY ===\")\n",
    "priority_counts = technical_audit['Priority'].value_counts()\n",
    "for priority in ['CRITICAL', 'HIGH', 'MEDIUM']:\n",
    "    if priority in priority_counts:\n",
    "        print(f\"{priority}: {priority_counts[priority]} items\")\n",
    "\n",
    "# Save audit\n",
    "technical_audit.to_csv('technical_audit.csv', index=False)\n",
    "print(\"\\n\u2713 Technical audit saved to technical_audit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the output:**\n",
    "\n",
    "The technical audit table lists **20 items** across five categories:\n",
    "Notebook Execution, Data & Splits, Modeling, Evaluation, Artifacts, and\n",
    "Code Quality. Each item shows a concrete 'How to Check' action and a\n",
    "priority level (**CRITICAL**, **HIGH**, or **MEDIUM**). The priority\n",
    "summary at the bottom tells you how many items fall into each tier. Focus\n",
    "on clearing all CRITICAL items first -- a notebook that cannot Run All is\n",
    "an automatic failure, regardless of model sophistication.\n",
    "\n",
    "**Key takeaway:** Treat the CRITICAL items as non-negotiable gates. Only\n",
    "move on to HIGH and MEDIUM items once every CRITICAL checkbox is ticked.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "### 2.2 Communication Quality Audit\n",
    "\n",
    "Technical correctness is necessary but not sufficient -- your notebook also\n",
    "needs to *communicate* clearly. This audit covers structure (logical flow,\n",
    "summary present), documentation (markdown explains the 'why', key findings\n",
    "highlighted), visualisation quality (titles, labels, relevance), and\n",
    "professionalism (consistent formatting, bibliography, no placeholder text).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Communication quality checklist\n",
    "communication_audit = pd.DataFrame([\n",
    "    {\n",
    "        'Category': 'Structure',\n",
    "        'Item': 'Clear title and introduction',\n",
    "        'How to Check': 'First cell has project title and context',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'HIGH'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Structure',\n",
    "        'Item': 'Logical section flow',\n",
    "        'How to Check': 'Sections follow standard order (EDA \u2192 Preprocessing \u2192 Modeling \u2192 Evaluation)',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'HIGH'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Structure',\n",
    "        'Item': 'Summary/conclusion present',\n",
    "        'How to Check': 'Final section summarizes key findings',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'HIGH'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Documentation',\n",
    "        'Item': 'Markdown cells explain \"why\"',\n",
    "        'How to Check': 'Each section has explanation before code',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'HIGH'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Documentation',\n",
    "        'Item': 'Key findings highlighted',\n",
    "        'How to Check': 'Important results are called out clearly',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'HIGH'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Documentation',\n",
    "        'Item': 'Assumptions stated explicitly',\n",
    "        'How to Check': 'Key assumptions documented',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'MEDIUM'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Visualizations',\n",
    "        'Item': 'All plots have titles',\n",
    "        'How to Check': 'Every visualization has descriptive title',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'HIGH'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Visualizations',\n",
    "        'Item': 'Axes are labeled',\n",
    "        'How to Check': 'X and Y axes have clear labels',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'HIGH'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Visualizations',\n",
    "        'Item': 'Visualizations support narrative',\n",
    "        'How to Check': 'Each plot has a purpose and explanation',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'MEDIUM'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Tables',\n",
    "        'Item': 'Tables are formatted',\n",
    "        'How to Check': 'DataFrames displayed clearly',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'MEDIUM'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Tables',\n",
    "        'Item': 'Key values highlighted',\n",
    "        'How to Check': 'Important numbers are called out',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'MEDIUM'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Professionalism',\n",
    "        'Item': 'Consistent formatting',\n",
    "        'How to Check': 'Headers, fonts, spacing consistent throughout',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'MEDIUM'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Professionalism',\n",
    "        'Item': 'No typos in key sections',\n",
    "        'How to Check': 'Spell-check title, headers, conclusions',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'MEDIUM'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Professionalism',\n",
    "        'Item': 'Bibliography included',\n",
    "        'How to Check': 'References section at end',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'MEDIUM'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Professionalism',\n",
    "        'Item': 'Author and date documented',\n",
    "        'How to Check': 'Name and date in header',\n",
    "        'Status': '\u25a1',\n",
    "        'Priority': 'LOW'\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"=== COMMUNICATION QUALITY AUDIT ===\")\n",
    "print(communication_audit.to_string(index=False))\n",
    "\n",
    "# Save audit\n",
    "communication_audit.to_csv('communication_audit.csv', index=False)\n",
    "print(\"\\n\u2713 Communication audit saved to communication_audit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the output:**\n",
    "\n",
    "The communication audit has **15 items** grouped into Structure,\n",
    "Documentation, Visualizations, Tables, and Professionalism. Unlike the\n",
    "technical audit, most items here are **HIGH** or **MEDIUM** priority\n",
    "because they affect readability rather than correctness. Pay particular\n",
    "attention to the Visualizations section: unlabelled axes and missing\n",
    "titles are among the most frequent deductions on presentation-heavy\n",
    "assignments.\n",
    "\n",
    "**Why this matters:** An evaluator's first impression of your notebook is\n",
    "formed by its structure and visual polish. A well-documented notebook\n",
    "signals rigour even before the evaluator reads a single line of code.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## \ud83d\udcdd PAUSE-AND-DO Exercise 1 (5 minutes)\n",
    "\n",
    "**Task:** Run-all audit and fix one reproducibility issue (real or simulated).\n",
    "\n",
    "**Instructions:**\n",
    "1. Open your project notebook\n",
    "2. Restart kernel: `Runtime \u2192 Restart runtime`\n",
    "3. Run all cells: `Runtime \u2192 Run all`\n",
    "4. Watch for errors, warnings, or missing outputs\n",
    "5. If you find an issue, fix it and re-run\n",
    "6. If no issues, simulate one and document how you'd fix it\n",
    "7. Document your findings below\n",
    "\n",
    "**Common issues to check:**\n",
    "- Missing imports\n",
    "- Variables used before definition\n",
    "- File paths that don't exist\n",
    "- Cells that depend on manual execution order\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### YOUR AUDIT RESULTS HERE:\n",
    "\n",
    "**Run-all status:**  \n",
    "[Did all cells execute successfully? Yes/No]\n",
    "\n",
    "**Issues found:**  \n",
    "1. [Describe any errors or warnings]\n",
    "2. [List any missing outputs]\n",
    "3. [Note any other problems]\n",
    "\n",
    "**Fixes applied:**  \n",
    "1. [How you fixed issue #1]\n",
    "2. [How you fixed issue #2]\n",
    "3. [How you fixed issue #3]\n",
    "\n",
    "**Verification:**  \n",
    "[Did run-all succeed after fixes? Yes/No]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 3. Submission Links and Artifact Manifest\n",
    "\n",
    "### 3.1 Artifact Manifest Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create artifact manifest\n",
    "artifact_manifest = {\n",
    "    'project_info': {\n",
    "        'title': '[Your Project Title]',\n",
    "        'author': '[Your Name]',\n",
    "        'submission_date': datetime.now().strftime('%Y-%m-%d'),\n",
    "        'course': 'MGMT 47400 - Predictive Analytics',\n",
    "        'term': '2027 Summer'\n",
    "    },\n",
    "    'deliverables': {\n",
    "        'notebook': {\n",
    "            'description': 'Complete analysis notebook with run-all outputs',\n",
    "            'format': 'Jupyter Notebook (.ipynb)',\n",
    "            'link': '[Colab link here]',\n",
    "            'status': 'REQUIRED',\n",
    "            'submitted': False\n",
    "        },\n",
    "        'slide_deck': {\n",
    "            'description': 'Executive presentation (10-12 slides)',\n",
    "            'format': 'PDF or PowerPoint',\n",
    "            'link': '[Upload link here]',\n",
    "            'status': 'REQUIRED',\n",
    "            'submitted': False\n",
    "        },\n",
    "        'video': {\n",
    "            'description': 'Conference-style video presentation (2-3 min)',\n",
    "            'format': 'MP4',\n",
    "            'link': '[Video link here]',\n",
    "            'status': 'REQUIRED',\n",
    "            'submitted': False\n",
    "        },\n",
    "        'model_artifacts': {\n",
    "            'description': 'Saved model pipeline and configuration',\n",
    "            'format': 'joblib + JSON',\n",
    "            'link': '[GitHub/Drive link here]',\n",
    "            'status': 'REQUIRED',\n",
    "            'submitted': False\n",
    "        },\n",
    "        'monitoring_plan': {\n",
    "            'description': 'Production monitoring plan',\n",
    "            'format': 'CSV or PDF',\n",
    "            'link': '[Link or \"Included in notebook\"]',\n",
    "            'status': 'REQUIRED',\n",
    "            'submitted': False\n",
    "        },\n",
    "        'model_card': {\n",
    "            'description': 'Model documentation (use case, data, performance, limitations)',\n",
    "            'format': 'Markdown section in notebook',\n",
    "            'link': 'Included in notebook',\n",
    "            'status': 'RECOMMENDED',\n",
    "            'submitted': False\n",
    "        }\n",
    "    },\n",
    "    'validation': {\n",
    "        'notebook_run_all': False,\n",
    "        'all_outputs_visible': False,\n",
    "        'links_tested': False,\n",
    "        'file_sizes_checked': False,\n",
    "        'permissions_verified': False\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display manifest\n",
    "print(\"=== ARTIFACT MANIFEST ===\")\n",
    "print(json.dumps(artifact_manifest, indent=2))\n",
    "\n",
    "# Save manifest\n",
    "with open('artifact_manifest.json', 'w') as f:\n",
    "    json.dump(artifact_manifest, f, indent=2)\n",
    "print(\"\\n\u2713 Artifact manifest saved to artifact_manifest.json\")\n",
    "\n",
    "# Create checklist view\n",
    "deliverables_df = pd.DataFrame([\n",
    "    {\n",
    "        'Deliverable': key,\n",
    "        'Description': value['description'],\n",
    "        'Format': value['format'],\n",
    "        'Status': value['status'],\n",
    "        'Submitted': '\u25a1' if not value['submitted'] else '\u2713'\n",
    "    }\n",
    "    for key, value in artifact_manifest['deliverables'].items()\n",
    "])\n",
    "\n",
    "print(\"\\n=== DELIVERABLES CHECKLIST ===\")\n",
    "print(deliverables_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the output:**\n",
    "\n",
    "The artifact manifest is printed as formatted JSON, listing project metadata,\n",
    "six deliverables (notebook, slide deck, video, model artifacts, monitoring\n",
    "plan, model card), and five validation flags. The deliverables checklist\n",
    "table below it gives a compact, scannable view with a `Submitted` column\n",
    "you can toggle. Each deliverable's required **format** and **submission\n",
    "method** are specified so there is no ambiguity about what to upload and\n",
    "where.\n",
    "\n",
    "**Key takeaway:** Before clicking 'Submit', walk through this manifest\n",
    "row by row and test every link in an incognito browser to ensure it is\n",
    "accessible.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 4. Peer Review Rubric\n",
    "\n",
    "### Why Peer Review?\n",
    "\n",
    "> **\"You learn as much from reviewing others' work as from your own.\"**  \n",
    "> Good feedback requires critical thinking and makes you a better analyst.\n",
    "\n",
    "### 4.1 Review Principles\n",
    "\n",
    "**Be useful, not nice:**\n",
    "- Focus on specific, actionable feedback\n",
    "- Point out both strengths and weaknesses\n",
    "- Suggest concrete improvements\n",
    "\n",
    "**Be professional:**\n",
    "- Critique the work, not the person\n",
    "- Use \"I notice\" instead of \"You did wrong\"\n",
    "- Balance critical feedback with positive observations\n",
    "\n",
    "**Be thorough:**\n",
    "- Check technical correctness\n",
    "- Evaluate communication clarity\n",
    "- Consider business relevance\n",
    "\n",
    "### 4.2 Peer Review Rubric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peer review rubric\n",
    "review_rubric = pd.DataFrame([\n",
    "    {\n",
    "        'Dimension': 'Reproducibility',\n",
    "        'Weight': '20%',\n",
    "        'Excellent (4)': 'Run-all works perfectly, all outputs visible, fully documented',\n",
    "        'Good (3)': 'Run-all works with minor issues, most outputs visible',\n",
    "        'Needs Work (2)': 'Run-all has errors, some outputs missing',\n",
    "        'Insufficient (1)': 'Cannot run notebook, major errors',\n",
    "        'Score': ''\n",
    "    },\n",
    "    {\n",
    "        'Dimension': 'Methodology',\n",
    "        'Weight': '30%',\n",
    "        'Excellent (4)': 'Sound methods, proper validation, appropriate metrics, no leakage',\n",
    "        'Good (3)': 'Generally sound with minor issues in validation or metrics',\n",
    "        'Needs Work (2)': 'Significant methodology gaps or potential leakage',\n",
    "        'Insufficient (1)': 'Fundamental methodology errors',\n",
    "        'Score': ''\n",
    "    },\n",
    "    {\n",
    "        'Dimension': 'Results',\n",
    "        'Weight': '20%',\n",
    "        'Excellent (4)': 'Clear findings, well-supported, appropriate comparisons',\n",
    "        'Good (3)': 'Clear findings with minor gaps in support or comparison',\n",
    "        'Needs Work (2)': 'Unclear findings or weak evidence',\n",
    "        'Insufficient (1)': 'No clear results or unsupported claims',\n",
    "        'Score': ''\n",
    "    },\n",
    "    {\n",
    "        'Dimension': 'Communication',\n",
    "        'Weight': '20%',\n",
    "        'Excellent (4)': 'Clear narrative, effective visuals, professional presentation',\n",
    "        'Good (3)': 'Generally clear with minor issues in flow or visuals',\n",
    "        'Needs Work (2)': 'Unclear narrative or poor visual communication',\n",
    "        'Insufficient (1)': 'Confusing structure, ineffective communication',\n",
    "        'Score': ''\n",
    "    },\n",
    "    {\n",
    "        'Dimension': 'Responsible AI',\n",
    "        'Weight': '10%',\n",
    "        'Excellent (4)': 'Limitations acknowledged, monitoring plan detailed, risks addressed',\n",
    "        'Good (3)': 'Basic limitations and monitoring plan present',\n",
    "        'Needs Work (2)': 'Minimal attention to limitations or risks',\n",
    "        'Insufficient (1)': 'No consideration of limitations or risks',\n",
    "        'Score': ''\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"=== PEER REVIEW RUBRIC ===\")\n",
    "print(review_rubric.to_string(index=False))\n",
    "\n",
    "# Save rubric\n",
    "review_rubric.to_csv('peer_review_rubric.csv', index=False)\n",
    "print(\"\\n\u2713 Review rubric saved to peer_review_rubric.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the output:**\n",
    "\n",
    "The peer review rubric has **five dimensions**: Reproducibility (20 %),\n",
    "Methodology (30 %), Results (20 %), Communication (20 %), and Responsible\n",
    "AI (10 %). Each dimension has four scoring levels (Excellent 4, Good 3,\n",
    "Needs Work 2, Insufficient 1) with concrete descriptors. Notice that\n",
    "**Methodology** carries the highest weight because sound analytical\n",
    "practice is the foundation of a credible project. The **Responsible AI**\n",
    "dimension, while only 10 %, explicitly rewards acknowledgement of\n",
    "limitations and monitoring plans.\n",
    "\n",
    "**Why this matters:** Scoring with a rubric removes subjectivity and\n",
    "ensures every reviewer evaluates the same criteria. Use the descriptors\n",
    "to anchor your scores, not gut feeling.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "### 4.3 Peer Review Form Template\n",
    "\n",
    "The form below gives you a structured way to record your evaluation. It\n",
    "mirrors the rubric dimensions (Reproducibility, Methodology, Results,\n",
    "Communication, Responsible AI) and adds space for specific strengths,\n",
    "areas for improvement, and critical issues. Filling it out completely\n",
    "ensures that your feedback is both fair and actionable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peer review form template\n",
    "review_form = \"\"\"\n",
    "=== PEER REVIEW FORM ===\n",
    "\n",
    "Reviewer Name: [Your name]\n",
    "Project Reviewed: [Project title or author name]\n",
    "Review Date: [Date]\n",
    "\n",
    "---\n",
    "\n",
    "## SCORES (1-4 scale)\n",
    "\n",
    "Reproducibility (20%):     [ ] / 4\n",
    "Methodology (30%):          [ ] / 4\n",
    "Results (20%):              [ ] / 4\n",
    "Communication (20%):        [ ] / 4\n",
    "Responsible AI (10%):       [ ] / 4\n",
    "\n",
    "TOTAL (weighted):           [ ] / 4.0\n",
    "\n",
    "---\n",
    "\n",
    "## DETAILED FEEDBACK\n",
    "\n",
    "### Strengths (What did this project do well?)\n",
    "1. [Specific strength with example]\n",
    "2. [Specific strength with example]\n",
    "3. [Specific strength with example]\n",
    "\n",
    "### Areas for Improvement (What could be better?)\n",
    "1. [Specific issue + suggested fix]\n",
    "2. [Specific issue + suggested fix]\n",
    "3. [Specific issue + suggested fix]\n",
    "\n",
    "### Critical Issues (Must fix before production)\n",
    "1. [Critical issue if any]\n",
    "2. [Critical issue if any]\n",
    "\n",
    "---\n",
    "\n",
    "## DIMENSION-SPECIFIC FEEDBACK\n",
    "\n",
    "### Reproducibility\n",
    "- Run-all test: [PASS/FAIL with details]\n",
    "- Outputs visible: [Yes/No with details]\n",
    "- Documentation: [Assessment]\n",
    "\n",
    "### Methodology\n",
    "- Data splitting: [Assessment]\n",
    "- Model selection: [Assessment]\n",
    "- Validation strategy: [Assessment]\n",
    "- Potential leakage: [Any concerns?]\n",
    "\n",
    "### Results\n",
    "- Clarity of findings: [Assessment]\n",
    "- Evidence quality: [Assessment]\n",
    "- Baseline comparison: [Present? Appropriate?]\n",
    "\n",
    "### Communication\n",
    "- Narrative flow: [Assessment]\n",
    "- Visual quality: [Assessment]\n",
    "- Professional presentation: [Assessment]\n",
    "\n",
    "### Responsible AI\n",
    "- Limitations acknowledged: [Yes/No with details]\n",
    "- Monitoring plan: [Present? Adequate?]\n",
    "- Risk awareness: [Assessment]\n",
    "\n",
    "---\n",
    "\n",
    "## ADDITIONAL COMMENTS\n",
    "\n",
    "[Any other observations, suggestions, or questions]\n",
    "\n",
    "---\n",
    "\n",
    "## REVIEWER REFLECTION\n",
    "\n",
    "What did I learn from reviewing this project?\n",
    "[Your reflection here]\n",
    "\n",
    "What will I apply to my own work?\n",
    "[Your takeaways here]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(review_form)\n",
    "\n",
    "# Save form\n",
    "with open('peer_review_form.txt', 'w') as f:\n",
    "    f.write(review_form)\n",
    "print(\"\\n\u2713 Review form saved to peer_review_form.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the output:**\n",
    "\n",
    "The printed form provides a fill-in-the-blank template with sections for\n",
    "**Scores** (one per rubric dimension), **Detailed Feedback** (strengths,\n",
    "areas for improvement, critical issues), **Dimension-Specific Feedback**\n",
    "(reproducibility, methodology, results, communication, responsible AI),\n",
    "and a **Reviewer Reflection** asking what you learned. The form is also\n",
    "saved as a text file so you can fill it in outside the notebook if\n",
    "preferred.\n",
    "\n",
    "**Key takeaway:** Good peer feedback is specific and actionable. Instead\n",
    "of writing 'visuals could be better', write 'the ROC curve on slide 6 is\n",
    "missing axis labels and an AUC annotation -- adding those would strengthen\n",
    "credibility.'\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## \ud83d\udcdd PAUSE-AND-DO Exercise 2 (5 minutes)\n",
    "\n",
    "**Task:** Complete one peer review with rubric scores + 3 actionable edits.\n",
    "\n",
    "**Instructions:**\n",
    "1. Review the assigned project (or use a sample project)\n",
    "2. Score each dimension (1-4) using the rubric\n",
    "3. Identify 3 specific, actionable improvements\n",
    "4. Complete the review form below\n",
    "5. Focus on being helpful and constructive\n",
    "\n",
    "**Review guidelines:**\n",
    "- Spend ~2 minutes per dimension\n",
    "- First check if notebook runs (critical)\n",
    "- Then evaluate methodology and results\n",
    "- Finally assess communication and responsibility\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "### YOUR PEER REVIEW HERE:\n",
    "\n",
    "**Project reviewed:** [Title/Author]\n",
    "\n",
    "**Scores:**\n",
    "- Reproducibility: [ ] / 4\n",
    "- Methodology: [ ] / 4\n",
    "- Results: [ ] / 4\n",
    "- Communication: [ ] / 4\n",
    "- Responsible AI: [ ] / 4\n",
    "\n",
    "**Three Actionable Improvements:**\n",
    "\n",
    "1. **[Specific issue]**\n",
    "   - Current state: [What you observed]\n",
    "   - Suggested fix: [Concrete action to take]\n",
    "   - Expected improvement: [How this would help]\n",
    "\n",
    "2. **[Specific issue]**\n",
    "   - Current state:\n",
    "   - Suggested fix:\n",
    "   - Expected improvement:\n",
    "\n",
    "3. **[Specific issue]**\n",
    "   - Current state:\n",
    "   - Suggested fix:\n",
    "   - Expected improvement:\n",
    "\n",
    "**Overall assessment:**\n",
    "[1-2 sentences summarizing the project's main strength and main area for improvement]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 5. Postmortem Prompts\n",
    "\n",
    "### Why Write a Postmortem?\n",
    "\n",
    "> **\"Reflection turns experience into learning.\"**  \n",
    "> A postmortem helps you articulate what you learned and what you'd do differently.\n",
    "\n",
    "### 5.1 Postmortem Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postmortem template\n",
    "postmortem_template = \"\"\"\n",
    "=== PROJECT POSTMORTEM ===\n",
    "\n",
    "Project: [Your project title]\n",
    "Author: [Your name]\n",
    "Date: [Completion date]\n",
    "\n",
    "---\n",
    "\n",
    "## WHAT WORKED WELL (3-5 items)\n",
    "\n",
    "1. [Specific aspect that went well and why]\n",
    "   Example: \"EDA was thorough and caught a data quality issue early\"\n",
    "\n",
    "2. [Specific aspect that went well and why]\n",
    "\n",
    "3. [Specific aspect that went well and why]\n",
    "\n",
    "---\n",
    "\n",
    "## WHAT DIDN'T WORK (3-5 items)\n",
    "\n",
    "1. [Specific challenge and why it was difficult]\n",
    "   Example: \"Feature engineering took longer than expected due to unclear documentation\"\n",
    "\n",
    "2. [Specific challenge and why it was difficult]\n",
    "\n",
    "3. [Specific challenge and why it was difficult]\n",
    "\n",
    "---\n",
    "\n",
    "## KEY LEARNINGS (3-5 items)\n",
    "\n",
    "1. [Specific lesson learned]\n",
    "   Example: \"Always check for data leakage before modeling, not after\"\n",
    "\n",
    "2. [Specific lesson learned]\n",
    "\n",
    "3. [Specific lesson learned]\n",
    "\n",
    "---\n",
    "\n",
    "## WHAT I'D DO DIFFERENTLY NEXT TIME (3-5 items)\n",
    "\n",
    "1. [Specific change you'd make]\n",
    "   Example: \"Start with simpler models and iterate, rather than jumping to complex models\"\n",
    "\n",
    "2. [Specific change you'd make]\n",
    "\n",
    "3. [Specific change you'd make]\n",
    "\n",
    "---\n",
    "\n",
    "## TECHNICAL SKILLS DEVELOPED\n",
    "\n",
    "- [Skill 1: e.g., \"Cross-validation with stratified folds\"]\n",
    "- [Skill 2: e.g., \"Feature importance interpretation\"]\n",
    "- [Skill 3: e.g., \"Model deployment with joblib\"]\n",
    "- [Skill 4]\n",
    "- [Skill 5]\n",
    "\n",
    "---\n",
    "\n",
    "## BUSINESS SKILLS DEVELOPED\n",
    "\n",
    "- [Skill 1: e.g., \"Translating technical metrics to business impact\"]\n",
    "- [Skill 2: e.g., \"Communicating limitations to stakeholders\"]\n",
    "- [Skill 3: e.g., \"Designing monitoring plans for production\"]\n",
    "\n",
    "---\n",
    "\n",
    "## IF I HAD MORE TIME, I WOULD...\n",
    "\n",
    "1. [Extension or improvement]\n",
    "2. [Extension or improvement]\n",
    "3. [Extension or improvement]\n",
    "\n",
    "---\n",
    "\n",
    "## MOST SURPRISING FINDING\n",
    "\n",
    "[What unexpected insight did you discover?]\n",
    "\n",
    "---\n",
    "\n",
    "## MOST VALUABLE COURSE RESOURCE\n",
    "\n",
    "[Which reading, video, or exercise was most helpful?]\n",
    "\n",
    "---\n",
    "\n",
    "## ADVICE FOR FUTURE STUDENTS\n",
    "\n",
    "[What would you tell someone starting this project?]\n",
    "\n",
    "---\n",
    "\n",
    "## NEXT STEPS\n",
    "\n",
    "[What would you do to continue this project or apply these skills?]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(postmortem_template)\n",
    "\n",
    "# Save template\n",
    "with open('postmortem_template.txt', 'w') as f:\n",
    "    f.write(postmortem_template)\n",
    "print(\"\\n\u2713 Postmortem template saved to postmortem_template.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the output:**\n",
    "\n",
    "The postmortem template prints nine reflection sections: What Worked Well,\n",
    "What Didn't Work, Key Learnings, What I'd Do Differently, Technical Skills\n",
    "Developed, Business Skills Developed, If I Had More Time, Most Surprising\n",
    "Finding, and Advice for Future Students. Each section asks for 3-5 specific,\n",
    "evidence-based items rather than vague generalities. The template is saved\n",
    "to a text file for offline completion.\n",
    "\n",
    "**Why this matters:** A postmortem cements learning. Research on\n",
    "metacognition shows that structured reflection significantly improves\n",
    "long-term retention of both technical and process skills.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "### 5.2 Your Project Postmortem\n",
    "\n",
    "Take 10-15 minutes to complete your project postmortem below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "### YOUR POSTMORTEM HERE:\n",
    "\n",
    "**What worked well:**\n",
    "1. [Item 1]\n",
    "2. [Item 2]\n",
    "3. [Item 3]\n",
    "\n",
    "**What didn't work:**\n",
    "1. [Item 1]\n",
    "2. [Item 2]\n",
    "3. [Item 3]\n",
    "\n",
    "**Key learnings:**\n",
    "1. [Learning 1]\n",
    "2. [Learning 2]\n",
    "3. [Learning 3]\n",
    "\n",
    "**What I'd do differently:**\n",
    "1. [Change 1]\n",
    "2. [Change 2]\n",
    "3. [Change 3]\n",
    "\n",
    "**Most surprising finding:**  \n",
    "[Your answer]\n",
    "\n",
    "**Advice for future students:**  \n",
    "[Your advice]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 6. Wrap-Up: Key Takeaways\n",
    "\n",
    "### What We Accomplished in This Course:\n",
    "\n",
    "**Week 1: Foundations**\n",
    "- Colab workflow and responsible AI-assisted coding\n",
    "- EDA, preprocessing, and avoiding leakage\n",
    "- Baseline models and proper validation\n",
    "\n",
    "**Week 2: Model Development**\n",
    "- Linear models, tree-based models, ensembles\n",
    "- Hyperparameter tuning and model selection\n",
    "- Performance metrics and evaluation strategies\n",
    "\n",
    "**Week 3: Advanced Topics**\n",
    "- Feature engineering and selection\n",
    "- Model interpretation and explainability\n",
    "- Imbalanced data and calibration\n",
    "\n",
    "**Week 4: Production and Communication**\n",
    "- Reproducibility and deployment thinking\n",
    "- Executive communication and storytelling\n",
    "- Peer review and continuous improvement\n",
    "\n",
    "### Essential Skills You've Developed:\n",
    "\n",
    "**Technical:**\n",
    "- \u2713 End-to-end ML pipeline development\n",
    "- \u2713 Model selection and validation\n",
    "- \u2713 Production-ready code and artifacts\n",
    "- \u2713 Monitoring and maintenance planning\n",
    "\n",
    "**Analytical:**\n",
    "- \u2713 Problem framing and metric selection\n",
    "- \u2713 Critical evaluation of results\n",
    "- \u2713 Assumption identification and testing\n",
    "- \u2713 Risk assessment and mitigation\n",
    "\n",
    "**Communication:**\n",
    "- \u2713 Executive-level storytelling\n",
    "- \u2713 Visual communication\n",
    "- \u2713 Technical documentation\n",
    "- \u2713 Peer feedback and collaboration\n",
    "\n",
    "### Remember:\n",
    "\n",
    "> **\"The best data scientists are not just good at modeling\u2014they're good at communication, judgment, and continuous learning.\"**  \n",
    "> Keep developing all three.\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "**Continue learning:**\n",
    "- Deep learning and neural networks\n",
    "- Advanced NLP and computer vision\n",
    "- Causal inference and experimentation\n",
    "- MLOps and production systems\n",
    "\n",
    "**Build your portfolio:**\n",
    "- Complete end-to-end projects\n",
    "- Contribute to open source\n",
    "- Write about your work\n",
    "- Present at meetups or conferences\n",
    "\n",
    "**Stay connected:**\n",
    "- Join ML communities\n",
    "- Follow industry blogs and papers\n",
    "- Practice on Kaggle or similar platforms\n",
    "- Network with practitioners\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Participation Assignment Submission Instructions\n",
    "\n",
    "### To Submit This Notebook:\n",
    "\n",
    "1. **Complete all exercises**: Fill in both PAUSE-AND-DO exercise cells with your findings\n",
    "2. **Run All Cells**: Execute `Runtime \u2192 Run all` to ensure everything works\n",
    "3. **Save a Copy**: `File \u2192 Save a copy in Drive`\n",
    "4. **Submit**: Upload your `.ipynb` file in the participation assignment you find in the course Brightspace page.\n",
    "\n",
    "### Before Submitting, Check:\n",
    "\n",
    "- [ ] All cells execute without errors\n",
    "- [ ] All outputs are visible\n",
    "- [ ] Both exercise responses are complete\n",
    "- [ ] Notebook is shared with correct permissions\n",
    "- [ ] You can explain every line of code you wrote\n",
    "\n",
    "### Next Step:\n",
    "\n",
    "Complete the **Quiz** in Brightspace (auto-graded)\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Final Submission Instructions\n\n### To Submit Your Complete Project:\n\n1. **Complete All Deliverables**: Check artifact manifest above\n2. **Run Final Audit**: Complete both technical and communication checklists\n3. **Test All Links**: Verify in incognito/private browser\n4. **Submit to LMS**: Follow course-specific instructions\n5. **Complete Peer Review**: Review assigned project(s)\n6. **Write Postmortem**: Reflect on your learning journey\n\n### Final Checklist:\n\n**Deliverables (REQUIRED):**\n- [ ] Jupyter Notebook (run-all complete, shared)\n- [ ] Slide Deck (10-12 slides, professional)\n- [ ] Conference Video (2-3 minutes, good quality)\n- [ ] Model Artifacts (saved and accessible)\n- [ ] Monitoring Plan (documented)\n\n**Peer Review (REQUIRED):**\n- [ ] Review form completed with scores\n- [ ] 3+ actionable suggestions provided\n- [ ] Submitted by deadline\n\n**Postmortem (RECOMMENDED):**\n- [ ] What worked / didn't work\n- [ ] Key learnings\n- [ ] What you'd do differently\n\n### Before You Click Submit:\n\n- [ ] All files uploaded/linked\n- [ ] All links tested\n- [ ] All permissions verified\n- [ ] Deadline confirmed\n- [ ] Backup copies saved\n\n---\n\n## Bibliography\n\n### Core References\n\n- Mitchell, M., Wu, S., Zaldivar, A., Barnes, P., Vasserman, L., Hutchinson, B., Spitzer, E., Raji, I. D., & Gebru, T. (2019). Model Cards for Model Reporting. *Proceedings of the Conference on Fairness, Accountability, and Transparency*.\n- Huyen, C. (2022). *Designing Machine Learning Systems*. O'Reilly Media. (Chapters on deployment checklists and monitoring)\n- Knaflic, C. N. (2015). *Storytelling with Data: A Data Visualization Guide for Business Professionals*. Wiley.\n- Minto, B. (2009). *The Pyramid Principle: Logic in Writing and Thinking*. Pearson Education.\n\n### Additional Resources\n\n- Provost, F., & Fawcett, T. (2013). *Data Science for Business*. O'Reilly Media.\n- James, G., Witten, D., Hastie, T., & Tibshirani, R. (2021). *An Introduction to Statistical Learning with Python*. Springer.\n- Lakshmanan, V., Robinson, S., & Munn, M. (2020). *Machine Learning Design Patterns*. O'Reilly Media.\n- scikit-learn User Guide: [Model persistence](https://scikit-learn.org/stable/model_persistence.html)\n- Google: [People + AI Guidebook](https://pair.withgoogle.com/guidebook)\n\n---\n\n## Thank You!\n\nCongratulations on completing the Predictive Analytics course!\n\nYou've built a complete end-to-end ML project from problem framing through production planning. This is a significant accomplishment that demonstrates both technical skill and professional judgment.\n\n**Remember:**\n- Keep learning and experimenting\n- Share your work with others\n- Ask questions and seek feedback\n- Apply these skills to real-world problems\n\n**Good luck with your data science journey!**\n\n---\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "Thank you!\n",
    "\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}